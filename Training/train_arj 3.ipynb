{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgJoLQ9grYes",
        "outputId": "1ac1e9f4-6827-4f3f-f707-530e312a497f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive.mount('/content/drive/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYtPaTMErvgL",
        "outputId": "ca5ffcf5-afe1-4d39-f36b-01eeda7ea088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Handwriting_recog_train\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Handwriting_recog_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vaivFjltVEm",
        "outputId": "63cf2ef1-6cd6-4428-fe2e-798684ff78cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "annotations.csv  arial.ttf  \u001b[0m\u001b[01;34mdataset\u001b[0m/  vgg16.png\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yhrSBhkTqYL9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import shutil\n",
        "from skimage.feature import hog\n",
        "from skimage.morphology import skeletonize\n",
        "from skimage import exposure\n",
        "import random\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, Model, Input, activations\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4u3TkOB6qYMB"
      },
      "outputs": [],
      "source": [
        "# Folder paths\n",
        "annotation_csv = 'annotations.csv'\n",
        "dataset_folder = 'dataset'  # Folder containing original images\n",
        "# dataset_folder = 'drive/MyDrive/Handwriting_recog_train'  # Folder containing original images\n",
        "\n",
        "# Alpha\n",
        "# alpha = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "alpha = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "\n",
        "# Load annotations\n",
        "with open(annotation_csv, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    annotations = list(reader)[1:]  # Skip header\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sBnpWL5ku2rr"
      },
      "outputs": [],
      "source": [
        "# annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNHoKq14vQ7a",
        "outputId": "a55eaa09-9a9f-4d4b-a5a6-e152b671711c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "annotations.csv  \u001b[0m\u001b[01;34mdataset\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pxdou--qvSdD"
      },
      "outputs": [],
      "source": [
        "blah = cv2.imread(\"dataset/a1.jpg\")\n",
        "if blah is None:\n",
        "    print(\"blah\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Iw25WlHeyKPv",
        "outputId": "bfcd8de4-fce5-4772-b799-de69ded09188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a 307\n",
            "b 96\n",
            "c 178\n",
            "d 219\n",
            "e 507\n",
            "f 54\n",
            "g 110\n",
            "h 168\n",
            "i 301\n",
            "j 13\n",
            "k 40\n",
            "l 145\n",
            "m 134\n",
            "n 398\n",
            "o 377\n",
            "p 125\n",
            "q 28\n",
            "r 259\n",
            "s 293\n",
            "t 363\n",
            "u 154\n",
            "v 60\n",
            "w 65\n",
            "x 28\n",
            "y 79\n",
            "z 19\n"
          ]
        }
      ],
      "source": [
        "letterList = []\n",
        "for annotation in annotations:\n",
        "    _, letter, _, _, _, _ = annotation\n",
        "    letterList.append(letter)\n",
        "alphaIndexes = {}\n",
        "for i in alpha:\n",
        "    alphaIndexes[i] = []\n",
        "for i in range(len(letterList)):\n",
        "    try:\n",
        "        alphaIndexes[letterList[i]].append(i)\n",
        "    except:\n",
        "        pass\n",
        "for i, j in alphaIndexes.items():\n",
        "    print(i, len(j))\n",
        "# alphaIndexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VieEfWkJqYMB"
      },
      "outputs": [],
      "source": [
        "# flag = annotations[0][0]\n",
        "c = 0\n",
        "image_list1, image_list2, image_list3, image_list4, image_list5 = [], [], [], [], []\n",
        "label_list = []\n",
        "\n",
        "# Feature extraction steps\n",
        "for annotation in annotations:\n",
        "    c += 1\n",
        "    image_name1, letter, center_x, center_y, dist_x, dist_y = annotation\n",
        "\n",
        "    # Load original image\n",
        "    image_name1 = image_name1.replace('\\\\', '/')\n",
        "    # image_path = os.path.join(dataset_folder, image_name)\n",
        "    # img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.imread(image_name1, cv2.IMREAD_GRAYSCALE)\n",
        "    image_name = image_name1[image_name1.find('\\\\')+1:image_name1.find('.')]\n",
        "\n",
        "    if img is None:\n",
        "        # print(f\"Error: {image_path}_{c} not found!\")\n",
        "        print(f\"Error: {image_name1}_{c} not found!\")\n",
        "        continue\n",
        "\n",
        "    # Crop the letter using the annotation box\n",
        "    start_x = int(float(center_x) - float(dist_x) / 2)\n",
        "    start_y = int(float(center_y) - float(dist_y) / 2)\n",
        "    end_x = int(float(center_x) + float(dist_x) / 2)\n",
        "    end_y = int(float(center_y) + float(dist_y) / 2)\n",
        "    cropped = img[start_y:end_y, start_x:end_x]\n",
        "\n",
        "    # 1. Image Enhancement & Normalization (Histogram Equalization)\n",
        "    resized = cv2.resize(cropped, (64, 64))\n",
        "    enhanced = cv2.equalizeHist(resized)\n",
        "    norm_image = cv2.normalize(enhanced, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    image_list1.append(norm_image)\n",
        "    label_list.append(letter)\n",
        "\n",
        "    # 2. Segmentation (Thresholding)\n",
        "    _, segmented = cv2.threshold(norm_image, 30, 255, cv2.THRESH_BINARY_INV)\n",
        "    image_list2.append(segmented)\n",
        "\n",
        "    # 3. Edge Detection (Canny)\n",
        "    edges = cv2.Canny(segmented, 100, 200)\n",
        "    image_list3.append(edges)\n",
        "\n",
        "    # 4. Skeletonization\n",
        "    binary = segmented / 255  # Convert to binary (0, 1)\n",
        "    skeleton = skeletonize(binary).astype(np.uint8) * 255\n",
        "    image_list4.append(skeleton)\n",
        "\n",
        "    # 5. HOG (Histogram of Oriented Gradients)\n",
        "    hog_features, hog_image = hog(segmented, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
        "    image_list5.append(hog_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "id": "yjTvJf91qYMC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'A',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'B',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'c',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'C',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'd',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'D',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'e',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'E',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'f',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'F',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'g',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'G',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'h',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'H',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'i',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'I',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'j',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'J',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'k',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'K',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'L',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'm',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'M',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'n',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'N',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'o',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'p',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'P',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'Q',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'r',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 'R',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 's',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 'S',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 't',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'T',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'u',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'U',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'v',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'V',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'w',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'W',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'x',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'X',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'Y',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'Z',\n",
              " 'A',\n",
              " 'r',\n",
              " 't',\n",
              " 'f',\n",
              " 'c',\n",
              " 'a',\n",
              " 'l',\n",
              " 'I',\n",
              " 'n',\n",
              " 't',\n",
              " 'l',\n",
              " 'g',\n",
              " 'n',\n",
              " 'c',\n",
              " 'e',\n",
              " 'M',\n",
              " 'o',\n",
              " 'u',\n",
              " 'e',\n",
              " 'W',\n",
              " 'h',\n",
              " 'a',\n",
              " 't',\n",
              " 'i',\n",
              " 's',\n",
              " 'i',\n",
              " 'n',\n",
              " 'e',\n",
              " 'c',\n",
              " 'n',\n",
              " 'e',\n",
              " 'g',\n",
              " 'S',\n",
              " 'o',\n",
              " 'm',\n",
              " 'e',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 't',\n",
              " 'h',\n",
              " 'a',\n",
              " 't',\n",
              " 's',\n",
              " 'o',\n",
              " 'm',\n",
              " 'e',\n",
              " 'o',\n",
              " 'n',\n",
              " 'e',\n",
              " 'w',\n",
              " 'h',\n",
              " 'r',\n",
              " 'a',\n",
              " 'i',\n",
              " 'n',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 's',\n",
              " 'o',\n",
              " 'm',\n",
              " 'e',\n",
              " 'c',\n",
              " 's',\n",
              " 'e',\n",
              " 'n',\n",
              " 's',\n",
              " 'e',\n",
              " 'i',\n",
              " 'h',\n",
              " 'a',\n",
              " 'v',\n",
              " 'e',\n",
              " 'w',\n",
              " 'l',\n",
              " 't',\n",
              " 'l',\n",
              " 'e',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 'k',\n",
              " 'r',\n",
              " 'o',\n",
              " 'h',\n",
              " 's',\n",
              " 'r',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 't',\n",
              " 't',\n",
              " 'h',\n",
              " 'H',\n",
              " 'u',\n",
              " 'm',\n",
              " 'a',\n",
              " 'n',\n",
              " 's',\n",
              " 'l',\n",
              " 'e',\n",
              " 'a',\n",
              " 'r',\n",
              " 'n',\n",
              " 'b',\n",
              " 'y',\n",
              " 'd',\n",
              " 'o',\n",
              " 'n',\n",
              " 'g',\n",
              " 't',\n",
              " 'h',\n",
              " 'i',\n",
              " 'n',\n",
              " 's',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'n',\n",
              " 't',\n",
              " 'j',\n",
              " 'u',\n",
              " 's',\n",
              " 't',\n",
              " 'r',\n",
              " 'e',\n",
              " 'a',\n",
              " 'm',\n",
              " 'd',\n",
              " 'n',\n",
              " 'a',\n",
              " 'r',\n",
              " 't',\n",
              " 'u',\n",
              " 'o',\n",
              " 'b',\n",
              " 'a',\n",
              " 'g',\n",
              " 'n',\n",
              " 'p',\n",
              " 'y',\n",
              " 'n',\n",
              " 'o',\n",
              " 'g',\n",
              " 'n',\n",
              " 'i',\n",
              " 'o',\n",
              " 'g',\n",
              " 's',\n",
              " 'i',\n",
              " 'f',\n",
              " 'm',\n",
              " 's',\n",
              " 'h',\n",
              " 't',\n",
              " 'e',\n",
              " 'k',\n",
              " 'l',\n",
              " 'g',\n",
              " 'n',\n",
              " 'i',\n",
              " 'n',\n",
              " 'l',\n",
              " 'r',\n",
              " 'o',\n",
              " 'b',\n",
              " 'u',\n",
              " 'l',\n",
              " 'l',\n",
              " 's',\n",
              " 'h',\n",
              " 'i',\n",
              " 't',\n",
              " 'A',\n",
              " 'I',\n",
              " 't',\n",
              " 'y',\n",
              " 'p',\n",
              " 'e',\n",
              " 's',\n",
              " 'M',\n",
              " 'a',\n",
              " 'c',\n",
              " 'h',\n",
              " 'n',\n",
              " 'e',\n",
              " 'e',\n",
              " 'a',\n",
              " 'r',\n",
              " 'n',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 'L',\n",
              " 'N',\n",
              " 'L',\n",
              " 'P',\n",
              " 'E',\n",
              " 'V',\n",
              " 'P',\n",
              " 'A',\n",
              " 'T',\n",
              " 'T',\n",
              " 'A',\n",
              " 'A',\n",
              " 'T',\n",
              " 'N',\n",
              " 'L',\n",
              " 'P',\n",
              " 'C',\n",
              " 'R',\n",
              " 'n',\n",
              " 'o',\n",
              " 'v',\n",
              " 'r',\n",
              " 'e',\n",
              " 'o',\n",
              " 'a',\n",
              " 't',\n",
              " 'n',\n",
              " 'e',\n",
              " 'e',\n",
              " 'n',\n",
              " 'a',\n",
              " 'r',\n",
              " 'o',\n",
              " 'n',\n",
              " 'i',\n",
              " 'n',\n",
              " 'o',\n",
              " 's',\n",
              " 'a',\n",
              " 'e',\n",
              " 'r',\n",
              " 'd',\n",
              " 'a',\n",
              " 'm',\n",
              " 'u',\n",
              " 'n',\n",
              " 'o',\n",
              " 'o',\n",
              " 'e',\n",
              " 'e',\n",
              " 'g',\n",
              " 'r',\n",
              " 'e',\n",
              " 'r',\n",
              " 'e',\n",
              " 'n',\n",
              " 'a',\n",
              " 't',\n",
              " 't',\n",
              " 'o',\n",
              " 'n',\n",
              " 'a',\n",
              " 'g',\n",
              " 'n',\n",
              " 'i',\n",
              " 'r',\n",
              " 'u',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'r',\n",
              " 'o',\n",
              " 'a',\n",
              " 'c',\n",
              " 'h',\n",
              " 't',\n",
              " 'g',\n",
              " 'x',\n",
              " 't',\n",
              " 's',\n",
              " 'y',\n",
              " 's',\n",
              " 'r',\n",
              " 'e',\n",
              " 'e',\n",
              " 's',\n",
              " 'm',\n",
              " 'p',\n",
              " 'h',\n",
              " 'R',\n",
              " 'e',\n",
              " 'e',\n",
              " 'c',\n",
              " 'i',\n",
              " 's',\n",
              " 'i',\n",
              " 'o',\n",
              " 'n',\n",
              " 's',\n",
              " 'c',\n",
              " 't',\n",
              " 'b',\n",
              " 'R',\n",
              " 'o',\n",
              " 'a',\n",
              " 'n',\n",
              " 'n',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 'e',\n",
              " 'c',\n",
              " 'o',\n",
              " 'g',\n",
              " 'n',\n",
              " 'i',\n",
              " 't',\n",
              " 'o',\n",
              " 'n',\n",
              " 'S',\n",
              " 'T',\n",
              " 'p',\n",
              " 'f',\n",
              " 'w',\n",
              " 'h',\n",
              " 't',\n",
              " 'i',\n",
              " 'N',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " 'g',\n",
              " 'y',\n",
              " 'h',\n",
              " 'r',\n",
              " 'a',\n",
              " 'r',\n",
              " 'e',\n",
              " 'i',\n",
              " 'i',\n",
              " 'o',\n",
              " 'p',\n",
              " 'p',\n",
              " 'r',\n",
              " 'o',\n",
              " 'a',\n",
              " 'c',\n",
              " 'h',\n",
              " 'e',\n",
              " 's',\n",
              " 'o',\n",
              " 't',\n",
              " 'A',\n",
              " 'I',\n",
              " 'e',\n",
              " 'u',\n",
              " 'i',\n",
              " 's',\n",
              " 'e',\n",
              " 'i',\n",
              " 'a',\n",
              " 'h',\n",
              " 'n',\n",
              " 'k',\n",
              " 'n',\n",
              " 'i',\n",
              " 'i',\n",
              " 'g',\n",
              " 'h',\n",
              " 'u',\n",
              " 'm',\n",
              " 'n',\n",
              " 'l',\n",
              " 'a',\n",
              " 'C',\n",
              " 'o',\n",
              " 'i',\n",
              " 'e',\n",
              " 'v',\n",
              " 'i',\n",
              " 'g',\n",
              " 'l',\n",
              " 'l',\n",
              " 'l',\n",
              " 'd',\n",
              " 'o',\n",
              " 'e',\n",
              " 'n',\n",
              " 'm',\n",
              " 'g',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'h',\n",
              " 'k',\n",
              " 'i',\n",
              " 'n',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 'r',\n",
              " 'a',\n",
              " 't',\n",
              " 'o',\n",
              " 'n',\n",
              " 'a',\n",
              " 'l',\n",
              " 'l',\n",
              " 'y',\n",
              " 'i',\n",
              " 'L',\n",
              " 'a',\n",
              " 's',\n",
              " 'w',\n",
              " 'f',\n",
              " 't',\n",
              " ...]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rd3O48PmqYMD"
      },
      "outputs": [],
      "source": [
        "alphaIndexes = {}\n",
        "for i in alpha:\n",
        "    alphaIndexes[i] = []\n",
        "for i in range(len(label_list)):\n",
        "    try:\n",
        "        alphaIndexes[label_list[i]].append(i)\n",
        "    except:\n",
        "        pass\n",
        "# alphaIndexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TppIvRVQqYMD"
      },
      "outputs": [],
      "source": [
        "indexes = [i for i in range(len(label_list))]\n",
        "xrl, xtl = train_test_split(indexes, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BdQu59WFz1HL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': [[0,\n",
              "   1,\n",
              "   2,\n",
              "   4,\n",
              "   6,\n",
              "   8,\n",
              "   10,\n",
              "   595,\n",
              "   611,\n",
              "   631,\n",
              "   643,\n",
              "   646,\n",
              "   661,\n",
              "   687,\n",
              "   692,\n",
              "   706,\n",
              "   717,\n",
              "   721,\n",
              "   727,\n",
              "   808,\n",
              "   814,\n",
              "   822,\n",
              "   826,\n",
              "   840,\n",
              "   845,\n",
              "   856,\n",
              "   912,\n",
              "   919,\n",
              "   929,\n",
              "   944,\n",
              "   957,\n",
              "   974,\n",
              "   985,\n",
              "   989,\n",
              "   1006,\n",
              "   1010,\n",
              "   1044,\n",
              "   1048,\n",
              "   1051,\n",
              "   1056,\n",
              "   1062,\n",
              "   1145,\n",
              "   1163,\n",
              "   1178,\n",
              "   1190,\n",
              "   1193,\n",
              "   1198,\n",
              "   1212,\n",
              "   1229,\n",
              "   1238,\n",
              "   1307,\n",
              "   1312,\n",
              "   1332,\n",
              "   1357,\n",
              "   1418,\n",
              "   1426,\n",
              "   1435,\n",
              "   1511,\n",
              "   1516,\n",
              "   1525,\n",
              "   1582,\n",
              "   1612,\n",
              "   1615,\n",
              "   1626,\n",
              "   1643,\n",
              "   1684,\n",
              "   1718,\n",
              "   1722,\n",
              "   1734,\n",
              "   1748,\n",
              "   1782,\n",
              "   1837,\n",
              "   1893,\n",
              "   1898,\n",
              "   1900,\n",
              "   1920,\n",
              "   1926,\n",
              "   1953,\n",
              "   2025,\n",
              "   2038,\n",
              "   2054,\n",
              "   2094,\n",
              "   2105,\n",
              "   2134,\n",
              "   2173,\n",
              "   2176,\n",
              "   2197,\n",
              "   2223,\n",
              "   2232,\n",
              "   2233,\n",
              "   2244,\n",
              "   2250,\n",
              "   2264,\n",
              "   2322,\n",
              "   2350,\n",
              "   2385,\n",
              "   2391,\n",
              "   2406,\n",
              "   2461,\n",
              "   2484,\n",
              "   2488,\n",
              "   2585,\n",
              "   2596,\n",
              "   2602,\n",
              "   2633,\n",
              "   2638,\n",
              "   2670,\n",
              "   2674,\n",
              "   2680,\n",
              "   2683,\n",
              "   2731,\n",
              "   2742,\n",
              "   2780,\n",
              "   2785,\n",
              "   2794,\n",
              "   2803,\n",
              "   2814,\n",
              "   2850,\n",
              "   2857,\n",
              "   2879,\n",
              "   2909,\n",
              "   2957,\n",
              "   3002,\n",
              "   3029,\n",
              "   3053,\n",
              "   3073,\n",
              "   3089,\n",
              "   3106,\n",
              "   3114,\n",
              "   3141,\n",
              "   3153,\n",
              "   3176,\n",
              "   3189,\n",
              "   3191,\n",
              "   3195,\n",
              "   3227,\n",
              "   3246,\n",
              "   3265,\n",
              "   3275,\n",
              "   3277,\n",
              "   3307,\n",
              "   3343,\n",
              "   3345,\n",
              "   3368,\n",
              "   3397,\n",
              "   3426,\n",
              "   3452,\n",
              "   3464,\n",
              "   3489,\n",
              "   3513,\n",
              "   3518,\n",
              "   3546,\n",
              "   3563,\n",
              "   3584,\n",
              "   3631,\n",
              "   3662,\n",
              "   3677,\n",
              "   3707,\n",
              "   3725,\n",
              "   3735,\n",
              "   3745,\n",
              "   3758,\n",
              "   3774,\n",
              "   3787,\n",
              "   3795,\n",
              "   3807,\n",
              "   3817,\n",
              "   3836,\n",
              "   3854,\n",
              "   3902,\n",
              "   3916,\n",
              "   3930,\n",
              "   3932,\n",
              "   3937,\n",
              "   3952,\n",
              "   3980,\n",
              "   4019,\n",
              "   4024,\n",
              "   4037,\n",
              "   4054,\n",
              "   4074,\n",
              "   4076,\n",
              "   4079,\n",
              "   4103,\n",
              "   4109,\n",
              "   4124,\n",
              "   4130,\n",
              "   4169,\n",
              "   4174,\n",
              "   4185,\n",
              "   4195,\n",
              "   4202,\n",
              "   4214,\n",
              "   4241,\n",
              "   4269,\n",
              "   4317,\n",
              "   4332,\n",
              "   4348,\n",
              "   4363,\n",
              "   4381,\n",
              "   4429,\n",
              "   4447,\n",
              "   4457,\n",
              "   4477,\n",
              "   4498,\n",
              "   4512,\n",
              "   4526,\n",
              "   4532,\n",
              "   4534,\n",
              "   4542,\n",
              "   4544,\n",
              "   4550,\n",
              "   4575,\n",
              "   4580,\n",
              "   4592,\n",
              "   4600,\n",
              "   4612,\n",
              "   4616,\n",
              "   4640,\n",
              "   4642,\n",
              "   4652,\n",
              "   4667,\n",
              "   4680,\n",
              "   4687,\n",
              "   4702,\n",
              "   4705,\n",
              "   4726,\n",
              "   4746,\n",
              "   4759,\n",
              "   4809,\n",
              "   4824,\n",
              "   4830,\n",
              "   4843,\n",
              "   4846,\n",
              "   4847,\n",
              "   4856,\n",
              "   4887,\n",
              "   4924,\n",
              "   4991,\n",
              "   4995,\n",
              "   5028,\n",
              "   5084,\n",
              "   5112,\n",
              "   5169,\n",
              "   5226],\n",
              "  [3,\n",
              "   5,\n",
              "   7,\n",
              "   9,\n",
              "   678,\n",
              "   772,\n",
              "   778,\n",
              "   888,\n",
              "   995,\n",
              "   1016,\n",
              "   1029,\n",
              "   1197,\n",
              "   1219,\n",
              "   1248,\n",
              "   1520,\n",
              "   1528,\n",
              "   1597,\n",
              "   1605,\n",
              "   1633,\n",
              "   1680,\n",
              "   1756,\n",
              "   1841,\n",
              "   2029,\n",
              "   2060,\n",
              "   2204,\n",
              "   2289,\n",
              "   2307,\n",
              "   2398,\n",
              "   2459,\n",
              "   2800,\n",
              "   2820,\n",
              "   2846,\n",
              "   2985,\n",
              "   2999,\n",
              "   3006,\n",
              "   3012,\n",
              "   3092,\n",
              "   3165,\n",
              "   3312,\n",
              "   3379,\n",
              "   3586,\n",
              "   3600,\n",
              "   3620,\n",
              "   3642,\n",
              "   3801,\n",
              "   3847,\n",
              "   3996,\n",
              "   4012,\n",
              "   4029,\n",
              "   4100,\n",
              "   4142,\n",
              "   4162,\n",
              "   4230,\n",
              "   4336,\n",
              "   4493,\n",
              "   4635,\n",
              "   4786,\n",
              "   4829,\n",
              "   4938,\n",
              "   5010,\n",
              "   5094,\n",
              "   5139]],\n",
              " 'b': [[23,\n",
              "   24,\n",
              "   25,\n",
              "   27,\n",
              "   28,\n",
              "   29,\n",
              "   30,\n",
              "   31,\n",
              "   679,\n",
              "   695,\n",
              "   726,\n",
              "   756,\n",
              "   885,\n",
              "   975,\n",
              "   1007,\n",
              "   1008,\n",
              "   1014,\n",
              "   1065,\n",
              "   1068,\n",
              "   1071,\n",
              "   1089,\n",
              "   1094,\n",
              "   1114,\n",
              "   1175,\n",
              "   1278,\n",
              "   1313,\n",
              "   1318,\n",
              "   1322,\n",
              "   1368,\n",
              "   1378,\n",
              "   1401,\n",
              "   1403,\n",
              "   1554,\n",
              "   1559,\n",
              "   1576,\n",
              "   1580,\n",
              "   1610,\n",
              "   1651,\n",
              "   1654,\n",
              "   1663,\n",
              "   1724,\n",
              "   1747,\n",
              "   1891,\n",
              "   1896,\n",
              "   2110,\n",
              "   2225,\n",
              "   2637,\n",
              "   2658,\n",
              "   2665,\n",
              "   2673,\n",
              "   2787,\n",
              "   2819,\n",
              "   3129,\n",
              "   3137,\n",
              "   3145,\n",
              "   3183,\n",
              "   3278,\n",
              "   3509,\n",
              "   3607,\n",
              "   3715,\n",
              "   3768,\n",
              "   3796,\n",
              "   4231,\n",
              "   4481,\n",
              "   4555,\n",
              "   4625,\n",
              "   4673,\n",
              "   4867,\n",
              "   4932,\n",
              "   4937,\n",
              "   5025,\n",
              "   5076,\n",
              "   5146,\n",
              "   5148,\n",
              "   5167,\n",
              "   5216],\n",
              "  [22,\n",
              "   26,\n",
              "   32,\n",
              "   680,\n",
              "   976,\n",
              "   1015,\n",
              "   1082,\n",
              "   1155,\n",
              "   1162,\n",
              "   1187,\n",
              "   1497,\n",
              "   1844,\n",
              "   2988,\n",
              "   3192,\n",
              "   3704,\n",
              "   3995,\n",
              "   4364,\n",
              "   4469,\n",
              "   4737,\n",
              "   5211]],\n",
              " 'c': [[44,\n",
              "   45,\n",
              "   46,\n",
              "   47,\n",
              "   48,\n",
              "   49,\n",
              "   50,\n",
              "   51,\n",
              "   52,\n",
              "   54,\n",
              "   594,\n",
              "   618,\n",
              "   653,\n",
              "   876,\n",
              "   930,\n",
              "   1011,\n",
              "   1036,\n",
              "   1038,\n",
              "   1085,\n",
              "   1092,\n",
              "   1194,\n",
              "   1214,\n",
              "   1288,\n",
              "   1290,\n",
              "   1297,\n",
              "   1303,\n",
              "   1335,\n",
              "   1339,\n",
              "   1351,\n",
              "   1352,\n",
              "   1359,\n",
              "   1507,\n",
              "   1529,\n",
              "   1632,\n",
              "   1645,\n",
              "   1656,\n",
              "   1691,\n",
              "   1702,\n",
              "   1713,\n",
              "   1721,\n",
              "   1741,\n",
              "   1775,\n",
              "   1793,\n",
              "   1860,\n",
              "   1865,\n",
              "   1871,\n",
              "   1908,\n",
              "   1978,\n",
              "   1986,\n",
              "   2039,\n",
              "   2239,\n",
              "   2298,\n",
              "   2331,\n",
              "   2354,\n",
              "   2373,\n",
              "   2386,\n",
              "   2431,\n",
              "   2432,\n",
              "   2446,\n",
              "   2476,\n",
              "   2511,\n",
              "   2522,\n",
              "   2531,\n",
              "   2557,\n",
              "   2640,\n",
              "   2667,\n",
              "   2675,\n",
              "   2678,\n",
              "   2685,\n",
              "   2690,\n",
              "   2710,\n",
              "   2743,\n",
              "   2847,\n",
              "   2863,\n",
              "   2897,\n",
              "   2900,\n",
              "   2904,\n",
              "   2951,\n",
              "   2971,\n",
              "   2987,\n",
              "   3061,\n",
              "   3095,\n",
              "   3110,\n",
              "   3115,\n",
              "   3138,\n",
              "   3158,\n",
              "   3193,\n",
              "   3234,\n",
              "   3279,\n",
              "   3399,\n",
              "   3596,\n",
              "   3622,\n",
              "   3628,\n",
              "   3689,\n",
              "   3816,\n",
              "   3935,\n",
              "   3951,\n",
              "   3982,\n",
              "   4018,\n",
              "   4081,\n",
              "   4088,\n",
              "   4152,\n",
              "   4166,\n",
              "   4197,\n",
              "   4200,\n",
              "   4217,\n",
              "   4224,\n",
              "   4300,\n",
              "   4328,\n",
              "   4373,\n",
              "   4378,\n",
              "   4398,\n",
              "   4472,\n",
              "   4475,\n",
              "   4488,\n",
              "   4517,\n",
              "   4531,\n",
              "   4535,\n",
              "   4548,\n",
              "   4609,\n",
              "   4613,\n",
              "   4633,\n",
              "   4639,\n",
              "   4643,\n",
              "   4662,\n",
              "   4682,\n",
              "   4685,\n",
              "   4692,\n",
              "   4722,\n",
              "   4748,\n",
              "   4754,\n",
              "   4777,\n",
              "   4815,\n",
              "   4855,\n",
              "   4860,\n",
              "   4869,\n",
              "   4912,\n",
              "   5024,\n",
              "   5053,\n",
              "   5152,\n",
              "   5160,\n",
              "   5217],\n",
              "  [53,\n",
              "   603,\n",
              "   773,\n",
              "   857,\n",
              "   883,\n",
              "   895,\n",
              "   1057,\n",
              "   1217,\n",
              "   1226,\n",
              "   1246,\n",
              "   1424,\n",
              "   1436,\n",
              "   1628,\n",
              "   1780,\n",
              "   1903,\n",
              "   2061,\n",
              "   2118,\n",
              "   2123,\n",
              "   2569,\n",
              "   2737,\n",
              "   3350,\n",
              "   3579,\n",
              "   3612,\n",
              "   3621,\n",
              "   3639,\n",
              "   3663,\n",
              "   3680,\n",
              "   4095,\n",
              "   4410,\n",
              "   4430,\n",
              "   4499,\n",
              "   4557,\n",
              "   4789,\n",
              "   4878,\n",
              "   4998,\n",
              "   5068]],\n",
              " 'd': [[66,\n",
              "   67,\n",
              "   68,\n",
              "   69,\n",
              "   70,\n",
              "   71,\n",
              "   72,\n",
              "   73,\n",
              "   74,\n",
              "   76,\n",
              "   648,\n",
              "   697,\n",
              "   708,\n",
              "   719,\n",
              "   968,\n",
              "   1165,\n",
              "   1207,\n",
              "   1277,\n",
              "   1284,\n",
              "   1407,\n",
              "   1410,\n",
              "   1458,\n",
              "   1521,\n",
              "   1533,\n",
              "   1543,\n",
              "   1550,\n",
              "   1570,\n",
              "   1584,\n",
              "   1585,\n",
              "   1614,\n",
              "   1698,\n",
              "   1720,\n",
              "   1731,\n",
              "   1732,\n",
              "   1753,\n",
              "   1825,\n",
              "   1827,\n",
              "   1836,\n",
              "   1843,\n",
              "   1892,\n",
              "   1899,\n",
              "   1902,\n",
              "   1924,\n",
              "   1954,\n",
              "   1964,\n",
              "   1995,\n",
              "   2021,\n",
              "   2053,\n",
              "   2077,\n",
              "   2084,\n",
              "   2103,\n",
              "   2125,\n",
              "   2135,\n",
              "   2137,\n",
              "   2141,\n",
              "   2146,\n",
              "   2155,\n",
              "   2168,\n",
              "   2207,\n",
              "   2217,\n",
              "   2222,\n",
              "   2242,\n",
              "   2296,\n",
              "   2356,\n",
              "   2434,\n",
              "   2454,\n",
              "   2471,\n",
              "   2504,\n",
              "   2508,\n",
              "   2528,\n",
              "   2572,\n",
              "   2579,\n",
              "   2604,\n",
              "   2653,\n",
              "   2661,\n",
              "   2666,\n",
              "   2761,\n",
              "   2776,\n",
              "   2807,\n",
              "   2843,\n",
              "   2859,\n",
              "   2877,\n",
              "   2912,\n",
              "   2969,\n",
              "   3001,\n",
              "   3017,\n",
              "   3031,\n",
              "   3050,\n",
              "   3064,\n",
              "   3090,\n",
              "   3103,\n",
              "   3222,\n",
              "   3223,\n",
              "   3243,\n",
              "   3250,\n",
              "   3256,\n",
              "   3257,\n",
              "   3258,\n",
              "   3266,\n",
              "   3317,\n",
              "   3323,\n",
              "   3324,\n",
              "   3341,\n",
              "   3360,\n",
              "   3387,\n",
              "   3394,\n",
              "   3417,\n",
              "   3499,\n",
              "   3519,\n",
              "   3520,\n",
              "   3561,\n",
              "   3564,\n",
              "   3565,\n",
              "   3573,\n",
              "   3606,\n",
              "   3730,\n",
              "   3737,\n",
              "   3810,\n",
              "   3823,\n",
              "   3856,\n",
              "   3897,\n",
              "   3903,\n",
              "   3904,\n",
              "   3914,\n",
              "   3999,\n",
              "   4011,\n",
              "   4067,\n",
              "   4099,\n",
              "   4101,\n",
              "   4159,\n",
              "   4183,\n",
              "   4203,\n",
              "   4258,\n",
              "   4267,\n",
              "   4304,\n",
              "   4334,\n",
              "   4349,\n",
              "   4350,\n",
              "   4379,\n",
              "   4391,\n",
              "   4427,\n",
              "   4435,\n",
              "   4455,\n",
              "   4470,\n",
              "   4509,\n",
              "   4514,\n",
              "   4543,\n",
              "   4582,\n",
              "   4622,\n",
              "   4628,\n",
              "   4671,\n",
              "   4675,\n",
              "   4704,\n",
              "   4706,\n",
              "   4707,\n",
              "   4757,\n",
              "   4762,\n",
              "   4811,\n",
              "   4844,\n",
              "   4876,\n",
              "   4889,\n",
              "   4898,\n",
              "   4903,\n",
              "   4904,\n",
              "   5005,\n",
              "   5020,\n",
              "   5021,\n",
              "   5042,\n",
              "   5044,\n",
              "   5101,\n",
              "   5135,\n",
              "   5157,\n",
              "   5166,\n",
              "   5204,\n",
              "   5261],\n",
              "  [75,\n",
              "   825,\n",
              "   914,\n",
              "   1102,\n",
              "   1429,\n",
              "   1549,\n",
              "   1876,\n",
              "   2058,\n",
              "   2187,\n",
              "   2189,\n",
              "   2309,\n",
              "   2360,\n",
              "   2536,\n",
              "   2639,\n",
              "   2810,\n",
              "   2844,\n",
              "   2861,\n",
              "   2936,\n",
              "   3025,\n",
              "   3085,\n",
              "   3294,\n",
              "   3309,\n",
              "   3370,\n",
              "   3583,\n",
              "   3675,\n",
              "   3719,\n",
              "   3727,\n",
              "   3776,\n",
              "   3884,\n",
              "   3925,\n",
              "   3958,\n",
              "   4010,\n",
              "   4263,\n",
              "   4360,\n",
              "   4495,\n",
              "   4559,\n",
              "   4665,\n",
              "   4695,\n",
              "   4806,\n",
              "   5092,\n",
              "   5158,\n",
              "   5196,\n",
              "   5206,\n",
              "   5222]],\n",
              " 'e': [[90,\n",
              "   92,\n",
              "   93,\n",
              "   94,\n",
              "   95,\n",
              "   96,\n",
              "   97,\n",
              "   99,\n",
              "   608,\n",
              "   617,\n",
              "   620,\n",
              "   625,\n",
              "   636,\n",
              "   639,\n",
              "   655,\n",
              "   658,\n",
              "   663,\n",
              "   671,\n",
              "   691,\n",
              "   716,\n",
              "   746,\n",
              "   769,\n",
              "   776,\n",
              "   777,\n",
              "   811,\n",
              "   812,\n",
              "   832,\n",
              "   833,\n",
              "   836,\n",
              "   838,\n",
              "   851,\n",
              "   868,\n",
              "   874,\n",
              "   875,\n",
              "   894,\n",
              "   921,\n",
              "   932,\n",
              "   942,\n",
              "   961,\n",
              "   970,\n",
              "   1019,\n",
              "   1063,\n",
              "   1073,\n",
              "   1075,\n",
              "   1112,\n",
              "   1141,\n",
              "   1147,\n",
              "   1148,\n",
              "   1149,\n",
              "   1150,\n",
              "   1159,\n",
              "   1167,\n",
              "   1174,\n",
              "   1177,\n",
              "   1181,\n",
              "   1192,\n",
              "   1221,\n",
              "   1294,\n",
              "   1338,\n",
              "   1343,\n",
              "   1369,\n",
              "   1397,\n",
              "   1417,\n",
              "   1421,\n",
              "   1422,\n",
              "   1437,\n",
              "   1438,\n",
              "   1449,\n",
              "   1451,\n",
              "   1504,\n",
              "   1523,\n",
              "   1526,\n",
              "   1536,\n",
              "   1542,\n",
              "   1551,\n",
              "   1552,\n",
              "   1565,\n",
              "   1568,\n",
              "   1573,\n",
              "   1577,\n",
              "   1578,\n",
              "   1586,\n",
              "   1598,\n",
              "   1599,\n",
              "   1608,\n",
              "   1619,\n",
              "   1625,\n",
              "   1635,\n",
              "   1636,\n",
              "   1642,\n",
              "   1662,\n",
              "   1672,\n",
              "   1674,\n",
              "   1683,\n",
              "   1687,\n",
              "   1694,\n",
              "   1697,\n",
              "   1706,\n",
              "   1725,\n",
              "   1750,\n",
              "   1824,\n",
              "   1864,\n",
              "   1872,\n",
              "   1875,\n",
              "   1881,\n",
              "   1894,\n",
              "   1907,\n",
              "   1917,\n",
              "   1921,\n",
              "   1931,\n",
              "   1934,\n",
              "   1944,\n",
              "   1971,\n",
              "   1977,\n",
              "   1979,\n",
              "   1982,\n",
              "   1987,\n",
              "   1992,\n",
              "   1993,\n",
              "   2002,\n",
              "   2063,\n",
              "   2067,\n",
              "   2083,\n",
              "   2119,\n",
              "   2120,\n",
              "   2126,\n",
              "   2127,\n",
              "   2136,\n",
              "   2142,\n",
              "   2148,\n",
              "   2156,\n",
              "   2206,\n",
              "   2219,\n",
              "   2228,\n",
              "   2249,\n",
              "   2257,\n",
              "   2262,\n",
              "   2278,\n",
              "   2282,\n",
              "   2306,\n",
              "   2310,\n",
              "   2315,\n",
              "   2318,\n",
              "   2328,\n",
              "   2330,\n",
              "   2351,\n",
              "   2377,\n",
              "   2387,\n",
              "   2388,\n",
              "   2396,\n",
              "   2404,\n",
              "   2418,\n",
              "   2421,\n",
              "   2426,\n",
              "   2427,\n",
              "   2435,\n",
              "   2445,\n",
              "   2465,\n",
              "   2469,\n",
              "   2470,\n",
              "   2477,\n",
              "   2487,\n",
              "   2490,\n",
              "   2495,\n",
              "   2580,\n",
              "   2583,\n",
              "   2591,\n",
              "   2629,\n",
              "   2636,\n",
              "   2648,\n",
              "   2664,\n",
              "   2679,\n",
              "   2695,\n",
              "   2705,\n",
              "   2738,\n",
              "   2770,\n",
              "   2783,\n",
              "   2812,\n",
              "   2816,\n",
              "   2821,\n",
              "   2833,\n",
              "   2854,\n",
              "   2867,\n",
              "   2872,\n",
              "   2885,\n",
              "   2888,\n",
              "   2896,\n",
              "   2901,\n",
              "   2946,\n",
              "   2949,\n",
              "   2962,\n",
              "   2968,\n",
              "   2976,\n",
              "   2981,\n",
              "   2982,\n",
              "   2993,\n",
              "   2997,\n",
              "   3008,\n",
              "   3049,\n",
              "   3052,\n",
              "   3075,\n",
              "   3078,\n",
              "   3086,\n",
              "   3094,\n",
              "   3102,\n",
              "   3104,\n",
              "   3121,\n",
              "   3130,\n",
              "   3135,\n",
              "   3142,\n",
              "   3144,\n",
              "   3150,\n",
              "   3152,\n",
              "   3161,\n",
              "   3163,\n",
              "   3173,\n",
              "   3181,\n",
              "   3184,\n",
              "   3190,\n",
              "   3218,\n",
              "   3220,\n",
              "   3242,\n",
              "   3248,\n",
              "   3255,\n",
              "   3283,\n",
              "   3293,\n",
              "   3320,\n",
              "   3322,\n",
              "   3355,\n",
              "   3359,\n",
              "   3374,\n",
              "   3377,\n",
              "   3388,\n",
              "   3405,\n",
              "   3416,\n",
              "   3424,\n",
              "   3434,\n",
              "   3439,\n",
              "   3443,\n",
              "   3457,\n",
              "   3462,\n",
              "   3479,\n",
              "   3482,\n",
              "   3492,\n",
              "   3494,\n",
              "   3503,\n",
              "   3522,\n",
              "   3531,\n",
              "   3538,\n",
              "   3539,\n",
              "   3567,\n",
              "   3570,\n",
              "   3602,\n",
              "   3605,\n",
              "   3613,\n",
              "   3634,\n",
              "   3653,\n",
              "   3666,\n",
              "   3670,\n",
              "   3679,\n",
              "   3684,\n",
              "   3687,\n",
              "   3696,\n",
              "   3700,\n",
              "   3731,\n",
              "   3741,\n",
              "   3753,\n",
              "   3761,\n",
              "   3779,\n",
              "   3783,\n",
              "   3793,\n",
              "   3809,\n",
              "   3815,\n",
              "   3819,\n",
              "   3825,\n",
              "   3832,\n",
              "   3842,\n",
              "   3850,\n",
              "   3852,\n",
              "   3870,\n",
              "   3871,\n",
              "   3874,\n",
              "   3898,\n",
              "   3906,\n",
              "   3915,\n",
              "   3922,\n",
              "   3923,\n",
              "   3926,\n",
              "   3950,\n",
              "   3954,\n",
              "   3960,\n",
              "   3983,\n",
              "   3992,\n",
              "   3998,\n",
              "   4001,\n",
              "   4008,\n",
              "   4016,\n",
              "   4034,\n",
              "   4043,\n",
              "   4063,\n",
              "   4065,\n",
              "   4066,\n",
              "   4073,\n",
              "   4084,\n",
              "   4110,\n",
              "   4112,\n",
              "   4127,\n",
              "   4137,\n",
              "   4153,\n",
              "   4155,\n",
              "   4204,\n",
              "   4207,\n",
              "   4209,\n",
              "   4216,\n",
              "   4219,\n",
              "   4236,\n",
              "   4259,\n",
              "   4274,\n",
              "   4280,\n",
              "   4282,\n",
              "   4288,\n",
              "   4294,\n",
              "   4303,\n",
              "   4308,\n",
              "   4313,\n",
              "   4319,\n",
              "   4340,\n",
              "   4352,\n",
              "   4361,\n",
              "   4367,\n",
              "   4374,\n",
              "   4384,\n",
              "   4388,\n",
              "   4390,\n",
              "   4419,\n",
              "   4423,\n",
              "   4441,\n",
              "   4471,\n",
              "   4485,\n",
              "   4489,\n",
              "   4502,\n",
              "   4511,\n",
              "   4516,\n",
              "   4553,\n",
              "   4586,\n",
              "   4603,\n",
              "   4606,\n",
              "   4618,\n",
              "   4624,\n",
              "   4631,\n",
              "   4638,\n",
              "   4648,\n",
              "   4663,\n",
              "   4677,\n",
              "   4710,\n",
              "   4711,\n",
              "   4721,\n",
              "   4736,\n",
              "   4761,\n",
              "   4767,\n",
              "   4776,\n",
              "   4800,\n",
              "   4804,\n",
              "   4807,\n",
              "   4816,\n",
              "   4819,\n",
              "   4836,\n",
              "   4848,\n",
              "   4864,\n",
              "   4882,\n",
              "   4902,\n",
              "   4917,\n",
              "   4921,\n",
              "   4954,\n",
              "   4987,\n",
              "   4989,\n",
              "   4997,\n",
              "   4999,\n",
              "   5002,\n",
              "   5007,\n",
              "   5008,\n",
              "   5030,\n",
              "   5063,\n",
              "   5069,\n",
              "   5072,\n",
              "   5082,\n",
              "   5087,\n",
              "   5096,\n",
              "   5114,\n",
              "   5116,\n",
              "   5122,\n",
              "   5141,\n",
              "   5149,\n",
              "   5150,\n",
              "   5159,\n",
              "   5185,\n",
              "   5192,\n",
              "   5194,\n",
              "   5195,\n",
              "   5218,\n",
              "   5220,\n",
              "   5232,\n",
              "   5233,\n",
              "   5243,\n",
              "   5245],\n",
              "  [89,\n",
              "   91,\n",
              "   98,\n",
              "   604,\n",
              "   652,\n",
              "   668,\n",
              "   806,\n",
              "   823,\n",
              "   867,\n",
              "   938,\n",
              "   1119,\n",
              "   1168,\n",
              "   1210,\n",
              "   1211,\n",
              "   1220,\n",
              "   1232,\n",
              "   1243,\n",
              "   1304,\n",
              "   1305,\n",
              "   1309,\n",
              "   1330,\n",
              "   1336,\n",
              "   1345,\n",
              "   1391,\n",
              "   1402,\n",
              "   1425,\n",
              "   1441,\n",
              "   1547,\n",
              "   1557,\n",
              "   1692,\n",
              "   1854,\n",
              "   1857,\n",
              "   1885,\n",
              "   1912,\n",
              "   2000,\n",
              "   2272,\n",
              "   2276,\n",
              "   2302,\n",
              "   2455,\n",
              "   2509,\n",
              "   2518,\n",
              "   2599,\n",
              "   2609,\n",
              "   2613,\n",
              "   2735,\n",
              "   2875,\n",
              "   2908,\n",
              "   3020,\n",
              "   3126,\n",
              "   3212,\n",
              "   3229,\n",
              "   3253,\n",
              "   3315,\n",
              "   3342,\n",
              "   3432,\n",
              "   3592,\n",
              "   3651,\n",
              "   3674,\n",
              "   3690,\n",
              "   3703,\n",
              "   3714,\n",
              "   3830,\n",
              "   3911,\n",
              "   3943,\n",
              "   3973,\n",
              "   4025,\n",
              "   4050,\n",
              "   4105,\n",
              "   4134,\n",
              "   4212,\n",
              "   4290,\n",
              "   4297,\n",
              "   4311,\n",
              "   4327,\n",
              "   4358,\n",
              "   4407,\n",
              "   4437,\n",
              "   4451,\n",
              "   4452,\n",
              "   4538,\n",
              "   4556,\n",
              "   4718,\n",
              "   4814,\n",
              "   4823,\n",
              "   4871,\n",
              "   4885,\n",
              "   4905,\n",
              "   4941,\n",
              "   4948,\n",
              "   5006,\n",
              "   5015,\n",
              "   5023,\n",
              "   5031,\n",
              "   5080,\n",
              "   5107,\n",
              "   5124,\n",
              "   5156,\n",
              "   5165,\n",
              "   5197,\n",
              "   5201,\n",
              "   5224,\n",
              "   5225]],\n",
              " 'f': [[110,\n",
              "   111,\n",
              "   112,\n",
              "   114,\n",
              "   116,\n",
              "   117,\n",
              "   118,\n",
              "   119,\n",
              "   120,\n",
              "   593,\n",
              "   998,\n",
              "   1204,\n",
              "   1253,\n",
              "   1276,\n",
              "   1716,\n",
              "   1799,\n",
              "   1997,\n",
              "   2383,\n",
              "   2552,\n",
              "   2723,\n",
              "   2751,\n",
              "   2778,\n",
              "   2796,\n",
              "   2963,\n",
              "   3080,\n",
              "   3201,\n",
              "   3366,\n",
              "   3526,\n",
              "   3693,\n",
              "   3698,\n",
              "   3699,\n",
              "   3789,\n",
              "   3868,\n",
              "   3869,\n",
              "   3919,\n",
              "   3985,\n",
              "   4036,\n",
              "   4221,\n",
              "   4285,\n",
              "   4464,\n",
              "   4597,\n",
              "   4649,\n",
              "   5119],\n",
              "  [113, 115, 741, 906, 1254, 1395, 3213, 4123, 4473, 4529, 4893]],\n",
              " 'g': [[133,\n",
              "   134,\n",
              "   135,\n",
              "   137,\n",
              "   138,\n",
              "   139,\n",
              "   140,\n",
              "   141,\n",
              "   628,\n",
              "   700,\n",
              "   728,\n",
              "   734,\n",
              "   738,\n",
              "   783,\n",
              "   834,\n",
              "   846,\n",
              "   860,\n",
              "   893,\n",
              "   897,\n",
              "   915,\n",
              "   951,\n",
              "   964,\n",
              "   973,\n",
              "   983,\n",
              "   1021,\n",
              "   1033,\n",
              "   1041,\n",
              "   1059,\n",
              "   1064,\n",
              "   1154,\n",
              "   1196,\n",
              "   1244,\n",
              "   1269,\n",
              "   1279,\n",
              "   1500,\n",
              "   1616,\n",
              "   1729,\n",
              "   1868,\n",
              "   1923,\n",
              "   2022,\n",
              "   2080,\n",
              "   2130,\n",
              "   2190,\n",
              "   2365,\n",
              "   2428,\n",
              "   2473,\n",
              "   2586,\n",
              "   2789,\n",
              "   2956,\n",
              "   2978,\n",
              "   3032,\n",
              "   3051,\n",
              "   3132,\n",
              "   3210,\n",
              "   3221,\n",
              "   3226,\n",
              "   3264,\n",
              "   3288,\n",
              "   3433,\n",
              "   3440,\n",
              "   3455,\n",
              "   3480,\n",
              "   3536,\n",
              "   3968,\n",
              "   4002,\n",
              "   4060,\n",
              "   4179,\n",
              "   4255,\n",
              "   4357,\n",
              "   4436,\n",
              "   4510,\n",
              "   4523,\n",
              "   4545,\n",
              "   4569,\n",
              "   4590,\n",
              "   4596,\n",
              "   4630,\n",
              "   4637,\n",
              "   4656,\n",
              "   4668,\n",
              "   4678,\n",
              "   4689,\n",
              "   4691,\n",
              "   4712,\n",
              "   4714,\n",
              "   4828,\n",
              "   4922,\n",
              "   5256],\n",
              "  [132,\n",
              "   136,\n",
              "   142,\n",
              "   601,\n",
              "   621,\n",
              "   749,\n",
              "   1003,\n",
              "   1079,\n",
              "   1388,\n",
              "   1648,\n",
              "   2524,\n",
              "   3162,\n",
              "   3261,\n",
              "   3282,\n",
              "   3327,\n",
              "   3740,\n",
              "   3751,\n",
              "   3827,\n",
              "   3964,\n",
              "   4048,\n",
              "   4623,\n",
              "   5088]],\n",
              " 'h': [[154,\n",
              "   155,\n",
              "   156,\n",
              "   157,\n",
              "   158,\n",
              "   159,\n",
              "   160,\n",
              "   161,\n",
              "   162,\n",
              "   164,\n",
              "   610,\n",
              "   641,\n",
              "   660,\n",
              "   683,\n",
              "   761,\n",
              "   774,\n",
              "   858,\n",
              "   872,\n",
              "   917,\n",
              "   931,\n",
              "   945,\n",
              "   952,\n",
              "   1012,\n",
              "   1032,\n",
              "   1108,\n",
              "   1189,\n",
              "   1215,\n",
              "   1216,\n",
              "   1237,\n",
              "   1249,\n",
              "   1263,\n",
              "   1271,\n",
              "   1286,\n",
              "   1287,\n",
              "   1370,\n",
              "   1373,\n",
              "   1383,\n",
              "   1503,\n",
              "   1531,\n",
              "   1594,\n",
              "   1631,\n",
              "   1646,\n",
              "   1686,\n",
              "   1701,\n",
              "   1704,\n",
              "   1884,\n",
              "   1913,\n",
              "   1919,\n",
              "   1935,\n",
              "   1988,\n",
              "   1991,\n",
              "   1999,\n",
              "   2028,\n",
              "   2046,\n",
              "   2065,\n",
              "   2106,\n",
              "   2122,\n",
              "   2238,\n",
              "   2275,\n",
              "   2301,\n",
              "   2334,\n",
              "   2362,\n",
              "   2366,\n",
              "   2453,\n",
              "   2505,\n",
              "   2635,\n",
              "   2641,\n",
              "   2668,\n",
              "   2684,\n",
              "   2689,\n",
              "   2726,\n",
              "   2748,\n",
              "   2806,\n",
              "   2813,\n",
              "   2829,\n",
              "   2841,\n",
              "   2855,\n",
              "   2882,\n",
              "   2887,\n",
              "   2961,\n",
              "   3019,\n",
              "   3039,\n",
              "   3120,\n",
              "   3172,\n",
              "   3194,\n",
              "   3252,\n",
              "   3319,\n",
              "   3364,\n",
              "   3472,\n",
              "   3497,\n",
              "   3502,\n",
              "   3545,\n",
              "   3558,\n",
              "   3597,\n",
              "   3669,\n",
              "   3695,\n",
              "   3744,\n",
              "   3778,\n",
              "   3794,\n",
              "   3814,\n",
              "   3841,\n",
              "   3872,\n",
              "   3910,\n",
              "   3921,\n",
              "   3949,\n",
              "   3962,\n",
              "   3969,\n",
              "   3972,\n",
              "   3988,\n",
              "   4053,\n",
              "   4062,\n",
              "   4157,\n",
              "   4186,\n",
              "   4291,\n",
              "   4343,\n",
              "   4404,\n",
              "   4406,\n",
              "   4422,\n",
              "   4453,\n",
              "   4476,\n",
              "   4483,\n",
              "   4518,\n",
              "   4551,\n",
              "   4634,\n",
              "   4661,\n",
              "   4686,\n",
              "   4857,\n",
              "   4861,\n",
              "   4879,\n",
              "   4906,\n",
              "   5081,\n",
              "   5121,\n",
              "   5131,\n",
              "   5133],\n",
              "  [163,\n",
              "   630,\n",
              "   670,\n",
              "   675,\n",
              "   702,\n",
              "   744,\n",
              "   908,\n",
              "   977,\n",
              "   1000,\n",
              "   1004,\n",
              "   1272,\n",
              "   1298,\n",
              "   1589,\n",
              "   1649,\n",
              "   1677,\n",
              "   1754,\n",
              "   2012,\n",
              "   2259,\n",
              "   2271,\n",
              "   2378,\n",
              "   2601,\n",
              "   2874,\n",
              "   3123,\n",
              "   3217,\n",
              "   3235,\n",
              "   3274,\n",
              "   3595,\n",
              "   3965,\n",
              "   4017,\n",
              "   4273,\n",
              "   4440,\n",
              "   4681,\n",
              "   4884,\n",
              "   5106]],\n",
              " 'i': [[176,\n",
              "   177,\n",
              "   178,\n",
              "   179,\n",
              "   180,\n",
              "   182,\n",
              "   184,\n",
              "   186,\n",
              "   613,\n",
              "   615,\n",
              "   626,\n",
              "   644,\n",
              "   659,\n",
              "   703,\n",
              "   740,\n",
              "   751,\n",
              "   762,\n",
              "   781,\n",
              "   818,\n",
              "   848,\n",
              "   891,\n",
              "   899,\n",
              "   910,\n",
              "   922,\n",
              "   923,\n",
              "   940,\n",
              "   943,\n",
              "   950,\n",
              "   960,\n",
              "   963,\n",
              "   979,\n",
              "   981,\n",
              "   993,\n",
              "   1037,\n",
              "   1039,\n",
              "   1100,\n",
              "   1104,\n",
              "   1107,\n",
              "   1117,\n",
              "   1120,\n",
              "   1143,\n",
              "   1152,\n",
              "   1183,\n",
              "   1224,\n",
              "   1233,\n",
              "   1239,\n",
              "   1240,\n",
              "   1267,\n",
              "   1289,\n",
              "   1324,\n",
              "   1334,\n",
              "   1358,\n",
              "   1406,\n",
              "   1423,\n",
              "   1427,\n",
              "   1434,\n",
              "   1442,\n",
              "   1443,\n",
              "   1444,\n",
              "   1455,\n",
              "   1509,\n",
              "   1510,\n",
              "   1588,\n",
              "   1603,\n",
              "   1606,\n",
              "   1703,\n",
              "   1733,\n",
              "   1743,\n",
              "   1773,\n",
              "   1794,\n",
              "   1797,\n",
              "   1806,\n",
              "   1822,\n",
              "   1852,\n",
              "   1867,\n",
              "   1910,\n",
              "   1933,\n",
              "   1946,\n",
              "   1948,\n",
              "   1959,\n",
              "   1969,\n",
              "   2007,\n",
              "   2023,\n",
              "   2024,\n",
              "   2033,\n",
              "   2075,\n",
              "   2081,\n",
              "   2098,\n",
              "   2101,\n",
              "   2115,\n",
              "   2145,\n",
              "   2167,\n",
              "   2179,\n",
              "   2180,\n",
              "   2199,\n",
              "   2200,\n",
              "   2202,\n",
              "   2284,\n",
              "   2304,\n",
              "   2321,\n",
              "   2341,\n",
              "   2357,\n",
              "   2369,\n",
              "   2374,\n",
              "   2442,\n",
              "   2463,\n",
              "   2516,\n",
              "   2534,\n",
              "   2551,\n",
              "   2559,\n",
              "   2595,\n",
              "   2626,\n",
              "   2694,\n",
              "   2706,\n",
              "   2734,\n",
              "   2755,\n",
              "   2758,\n",
              "   2769,\n",
              "   2782,\n",
              "   2805,\n",
              "   2836,\n",
              "   2838,\n",
              "   2842,\n",
              "   2938,\n",
              "   2941,\n",
              "   2954,\n",
              "   2990,\n",
              "   3037,\n",
              "   3066,\n",
              "   3069,\n",
              "   3148,\n",
              "   3166,\n",
              "   3208,\n",
              "   3224,\n",
              "   3259,\n",
              "   3280,\n",
              "   3292,\n",
              "   3325,\n",
              "   3361,\n",
              "   3381,\n",
              "   3391,\n",
              "   3400,\n",
              "   3408,\n",
              "   3428,\n",
              "   3446,\n",
              "   3456,\n",
              "   3460,\n",
              "   3508,\n",
              "   3516,\n",
              "   3587,\n",
              "   3599,\n",
              "   3645,\n",
              "   3671,\n",
              "   3676,\n",
              "   3717,\n",
              "   3738,\n",
              "   3747,\n",
              "   3749,\n",
              "   3769,\n",
              "   3771,\n",
              "   3786,\n",
              "   3797,\n",
              "   3799,\n",
              "   3803,\n",
              "   3824,\n",
              "   3828,\n",
              "   3837,\n",
              "   3849,\n",
              "   3876,\n",
              "   3892,\n",
              "   3893,\n",
              "   3936,\n",
              "   3959,\n",
              "   3963,\n",
              "   3967,\n",
              "   3974,\n",
              "   3987,\n",
              "   3990,\n",
              "   4004,\n",
              "   4014,\n",
              "   4027,\n",
              "   4039,\n",
              "   4058,\n",
              "   4080,\n",
              "   4086,\n",
              "   4144,\n",
              "   4151,\n",
              "   4165,\n",
              "   4181,\n",
              "   4188,\n",
              "   4196,\n",
              "   4234,\n",
              "   4238,\n",
              "   4247,\n",
              "   4253,\n",
              "   4261,\n",
              "   4264,\n",
              "   4266,\n",
              "   4309,\n",
              "   4344,\n",
              "   4346,\n",
              "   4371,\n",
              "   4394,\n",
              "   4402,\n",
              "   4408,\n",
              "   4416,\n",
              "   4418,\n",
              "   4536,\n",
              "   4537,\n",
              "   4547,\n",
              "   4567,\n",
              "   4570,\n",
              "   4577,\n",
              "   4588,\n",
              "   4595,\n",
              "   4629,\n",
              "   4644,\n",
              "   4670,\n",
              "   4696,\n",
              "   4698,\n",
              "   4713,\n",
              "   4724,\n",
              "   4739,\n",
              "   4741,\n",
              "   4749,\n",
              "   4773,\n",
              "   4839,\n",
              "   4840,\n",
              "   4897,\n",
              "   4919,\n",
              "   5000,\n",
              "   5033,\n",
              "   5067,\n",
              "   5099,\n",
              "   5110,\n",
              "   5118,\n",
              "   5143,\n",
              "   5190,\n",
              "   5199,\n",
              "   5228],\n",
              "  [181,\n",
              "   183,\n",
              "   185,\n",
              "   736,\n",
              "   877,\n",
              "   879,\n",
              "   949,\n",
              "   1093,\n",
              "   1105,\n",
              "   1106,\n",
              "   1245,\n",
              "   1300,\n",
              "   1348,\n",
              "   1502,\n",
              "   1512,\n",
              "   1515,\n",
              "   1530,\n",
              "   1678,\n",
              "   1809,\n",
              "   1838,\n",
              "   1941,\n",
              "   1967,\n",
              "   2014,\n",
              "   2048,\n",
              "   2052,\n",
              "   2153,\n",
              "   2178,\n",
              "   2230,\n",
              "   2554,\n",
              "   2624,\n",
              "   2712,\n",
              "   2862,\n",
              "   2979,\n",
              "   3107,\n",
              "   3133,\n",
              "   3177,\n",
              "   3204,\n",
              "   3286,\n",
              "   3367,\n",
              "   3418,\n",
              "   3767,\n",
              "   4046,\n",
              "   4056,\n",
              "   4114,\n",
              "   4116,\n",
              "   4132,\n",
              "   4176,\n",
              "   4243,\n",
              "   4277,\n",
              "   4321,\n",
              "   4355,\n",
              "   4614,\n",
              "   4627,\n",
              "   4728,\n",
              "   4770,\n",
              "   4780,\n",
              "   4817,\n",
              "   4849,\n",
              "   5004,\n",
              "   5012,\n",
              "   5129]],\n",
              " 'j': [[199, 200, 201, 202, 203, 204, 205, 206, 208, 4147], [198, 207, 711]],\n",
              " 'k': [[220,\n",
              "   221,\n",
              "   222,\n",
              "   223,\n",
              "   225,\n",
              "   226,\n",
              "   227,\n",
              "   228,\n",
              "   229,\n",
              "   672,\n",
              "   747,\n",
              "   978,\n",
              "   1299,\n",
              "   2114,\n",
              "   2236,\n",
              "   2317,\n",
              "   2430,\n",
              "   2496,\n",
              "   2581,\n",
              "   2590,\n",
              "   2593,\n",
              "   2676,\n",
              "   2890,\n",
              "   3044,\n",
              "   3197,\n",
              "   3269,\n",
              "   3664,\n",
              "   3853,\n",
              "   3942,\n",
              "   4295,\n",
              "   4619,\n",
              "   5035],\n",
              "  [224, 947, 1316, 1742, 2293, 2656, 2662, 4431]],\n",
              " 'l': [[241,\n",
              "   242,\n",
              "   243,\n",
              "   244,\n",
              "   245,\n",
              "   246,\n",
              "   247,\n",
              "   248,\n",
              "   249,\n",
              "   250,\n",
              "   251,\n",
              "   665,\n",
              "   667,\n",
              "   690,\n",
              "   748,\n",
              "   753,\n",
              "   956,\n",
              "   965,\n",
              "   966,\n",
              "   967,\n",
              "   990,\n",
              "   991,\n",
              "   1027,\n",
              "   1103,\n",
              "   1195,\n",
              "   1320,\n",
              "   1414,\n",
              "   1432,\n",
              "   1517,\n",
              "   1539,\n",
              "   1564,\n",
              "   1592,\n",
              "   1595,\n",
              "   1681,\n",
              "   1693,\n",
              "   1939,\n",
              "   2020,\n",
              "   2111,\n",
              "   2132,\n",
              "   2169,\n",
              "   2175,\n",
              "   2192,\n",
              "   2205,\n",
              "   2216,\n",
              "   2220,\n",
              "   2266,\n",
              "   2326,\n",
              "   2327,\n",
              "   2384,\n",
              "   2392,\n",
              "   2438,\n",
              "   2462,\n",
              "   2486,\n",
              "   2672,\n",
              "   2732,\n",
              "   2745,\n",
              "   2788,\n",
              "   2892,\n",
              "   2893,\n",
              "   2906,\n",
              "   2950,\n",
              "   2958,\n",
              "   3003,\n",
              "   3007,\n",
              "   3024,\n",
              "   3048,\n",
              "   3108,\n",
              "   3140,\n",
              "   3346,\n",
              "   3401,\n",
              "   3404,\n",
              "   3470,\n",
              "   3490,\n",
              "   3560,\n",
              "   3630,\n",
              "   3659,\n",
              "   3665,\n",
              "   3718,\n",
              "   3759,\n",
              "   3770,\n",
              "   3788,\n",
              "   3798,\n",
              "   3881,\n",
              "   3917,\n",
              "   3924,\n",
              "   3928,\n",
              "   3938,\n",
              "   3966,\n",
              "   4040,\n",
              "   4078,\n",
              "   4171,\n",
              "   4177,\n",
              "   4182,\n",
              "   4190,\n",
              "   4251,\n",
              "   4257,\n",
              "   4270,\n",
              "   4322,\n",
              "   4359,\n",
              "   4387,\n",
              "   4434,\n",
              "   4442,\n",
              "   4446,\n",
              "   4478,\n",
              "   4521,\n",
              "   4591,\n",
              "   4727,\n",
              "   4738,\n",
              "   4771,\n",
              "   4827,\n",
              "   4831,\n",
              "   4868,\n",
              "   4939,\n",
              "   5066,\n",
              "   5128,\n",
              "   5260],\n",
              "  [596,\n",
              "   600,\n",
              "   758,\n",
              "   759,\n",
              "   1054,\n",
              "   1337,\n",
              "   1544,\n",
              "   1745,\n",
              "   2056,\n",
              "   2198,\n",
              "   2246,\n",
              "   2741,\n",
              "   2886,\n",
              "   2907,\n",
              "   2959,\n",
              "   3004,\n",
              "   3160,\n",
              "   3708,\n",
              "   3835,\n",
              "   3857,\n",
              "   4000,\n",
              "   4125,\n",
              "   4168,\n",
              "   4194,\n",
              "   4443,\n",
              "   4459,\n",
              "   4734,\n",
              "   4802,\n",
              "   4935]],\n",
              " 'm': [[262,\n",
              "   263,\n",
              "   264,\n",
              "   265,\n",
              "   267,\n",
              "   268,\n",
              "   269,\n",
              "   270,\n",
              "   271,\n",
              "   635,\n",
              "   686,\n",
              "   718,\n",
              "   742,\n",
              "   870,\n",
              "   1031,\n",
              "   1096,\n",
              "   1111,\n",
              "   1113,\n",
              "   1122,\n",
              "   1124,\n",
              "   1206,\n",
              "   1255,\n",
              "   1315,\n",
              "   1367,\n",
              "   1382,\n",
              "   1433,\n",
              "   1655,\n",
              "   1726,\n",
              "   1786,\n",
              "   1791,\n",
              "   1813,\n",
              "   2043,\n",
              "   2240,\n",
              "   2285,\n",
              "   2305,\n",
              "   2359,\n",
              "   2382,\n",
              "   2436,\n",
              "   2456,\n",
              "   2467,\n",
              "   2479,\n",
              "   2500,\n",
              "   2507,\n",
              "   2529,\n",
              "   2530,\n",
              "   2589,\n",
              "   2611,\n",
              "   2615,\n",
              "   2616,\n",
              "   2736,\n",
              "   2795,\n",
              "   2835,\n",
              "   2845,\n",
              "   2848,\n",
              "   2864,\n",
              "   2870,\n",
              "   2905,\n",
              "   2937,\n",
              "   2953,\n",
              "   3058,\n",
              "   3065,\n",
              "   3099,\n",
              "   3128,\n",
              "   3182,\n",
              "   3211,\n",
              "   3393,\n",
              "   3437,\n",
              "   3461,\n",
              "   3481,\n",
              "   3493,\n",
              "   3528,\n",
              "   3529,\n",
              "   3537,\n",
              "   3589,\n",
              "   3590,\n",
              "   3636,\n",
              "   3637,\n",
              "   3673,\n",
              "   3742,\n",
              "   3975,\n",
              "   4038,\n",
              "   4070,\n",
              "   4111,\n",
              "   4120,\n",
              "   4154,\n",
              "   4399,\n",
              "   4400,\n",
              "   4412,\n",
              "   4413,\n",
              "   4957,\n",
              "   4959,\n",
              "   4960,\n",
              "   4961,\n",
              "   4962,\n",
              "   4964,\n",
              "   4965,\n",
              "   4973,\n",
              "   4974,\n",
              "   5039,\n",
              "   5046,\n",
              "   5064,\n",
              "   5246,\n",
              "   5248,\n",
              "   5249,\n",
              "   5257,\n",
              "   5262,\n",
              "   5263],\n",
              "  [266,\n",
              "   624,\n",
              "   651,\n",
              "   827,\n",
              "   954,\n",
              "   972,\n",
              "   1161,\n",
              "   1171,\n",
              "   1356,\n",
              "   1952,\n",
              "   2218,\n",
              "   2241,\n",
              "   2254,\n",
              "   2288,\n",
              "   2592,\n",
              "   2728,\n",
              "   2771,\n",
              "   2902,\n",
              "   3232,\n",
              "   3289,\n",
              "   3672,\n",
              "   3845,\n",
              "   3846,\n",
              "   4051,\n",
              "   4175,\n",
              "   4289,\n",
              "   5239]],\n",
              " 'n': [[284,\n",
              "   285,\n",
              "   286,\n",
              "   287,\n",
              "   289,\n",
              "   290,\n",
              "   291,\n",
              "   293,\n",
              "   598,\n",
              "   602,\n",
              "   616,\n",
              "   619,\n",
              "   638,\n",
              "   645,\n",
              "   647,\n",
              "   656,\n",
              "   688,\n",
              "   694,\n",
              "   704,\n",
              "   707,\n",
              "   720,\n",
              "   729,\n",
              "   732,\n",
              "   735,\n",
              "   775,\n",
              "   782,\n",
              "   802,\n",
              "   810,\n",
              "   813,\n",
              "   817,\n",
              "   829,\n",
              "   839,\n",
              "   847,\n",
              "   881,\n",
              "   892,\n",
              "   898,\n",
              "   902,\n",
              "   913,\n",
              "   946,\n",
              "   948,\n",
              "   955,\n",
              "   971,\n",
              "   1022,\n",
              "   1028,\n",
              "   1034,\n",
              "   1040,\n",
              "   1047,\n",
              "   1053,\n",
              "   1058,\n",
              "   1061,\n",
              "   1101,\n",
              "   1121,\n",
              "   1123,\n",
              "   1151,\n",
              "   1160,\n",
              "   1208,\n",
              "   1234,\n",
              "   1327,\n",
              "   1328,\n",
              "   1333,\n",
              "   1361,\n",
              "   1374,\n",
              "   1392,\n",
              "   1405,\n",
              "   1412,\n",
              "   1428,\n",
              "   1440,\n",
              "   1446,\n",
              "   1452,\n",
              "   1514,\n",
              "   1522,\n",
              "   1534,\n",
              "   1548,\n",
              "   1556,\n",
              "   1561,\n",
              "   1583,\n",
              "   1613,\n",
              "   1700,\n",
              "   1710,\n",
              "   1714,\n",
              "   1723,\n",
              "   1728,\n",
              "   1744,\n",
              "   1755,\n",
              "   1777,\n",
              "   1816,\n",
              "   1829,\n",
              "   1833,\n",
              "   1862,\n",
              "   1863,\n",
              "   1866,\n",
              "   1879,\n",
              "   1880,\n",
              "   1905,\n",
              "   1922,\n",
              "   1925,\n",
              "   1940,\n",
              "   1956,\n",
              "   1963,\n",
              "   1975,\n",
              "   1976,\n",
              "   1983,\n",
              "   1984,\n",
              "   1994,\n",
              "   2013,\n",
              "   2034,\n",
              "   2074,\n",
              "   2095,\n",
              "   2112,\n",
              "   2117,\n",
              "   2152,\n",
              "   2221,\n",
              "   2245,\n",
              "   2247,\n",
              "   2273,\n",
              "   2299,\n",
              "   2308,\n",
              "   2340,\n",
              "   2353,\n",
              "   2358,\n",
              "   2389,\n",
              "   2390,\n",
              "   2394,\n",
              "   2441,\n",
              "   2458,\n",
              "   2464,\n",
              "   2474,\n",
              "   2483,\n",
              "   2494,\n",
              "   2517,\n",
              "   2523,\n",
              "   2533,\n",
              "   2553,\n",
              "   2558,\n",
              "   2603,\n",
              "   2628,\n",
              "   2650,\n",
              "   2692,\n",
              "   2702,\n",
              "   2707,\n",
              "   2714,\n",
              "   2717,\n",
              "   2727,\n",
              "   2746,\n",
              "   2756,\n",
              "   2759,\n",
              "   2760,\n",
              "   2764,\n",
              "   2767,\n",
              "   2775,\n",
              "   2804,\n",
              "   2834,\n",
              "   2851,\n",
              "   2878,\n",
              "   2881,\n",
              "   2943,\n",
              "   2947,\n",
              "   2955,\n",
              "   2977,\n",
              "   2980,\n",
              "   2992,\n",
              "   2996,\n",
              "   3000,\n",
              "   3009,\n",
              "   3016,\n",
              "   3030,\n",
              "   3045,\n",
              "   3059,\n",
              "   3071,\n",
              "   3079,\n",
              "   3083,\n",
              "   3084,\n",
              "   3112,\n",
              "   3118,\n",
              "   3125,\n",
              "   3136,\n",
              "   3154,\n",
              "   3175,\n",
              "   3178,\n",
              "   3196,\n",
              "   3209,\n",
              "   3225,\n",
              "   3238,\n",
              "   3249,\n",
              "   3270,\n",
              "   3287,\n",
              "   3316,\n",
              "   3336,\n",
              "   3353,\n",
              "   3362,\n",
              "   3369,\n",
              "   3383,\n",
              "   3390,\n",
              "   3395,\n",
              "   3410,\n",
              "   3419,\n",
              "   3430,\n",
              "   3453,\n",
              "   3458,\n",
              "   3469,\n",
              "   3483,\n",
              "   3517,\n",
              "   3540,\n",
              "   3574,\n",
              "   3582,\n",
              "   3588,\n",
              "   3598,\n",
              "   3625,\n",
              "   3643,\n",
              "   3649,\n",
              "   3654,\n",
              "   3658,\n",
              "   3682,\n",
              "   3688,\n",
              "   3701,\n",
              "   3726,\n",
              "   3729,\n",
              "   3739,\n",
              "   3750,\n",
              "   3765,\n",
              "   3775,\n",
              "   3784,\n",
              "   3805,\n",
              "   3812,\n",
              "   3831,\n",
              "   3838,\n",
              "   3839,\n",
              "   3888,\n",
              "   3894,\n",
              "   3946,\n",
              "   3981,\n",
              "   3986,\n",
              "   4003,\n",
              "   4013,\n",
              "   4059,\n",
              "   4093,\n",
              "   4102,\n",
              "   4117,\n",
              "   4146,\n",
              "   4180,\n",
              "   4184,\n",
              "   4187,\n",
              "   4206,\n",
              "   4218,\n",
              "   4222,\n",
              "   4245,\n",
              "   4254,\n",
              "   4262,\n",
              "   4275,\n",
              "   4279,\n",
              "   4331,\n",
              "   4333,\n",
              "   4339,\n",
              "   4347,\n",
              "   4356,\n",
              "   4375,\n",
              "   4376,\n",
              "   4380,\n",
              "   4383,\n",
              "   4395,\n",
              "   4415,\n",
              "   4432,\n",
              "   4448,\n",
              "   4456,\n",
              "   4460,\n",
              "   4480,\n",
              "   4494,\n",
              "   4501,\n",
              "   4506,\n",
              "   4513,\n",
              "   4519,\n",
              "   4527,\n",
              "   4546,\n",
              "   4552,\n",
              "   4568,\n",
              "   4571,\n",
              "   4579,\n",
              "   4581,\n",
              "   4589,\n",
              "   4594,\n",
              "   4608,\n",
              "   4620,\n",
              "   4636,\n",
              "   4651,\n",
              "   4669,\n",
              "   4679,\n",
              "   4688,\n",
              "   4690,\n",
              "   4694,\n",
              "   4700,\n",
              "   4703,\n",
              "   4716,\n",
              "   4735,\n",
              "   4751,\n",
              "   4758,\n",
              "   4766,\n",
              "   4774,\n",
              "   4779,\n",
              "   4791,\n",
              "   4810,\n",
              "   4825,\n",
              "   4852,\n",
              "   4875,\n",
              "   4913,\n",
              "   4926,\n",
              "   4947,\n",
              "   4949,\n",
              "   4994,\n",
              "   5048,\n",
              "   5093,\n",
              "   5100,\n",
              "   5140,\n",
              "   5144,\n",
              "   5178,\n",
              "   5184,\n",
              "   5193,\n",
              "   5221,\n",
              "   5264],\n",
              "  [283,\n",
              "   288,\n",
              "   292,\n",
              "   627,\n",
              "   699,\n",
              "   709,\n",
              "   750,\n",
              "   752,\n",
              "   780,\n",
              "   819,\n",
              "   844,\n",
              "   889,\n",
              "   890,\n",
              "   980,\n",
              "   982,\n",
              "   988,\n",
              "   1153,\n",
              "   1164,\n",
              "   1199,\n",
              "   1268,\n",
              "   1293,\n",
              "   1323,\n",
              "   1342,\n",
              "   1362,\n",
              "   1501,\n",
              "   1513,\n",
              "   1566,\n",
              "   1653,\n",
              "   1807,\n",
              "   1810,\n",
              "   1817,\n",
              "   1901,\n",
              "   1906,\n",
              "   1966,\n",
              "   2059,\n",
              "   2062,\n",
              "   2227,\n",
              "   2281,\n",
              "   2381,\n",
              "   2510,\n",
              "   2537,\n",
              "   2571,\n",
              "   2693,\n",
              "   2700,\n",
              "   2839,\n",
              "   2869,\n",
              "   2998,\n",
              "   3127,\n",
              "   3174,\n",
              "   3205,\n",
              "   3260,\n",
              "   3326,\n",
              "   3435,\n",
              "   3635,\n",
              "   3641,\n",
              "   3736,\n",
              "   3757,\n",
              "   3891,\n",
              "   4047,\n",
              "   4064,\n",
              "   4129,\n",
              "   4248,\n",
              "   4305,\n",
              "   4369,\n",
              "   4549,\n",
              "   4572,\n",
              "   4660,\n",
              "   4666,\n",
              "   4805,\n",
              "   4845,\n",
              "   4888,\n",
              "   4918,\n",
              "   4927,\n",
              "   4988,\n",
              "   5086,\n",
              "   5136,\n",
              "   5151,\n",
              "   5198,\n",
              "   5212,\n",
              "   5223]],\n",
              " 'o': [[305,\n",
              "   306,\n",
              "   308,\n",
              "   310,\n",
              "   311,\n",
              "   312,\n",
              "   314,\n",
              "   606,\n",
              "   623,\n",
              "   634,\n",
              "   637,\n",
              "   674,\n",
              "   698,\n",
              "   725,\n",
              "   733,\n",
              "   737,\n",
              "   755,\n",
              "   807,\n",
              "   816,\n",
              "   830,\n",
              "   831,\n",
              "   843,\n",
              "   855,\n",
              "   896,\n",
              "   924,\n",
              "   928,\n",
              "   934,\n",
              "   959,\n",
              "   969,\n",
              "   1001,\n",
              "   1009,\n",
              "   1077,\n",
              "   1086,\n",
              "   1118,\n",
              "   1158,\n",
              "   1184,\n",
              "   1205,\n",
              "   1231,\n",
              "   1235,\n",
              "   1236,\n",
              "   1264,\n",
              "   1302,\n",
              "   1325,\n",
              "   1326,\n",
              "   1329,\n",
              "   1340,\n",
              "   1360,\n",
              "   1389,\n",
              "   1393,\n",
              "   1394,\n",
              "   1398,\n",
              "   1416,\n",
              "   1419,\n",
              "   1430,\n",
              "   1535,\n",
              "   1540,\n",
              "   1587,\n",
              "   1617,\n",
              "   1629,\n",
              "   1647,\n",
              "   1666,\n",
              "   1696,\n",
              "   1699,\n",
              "   1708,\n",
              "   1711,\n",
              "   1752,\n",
              "   1776,\n",
              "   1812,\n",
              "   1815,\n",
              "   1830,\n",
              "   1832,\n",
              "   1840,\n",
              "   1849,\n",
              "   1861,\n",
              "   1870,\n",
              "   1878,\n",
              "   1890,\n",
              "   1904,\n",
              "   1915,\n",
              "   1928,\n",
              "   1950,\n",
              "   1961,\n",
              "   1974,\n",
              "   1996,\n",
              "   2009,\n",
              "   2035,\n",
              "   2036,\n",
              "   2040,\n",
              "   2049,\n",
              "   2055,\n",
              "   2082,\n",
              "   2099,\n",
              "   2100,\n",
              "   2116,\n",
              "   2124,\n",
              "   2133,\n",
              "   2140,\n",
              "   2144,\n",
              "   2154,\n",
              "   2166,\n",
              "   2170,\n",
              "   2171,\n",
              "   2243,\n",
              "   2260,\n",
              "   2269,\n",
              "   2294,\n",
              "   2320,\n",
              "   2336,\n",
              "   2348,\n",
              "   2355,\n",
              "   2376,\n",
              "   2395,\n",
              "   2399,\n",
              "   2407,\n",
              "   2422,\n",
              "   2433,\n",
              "   2437,\n",
              "   2443,\n",
              "   2450,\n",
              "   2457,\n",
              "   2493,\n",
              "   2512,\n",
              "   2519,\n",
              "   2532,\n",
              "   2562,\n",
              "   2570,\n",
              "   2587,\n",
              "   2606,\n",
              "   2607,\n",
              "   2612,\n",
              "   2614,\n",
              "   2627,\n",
              "   2651,\n",
              "   2655,\n",
              "   2659,\n",
              "   2703,\n",
              "   2704,\n",
              "   2713,\n",
              "   2729,\n",
              "   2754,\n",
              "   2766,\n",
              "   2774,\n",
              "   2784,\n",
              "   2798,\n",
              "   2826,\n",
              "   2830,\n",
              "   2865,\n",
              "   2868,\n",
              "   2871,\n",
              "   2894,\n",
              "   2942,\n",
              "   2952,\n",
              "   2970,\n",
              "   2973,\n",
              "   3014,\n",
              "   3022,\n",
              "   3027,\n",
              "   3034,\n",
              "   3041,\n",
              "   3055,\n",
              "   3062,\n",
              "   3070,\n",
              "   3076,\n",
              "   3081,\n",
              "   3096,\n",
              "   3100,\n",
              "   3111,\n",
              "   3117,\n",
              "   3124,\n",
              "   3139,\n",
              "   3159,\n",
              "   3179,\n",
              "   3199,\n",
              "   3202,\n",
              "   3214,\n",
              "   3237,\n",
              "   3239,\n",
              "   3245,\n",
              "   3268,\n",
              "   3329,\n",
              "   3347,\n",
              "   3348,\n",
              "   3351,\n",
              "   3372,\n",
              "   3382,\n",
              "   3396,\n",
              "   3409,\n",
              "   3413,\n",
              "   3422,\n",
              "   3447,\n",
              "   3498,\n",
              "   3511,\n",
              "   3525,\n",
              "   3532,\n",
              "   3559,\n",
              "   3572,\n",
              "   3611,\n",
              "   3616,\n",
              "   3619,\n",
              "   3626,\n",
              "   3629,\n",
              "   3633,\n",
              "   3640,\n",
              "   3655,\n",
              "   3657,\n",
              "   3692,\n",
              "   3697,\n",
              "   3710,\n",
              "   3756,\n",
              "   3764,\n",
              "   3781,\n",
              "   3804,\n",
              "   3859,\n",
              "   3862,\n",
              "   3867,\n",
              "   3879,\n",
              "   3886,\n",
              "   3890,\n",
              "   3895,\n",
              "   3901,\n",
              "   3912,\n",
              "   3918,\n",
              "   3934,\n",
              "   3940,\n",
              "   3977,\n",
              "   3984,\n",
              "   4020,\n",
              "   4031,\n",
              "   4069,\n",
              "   4082,\n",
              "   4094,\n",
              "   4121,\n",
              "   4145,\n",
              "   4158,\n",
              "   4191,\n",
              "   4192,\n",
              "   4223,\n",
              "   4227,\n",
              "   4244,\n",
              "   4256,\n",
              "   4276,\n",
              "   4286,\n",
              "   4299,\n",
              "   4325,\n",
              "   4330,\n",
              "   4370,\n",
              "   4377,\n",
              "   4386,\n",
              "   4397,\n",
              "   4411,\n",
              "   4433,\n",
              "   4449,\n",
              "   4461,\n",
              "   4465,\n",
              "   4479,\n",
              "   4482,\n",
              "   4507,\n",
              "   4522,\n",
              "   4564,\n",
              "   4565,\n",
              "   4573,\n",
              "   4578,\n",
              "   4598,\n",
              "   4621,\n",
              "   4657,\n",
              "   4659,\n",
              "   4693,\n",
              "   4725,\n",
              "   4731,\n",
              "   4750,\n",
              "   4752,\n",
              "   4753,\n",
              "   4755,\n",
              "   4769,\n",
              "   4772,\n",
              "   4775,\n",
              "   4790,\n",
              "   4793,\n",
              "   4798,\n",
              "   4833,\n",
              "   4853,\n",
              "   4862,\n",
              "   4863,\n",
              "   4890,\n",
              "   4892,\n",
              "   4899,\n",
              "   4925,\n",
              "   4936,\n",
              "   4944,\n",
              "   4993,\n",
              "   5019,\n",
              "   5022,\n",
              "   5058,\n",
              "   5075,\n",
              "   5089,\n",
              "   5102,\n",
              "   5127,\n",
              "   5132,\n",
              "   5203,\n",
              "   5205,\n",
              "   5238],\n",
              "  [304,\n",
              "   307,\n",
              "   309,\n",
              "   313,\n",
              "   650,\n",
              "   803,\n",
              "   820,\n",
              "   880,\n",
              "   887,\n",
              "   901,\n",
              "   987,\n",
              "   1046,\n",
              "   1090,\n",
              "   1091,\n",
              "   1265,\n",
              "   1291,\n",
              "   1296,\n",
              "   1353,\n",
              "   1447,\n",
              "   1453,\n",
              "   1546,\n",
              "   1567,\n",
              "   1574,\n",
              "   1630,\n",
              "   1657,\n",
              "   1746,\n",
              "   1800,\n",
              "   1897,\n",
              "   1937,\n",
              "   1957,\n",
              "   1985,\n",
              "   1989,\n",
              "   2005,\n",
              "   2019,\n",
              "   2073,\n",
              "   2280,\n",
              "   2291,\n",
              "   2342,\n",
              "   2363,\n",
              "   2535,\n",
              "   2632,\n",
              "   2686,\n",
              "   2747,\n",
              "   2763,\n",
              "   3046,\n",
              "   3271,\n",
              "   3311,\n",
              "   3375,\n",
              "   3429,\n",
              "   3487,\n",
              "   3581,\n",
              "   3593,\n",
              "   3648,\n",
              "   3681,\n",
              "   3712,\n",
              "   3790,\n",
              "   3811,\n",
              "   4071,\n",
              "   4098,\n",
              "   4140,\n",
              "   4250,\n",
              "   4444,\n",
              "   4500,\n",
              "   4520,\n",
              "   4583,\n",
              "   4699,\n",
              "   4765,\n",
              "   4834,\n",
              "   4854,\n",
              "   4880,\n",
              "   4894,\n",
              "   4946,\n",
              "   5041,\n",
              "   5045,\n",
              "   5130,\n",
              "   5188]],\n",
              " 'p': [[327,\n",
              "   328,\n",
              "   329,\n",
              "   331,\n",
              "   332,\n",
              "   333,\n",
              "   334,\n",
              "   335,\n",
              "   768,\n",
              "   871,\n",
              "   905,\n",
              "   925,\n",
              "   926,\n",
              "   1066,\n",
              "   1083,\n",
              "   1115,\n",
              "   1156,\n",
              "   1176,\n",
              "   1188,\n",
              "   1314,\n",
              "   1372,\n",
              "   1377,\n",
              "   1381,\n",
              "   1555,\n",
              "   1560,\n",
              "   1581,\n",
              "   1611,\n",
              "   1814,\n",
              "   1949,\n",
              "   2015,\n",
              "   2016,\n",
              "   2044,\n",
              "   2085,\n",
              "   2157,\n",
              "   2172,\n",
              "   2286,\n",
              "   2311,\n",
              "   2345,\n",
              "   2379,\n",
              "   2401,\n",
              "   2439,\n",
              "   2481,\n",
              "   2492,\n",
              "   2576,\n",
              "   2681,\n",
              "   2697,\n",
              "   2699,\n",
              "   2715,\n",
              "   2752,\n",
              "   2824,\n",
              "   2825,\n",
              "   2852,\n",
              "   2858,\n",
              "   3077,\n",
              "   3122,\n",
              "   3167,\n",
              "   3376,\n",
              "   3402,\n",
              "   3609,\n",
              "   3647,\n",
              "   3743,\n",
              "   3834,\n",
              "   3976,\n",
              "   4022,\n",
              "   4023,\n",
              "   4052,\n",
              "   4097,\n",
              "   4119,\n",
              "   4161,\n",
              "   4211,\n",
              "   4225,\n",
              "   4284,\n",
              "   4323,\n",
              "   4345,\n",
              "   4467,\n",
              "   4496,\n",
              "   4541,\n",
              "   4562,\n",
              "   4599,\n",
              "   4605,\n",
              "   4683,\n",
              "   4796,\n",
              "   4797,\n",
              "   4842,\n",
              "   4851,\n",
              "   4865,\n",
              "   4909,\n",
              "   4910,\n",
              "   4945,\n",
              "   5014,\n",
              "   5052,\n",
              "   5056,\n",
              "   5108,\n",
              "   5154,\n",
              "   5163,\n",
              "   5177,\n",
              "   5180,\n",
              "   5182,\n",
              "   5187,\n",
              "   5258],\n",
              "  [326,\n",
              "   330,\n",
              "   336,\n",
              "   730,\n",
              "   1067,\n",
              "   1072,\n",
              "   1319,\n",
              "   1321,\n",
              "   1498,\n",
              "   1664,\n",
              "   2068,\n",
              "   2138,\n",
              "   2265,\n",
              "   2403,\n",
              "   2482,\n",
              "   3752,\n",
              "   3763,\n",
              "   3780,\n",
              "   4335,\n",
              "   4385,\n",
              "   4533,\n",
              "   4641,\n",
              "   5078,\n",
              "   5123,\n",
              "   5240]],\n",
              " 'q': [[349,\n",
              "   350,\n",
              "   351,\n",
              "   352,\n",
              "   353,\n",
              "   354,\n",
              "   355,\n",
              "   358,\n",
              "   359,\n",
              "   1820,\n",
              "   2550,\n",
              "   2811,\n",
              "   3685,\n",
              "   4952,\n",
              "   4963,\n",
              "   4971,\n",
              "   4972,\n",
              "   5043,\n",
              "   5091,\n",
              "   5179,\n",
              "   5183,\n",
              "   5236],\n",
              "  [348, 356, 357, 1670, 4984, 5181]],\n",
              " 'r': [[371,\n",
              "   372,\n",
              "   373,\n",
              "   374,\n",
              "   375,\n",
              "   376,\n",
              "   378,\n",
              "   379,\n",
              "   382,\n",
              "   591,\n",
              "   642,\n",
              "   673,\n",
              "   715,\n",
              "   779,\n",
              "   805,\n",
              "   815,\n",
              "   824,\n",
              "   849,\n",
              "   854,\n",
              "   866,\n",
              "   918,\n",
              "   927,\n",
              "   984,\n",
              "   1023,\n",
              "   1043,\n",
              "   1099,\n",
              "   1146,\n",
              "   1169,\n",
              "   1180,\n",
              "   1209,\n",
              "   1213,\n",
              "   1218,\n",
              "   1223,\n",
              "   1247,\n",
              "   1308,\n",
              "   1344,\n",
              "   1347,\n",
              "   1411,\n",
              "   1506,\n",
              "   1524,\n",
              "   1527,\n",
              "   1601,\n",
              "   1627,\n",
              "   1634,\n",
              "   1641,\n",
              "   1644,\n",
              "   1667,\n",
              "   1689,\n",
              "   1737,\n",
              "   1784,\n",
              "   1795,\n",
              "   1839,\n",
              "   1842,\n",
              "   1848,\n",
              "   1853,\n",
              "   1869,\n",
              "   1895,\n",
              "   1927,\n",
              "   1930,\n",
              "   1942,\n",
              "   1960,\n",
              "   1970,\n",
              "   1990,\n",
              "   2001,\n",
              "   2031,\n",
              "   2042,\n",
              "   2078,\n",
              "   2104,\n",
              "   2182,\n",
              "   2224,\n",
              "   2261,\n",
              "   2268,\n",
              "   2277,\n",
              "   2287,\n",
              "   2290,\n",
              "   2314,\n",
              "   2323,\n",
              "   2347,\n",
              "   2370,\n",
              "   2375,\n",
              "   2400,\n",
              "   2405,\n",
              "   2408,\n",
              "   2460,\n",
              "   2594,\n",
              "   2654,\n",
              "   2660,\n",
              "   2669,\n",
              "   2682,\n",
              "   2688,\n",
              "   2797,\n",
              "   2815,\n",
              "   2967,\n",
              "   2974,\n",
              "   2983,\n",
              "   2986,\n",
              "   3013,\n",
              "   3033,\n",
              "   3043,\n",
              "   3057,\n",
              "   3074,\n",
              "   3082,\n",
              "   3087,\n",
              "   3098,\n",
              "   3101,\n",
              "   3131,\n",
              "   3169,\n",
              "   3188,\n",
              "   3203,\n",
              "   3215,\n",
              "   3230,\n",
              "   3241,\n",
              "   3291,\n",
              "   3308,\n",
              "   3331,\n",
              "   3334,\n",
              "   3371,\n",
              "   3378,\n",
              "   3425,\n",
              "   3465,\n",
              "   3507,\n",
              "   3514,\n",
              "   3521,\n",
              "   3533,\n",
              "   3566,\n",
              "   3578,\n",
              "   3601,\n",
              "   3610,\n",
              "   3617,\n",
              "   3632,\n",
              "   3650,\n",
              "   3713,\n",
              "   3721,\n",
              "   3754,\n",
              "   3760,\n",
              "   3791,\n",
              "   3792,\n",
              "   3848,\n",
              "   3866,\n",
              "   3877,\n",
              "   3896,\n",
              "   3905,\n",
              "   3927,\n",
              "   3941,\n",
              "   3944,\n",
              "   4009,\n",
              "   4021,\n",
              "   4030,\n",
              "   4035,\n",
              "   4106,\n",
              "   4122,\n",
              "   4128,\n",
              "   4141,\n",
              "   4163,\n",
              "   4170,\n",
              "   4199,\n",
              "   4210,\n",
              "   4213,\n",
              "   4228,\n",
              "   4260,\n",
              "   4283,\n",
              "   4298,\n",
              "   4314,\n",
              "   4318,\n",
              "   4324,\n",
              "   4337,\n",
              "   4341,\n",
              "   4362,\n",
              "   4409,\n",
              "   4466,\n",
              "   4486,\n",
              "   4491,\n",
              "   4497,\n",
              "   4503,\n",
              "   4530,\n",
              "   4558,\n",
              "   4563,\n",
              "   4587,\n",
              "   4593,\n",
              "   4607,\n",
              "   4647,\n",
              "   4658,\n",
              "   4719,\n",
              "   4760,\n",
              "   4808,\n",
              "   4813,\n",
              "   4820,\n",
              "   4835,\n",
              "   4841,\n",
              "   4886,\n",
              "   4916,\n",
              "   4920,\n",
              "   4990,\n",
              "   5003,\n",
              "   5013,\n",
              "   5034,\n",
              "   5054,\n",
              "   5079,\n",
              "   5085,\n",
              "   5109,\n",
              "   5147,\n",
              "   5161,\n",
              "   5175,\n",
              "   5200,\n",
              "   5210,\n",
              "   5227,\n",
              "   5259],\n",
              "  [377,\n",
              "   380,\n",
              "   381,\n",
              "   677,\n",
              "   693,\n",
              "   722,\n",
              "   754,\n",
              "   835,\n",
              "   837,\n",
              "   920,\n",
              "   1013,\n",
              "   1295,\n",
              "   1306,\n",
              "   1624,\n",
              "   1665,\n",
              "   1801,\n",
              "   1823,\n",
              "   1835,\n",
              "   1858,\n",
              "   1874,\n",
              "   2004,\n",
              "   2201,\n",
              "   2255,\n",
              "   2349,\n",
              "   2397,\n",
              "   2417,\n",
              "   2451,\n",
              "   2856,\n",
              "   3023,\n",
              "   3088,\n",
              "   3185,\n",
              "   3290,\n",
              "   3354,\n",
              "   3444,\n",
              "   3652,\n",
              "   3732,\n",
              "   3885,\n",
              "   3899,\n",
              "   3913,\n",
              "   3978,\n",
              "   3997,\n",
              "   4090,\n",
              "   4220,\n",
              "   4302,\n",
              "   4312,\n",
              "   4351,\n",
              "   4653,\n",
              "   4708,\n",
              "   4850,\n",
              "   4933,\n",
              "   5125,\n",
              "   5252]],\n",
              " 's': [[395,\n",
              "   396,\n",
              "   397,\n",
              "   398,\n",
              "   399,\n",
              "   402,\n",
              "   403,\n",
              "   405,\n",
              "   406,\n",
              "   407,\n",
              "   614,\n",
              "   633,\n",
              "   649,\n",
              "   654,\n",
              "   676,\n",
              "   689,\n",
              "   705,\n",
              "   713,\n",
              "   743,\n",
              "   770,\n",
              "   821,\n",
              "   852,\n",
              "   863,\n",
              "   865,\n",
              "   878,\n",
              "   882,\n",
              "   941,\n",
              "   996,\n",
              "   1018,\n",
              "   1074,\n",
              "   1087,\n",
              "   1157,\n",
              "   1179,\n",
              "   1185,\n",
              "   1225,\n",
              "   1228,\n",
              "   1242,\n",
              "   1266,\n",
              "   1311,\n",
              "   1331,\n",
              "   1349,\n",
              "   1354,\n",
              "   1355,\n",
              "   1380,\n",
              "   1385,\n",
              "   1408,\n",
              "   1508,\n",
              "   1537,\n",
              "   1538,\n",
              "   1563,\n",
              "   1569,\n",
              "   1607,\n",
              "   1618,\n",
              "   1620,\n",
              "   1622,\n",
              "   1637,\n",
              "   1640,\n",
              "   1652,\n",
              "   1660,\n",
              "   1685,\n",
              "   1707,\n",
              "   1738,\n",
              "   1749,\n",
              "   1778,\n",
              "   1783,\n",
              "   1851,\n",
              "   1855,\n",
              "   1856,\n",
              "   1911,\n",
              "   1929,\n",
              "   1951,\n",
              "   1958,\n",
              "   1968,\n",
              "   2003,\n",
              "   2008,\n",
              "   2096,\n",
              "   2113,\n",
              "   2128,\n",
              "   2147,\n",
              "   2234,\n",
              "   2252,\n",
              "   2267,\n",
              "   2279,\n",
              "   2337,\n",
              "   2338,\n",
              "   2339,\n",
              "   2346,\n",
              "   2368,\n",
              "   2372,\n",
              "   2419,\n",
              "   2429,\n",
              "   2444,\n",
              "   2447,\n",
              "   2498,\n",
              "   2503,\n",
              "   2568,\n",
              "   2573,\n",
              "   2618,\n",
              "   2623,\n",
              "   2630,\n",
              "   2677,\n",
              "   2709,\n",
              "   2779,\n",
              "   2802,\n",
              "   2827,\n",
              "   2832,\n",
              "   2837,\n",
              "   2849,\n",
              "   2880,\n",
              "   2895,\n",
              "   2899,\n",
              "   2903,\n",
              "   2913,\n",
              "   2939,\n",
              "   2975,\n",
              "   2984,\n",
              "   2995,\n",
              "   3011,\n",
              "   3028,\n",
              "   3067,\n",
              "   3068,\n",
              "   3072,\n",
              "   3109,\n",
              "   3146,\n",
              "   3147,\n",
              "   3281,\n",
              "   3358,\n",
              "   3389,\n",
              "   3415,\n",
              "   3441,\n",
              "   3445,\n",
              "   3478,\n",
              "   3485,\n",
              "   3500,\n",
              "   3505,\n",
              "   3523,\n",
              "   3542,\n",
              "   3547,\n",
              "   3562,\n",
              "   3571,\n",
              "   3576,\n",
              "   3604,\n",
              "   3615,\n",
              "   3624,\n",
              "   3644,\n",
              "   3667,\n",
              "   3683,\n",
              "   3691,\n",
              "   3702,\n",
              "   3709,\n",
              "   3723,\n",
              "   3733,\n",
              "   3746,\n",
              "   3755,\n",
              "   3762,\n",
              "   3766,\n",
              "   3808,\n",
              "   3818,\n",
              "   3820,\n",
              "   3826,\n",
              "   3843,\n",
              "   3864,\n",
              "   3880,\n",
              "   3883,\n",
              "   3907,\n",
              "   3908,\n",
              "   3931,\n",
              "   3933,\n",
              "   3947,\n",
              "   3953,\n",
              "   3955,\n",
              "   3993,\n",
              "   4005,\n",
              "   4006,\n",
              "   4007,\n",
              "   4015,\n",
              "   4033,\n",
              "   4042,\n",
              "   4055,\n",
              "   4083,\n",
              "   4092,\n",
              "   4104,\n",
              "   4108,\n",
              "   4138,\n",
              "   4149,\n",
              "   4160,\n",
              "   4201,\n",
              "   4208,\n",
              "   4215,\n",
              "   4233,\n",
              "   4237,\n",
              "   4246,\n",
              "   4287,\n",
              "   4296,\n",
              "   4301,\n",
              "   4342,\n",
              "   4353,\n",
              "   4366,\n",
              "   4420,\n",
              "   4424,\n",
              "   4438,\n",
              "   4458,\n",
              "   4462,\n",
              "   4463,\n",
              "   4474,\n",
              "   4484,\n",
              "   4492,\n",
              "   4504,\n",
              "   4528,\n",
              "   4584,\n",
              "   4601,\n",
              "   4650,\n",
              "   4676,\n",
              "   4701,\n",
              "   4709,\n",
              "   4720,\n",
              "   4742,\n",
              "   4743,\n",
              "   4747,\n",
              "   4782,\n",
              "   4788,\n",
              "   4799,\n",
              "   4881,\n",
              "   4923,\n",
              "   4968,\n",
              "   5059,\n",
              "   5061,\n",
              "   5073,\n",
              "   5097,\n",
              "   5134,\n",
              "   5138,\n",
              "   5170,\n",
              "   5171,\n",
              "   5176],\n",
              "  [400,\n",
              "   401,\n",
              "   404,\n",
              "   657,\n",
              "   739,\n",
              "   760,\n",
              "   869,\n",
              "   933,\n",
              "   1191,\n",
              "   1230,\n",
              "   1241,\n",
              "   1386,\n",
              "   1518,\n",
              "   1519,\n",
              "   1541,\n",
              "   1596,\n",
              "   1661,\n",
              "   1695,\n",
              "   1719,\n",
              "   1819,\n",
              "   1932,\n",
              "   2251,\n",
              "   2361,\n",
              "   2420,\n",
              "   2466,\n",
              "   2478,\n",
              "   2491,\n",
              "   2582,\n",
              "   2597,\n",
              "   2940,\n",
              "   2991,\n",
              "   2994,\n",
              "   3332,\n",
              "   3344,\n",
              "   3467,\n",
              "   3491,\n",
              "   3535,\n",
              "   3568,\n",
              "   3569,\n",
              "   3614,\n",
              "   3623,\n",
              "   3851,\n",
              "   3961,\n",
              "   4049,\n",
              "   4135,\n",
              "   4189,\n",
              "   4271,\n",
              "   4354,\n",
              "   4368,\n",
              "   4610,\n",
              "   4756,\n",
              "   4783,\n",
              "   4803,\n",
              "   4822,\n",
              "   4895,\n",
              "   4951,\n",
              "   5017,\n",
              "   5018,\n",
              "   5071]],\n",
              " 't': [[420,\n",
              "   421,\n",
              "   422,\n",
              "   424,\n",
              "   426,\n",
              "   427,\n",
              "   428,\n",
              "   430,\n",
              "   431,\n",
              "   592,\n",
              "   599,\n",
              "   612,\n",
              "   632,\n",
              "   666,\n",
              "   669,\n",
              "   681,\n",
              "   682,\n",
              "   701,\n",
              "   714,\n",
              "   723,\n",
              "   763,\n",
              "   766,\n",
              "   809,\n",
              "   841,\n",
              "   853,\n",
              "   859,\n",
              "   884,\n",
              "   900,\n",
              "   909,\n",
              "   935,\n",
              "   986,\n",
              "   1005,\n",
              "   1017,\n",
              "   1035,\n",
              "   1042,\n",
              "   1060,\n",
              "   1078,\n",
              "   1081,\n",
              "   1095,\n",
              "   1109,\n",
              "   1140,\n",
              "   1144,\n",
              "   1170,\n",
              "   1273,\n",
              "   1274,\n",
              "   1275,\n",
              "   1280,\n",
              "   1281,\n",
              "   1283,\n",
              "   1285,\n",
              "   1317,\n",
              "   1350,\n",
              "   1384,\n",
              "   1387,\n",
              "   1396,\n",
              "   1400,\n",
              "   1448,\n",
              "   1450,\n",
              "   1575,\n",
              "   1590,\n",
              "   1593,\n",
              "   1623,\n",
              "   1638,\n",
              "   1639,\n",
              "   1650,\n",
              "   1668,\n",
              "   1676,\n",
              "   1690,\n",
              "   1712,\n",
              "   1735,\n",
              "   1818,\n",
              "   1850,\n",
              "   1882,\n",
              "   1883,\n",
              "   1889,\n",
              "   1909,\n",
              "   1916,\n",
              "   1936,\n",
              "   1938,\n",
              "   1943,\n",
              "   1947,\n",
              "   1981,\n",
              "   2010,\n",
              "   2011,\n",
              "   2017,\n",
              "   2018,\n",
              "   2047,\n",
              "   2050,\n",
              "   2051,\n",
              "   2066,\n",
              "   2129,\n",
              "   2149,\n",
              "   2177,\n",
              "   2181,\n",
              "   2203,\n",
              "   2237,\n",
              "   2253,\n",
              "   2258,\n",
              "   2263,\n",
              "   2270,\n",
              "   2274,\n",
              "   2283,\n",
              "   2292,\n",
              "   2297,\n",
              "   2300,\n",
              "   2312,\n",
              "   2316,\n",
              "   2319,\n",
              "   2332,\n",
              "   2333,\n",
              "   2335,\n",
              "   2352,\n",
              "   2364,\n",
              "   2371,\n",
              "   2380,\n",
              "   2423,\n",
              "   2440,\n",
              "   2449,\n",
              "   2468,\n",
              "   2501,\n",
              "   2502,\n",
              "   2506,\n",
              "   2574,\n",
              "   2598,\n",
              "   2605,\n",
              "   2625,\n",
              "   2634,\n",
              "   2696,\n",
              "   2701,\n",
              "   2708,\n",
              "   2711,\n",
              "   2722,\n",
              "   2730,\n",
              "   2733,\n",
              "   2757,\n",
              "   2768,\n",
              "   2791,\n",
              "   2792,\n",
              "   2793,\n",
              "   2801,\n",
              "   2817,\n",
              "   2818,\n",
              "   2840,\n",
              "   2853,\n",
              "   2860,\n",
              "   2866,\n",
              "   2883,\n",
              "   2884,\n",
              "   2889,\n",
              "   2960,\n",
              "   2965,\n",
              "   3005,\n",
              "   3018,\n",
              "   3026,\n",
              "   3038,\n",
              "   3054,\n",
              "   3093,\n",
              "   3105,\n",
              "   3113,\n",
              "   3116,\n",
              "   3119,\n",
              "   3149,\n",
              "   3187,\n",
              "   3207,\n",
              "   3216,\n",
              "   3244,\n",
              "   3247,\n",
              "   3267,\n",
              "   3273,\n",
              "   3276,\n",
              "   3284,\n",
              "   3285,\n",
              "   3310,\n",
              "   3314,\n",
              "   3318,\n",
              "   3356,\n",
              "   3373,\n",
              "   3398,\n",
              "   3403,\n",
              "   3427,\n",
              "   3436,\n",
              "   3442,\n",
              "   3449,\n",
              "   3459,\n",
              "   3484,\n",
              "   3486,\n",
              "   3488,\n",
              "   3501,\n",
              "   3506,\n",
              "   3510,\n",
              "   3527,\n",
              "   3541,\n",
              "   3580,\n",
              "   3585,\n",
              "   3618,\n",
              "   3627,\n",
              "   3656,\n",
              "   3661,\n",
              "   3668,\n",
              "   3678,\n",
              "   3694,\n",
              "   3706,\n",
              "   3711,\n",
              "   3734,\n",
              "   3772,\n",
              "   3782,\n",
              "   3785,\n",
              "   3800,\n",
              "   3802,\n",
              "   3813,\n",
              "   3821,\n",
              "   3840,\n",
              "   3855,\n",
              "   3865,\n",
              "   3875,\n",
              "   3900,\n",
              "   3909,\n",
              "   3920,\n",
              "   3956,\n",
              "   3970,\n",
              "   3971,\n",
              "   3979,\n",
              "   3989,\n",
              "   4028,\n",
              "   4032,\n",
              "   4044,\n",
              "   4061,\n",
              "   4068,\n",
              "   4087,\n",
              "   4115,\n",
              "   4126,\n",
              "   4131,\n",
              "   4139,\n",
              "   4143,\n",
              "   4156,\n",
              "   4164,\n",
              "   4193,\n",
              "   4205,\n",
              "   4239,\n",
              "   4292,\n",
              "   4316,\n",
              "   4320,\n",
              "   4326,\n",
              "   4338,\n",
              "   4372,\n",
              "   4393,\n",
              "   4405,\n",
              "   4417,\n",
              "   4425,\n",
              "   4439,\n",
              "   4445,\n",
              "   4450,\n",
              "   4454,\n",
              "   4525,\n",
              "   4540,\n",
              "   4566,\n",
              "   4576,\n",
              "   4585,\n",
              "   4602,\n",
              "   4615,\n",
              "   4617,\n",
              "   4654,\n",
              "   4684,\n",
              "   4697,\n",
              "   4717,\n",
              "   4723,\n",
              "   4729,\n",
              "   4740,\n",
              "   4745,\n",
              "   4832,\n",
              "   4838,\n",
              "   4883,\n",
              "   4896,\n",
              "   4907,\n",
              "   4908,\n",
              "   4950,\n",
              "   4992,\n",
              "   5009,\n",
              "   5029,\n",
              "   5062,\n",
              "   5074,\n",
              "   5083,\n",
              "   5090,\n",
              "   5104,\n",
              "   5105,\n",
              "   5113,\n",
              "   5120,\n",
              "   5164,\n",
              "   5242,\n",
              "   5244],\n",
              "  [423,\n",
              "   425,\n",
              "   429,\n",
              "   629,\n",
              "   710,\n",
              "   745,\n",
              "   842,\n",
              "   862,\n",
              "   999,\n",
              "   1020,\n",
              "   1045,\n",
              "   1052,\n",
              "   1227,\n",
              "   1250,\n",
              "   1251,\n",
              "   1282,\n",
              "   1409,\n",
              "   1439,\n",
              "   1545,\n",
              "   1562,\n",
              "   1572,\n",
              "   1621,\n",
              "   1709,\n",
              "   1781,\n",
              "   1798,\n",
              "   1914,\n",
              "   1998,\n",
              "   2006,\n",
              "   2037,\n",
              "   2121,\n",
              "   2191,\n",
              "   2235,\n",
              "   2303,\n",
              "   2393,\n",
              "   2485,\n",
              "   2578,\n",
              "   2671,\n",
              "   2716,\n",
              "   2765,\n",
              "   2781,\n",
              "   2828,\n",
              "   2972,\n",
              "   3010,\n",
              "   3060,\n",
              "   3251,\n",
              "   3313,\n",
              "   3365,\n",
              "   3380,\n",
              "   3466,\n",
              "   3473,\n",
              "   3515,\n",
              "   3720,\n",
              "   3724,\n",
              "   3777,\n",
              "   3873,\n",
              "   4045,\n",
              "   4091,\n",
              "   4096,\n",
              "   4150,\n",
              "   4242,\n",
              "   4278,\n",
              "   4329,\n",
              "   4382,\n",
              "   4403,\n",
              "   4645,\n",
              "   4664,\n",
              "   4781,\n",
              "   4785,\n",
              "   4787,\n",
              "   4901,\n",
              "   4996,\n",
              "   5057,\n",
              "   5155]],\n",
              " 'u': [[443,\n",
              "   444,\n",
              "   445,\n",
              "   446,\n",
              "   447,\n",
              "   448,\n",
              "   449,\n",
              "   450,\n",
              "   451,\n",
              "   453,\n",
              "   454,\n",
              "   685,\n",
              "   712,\n",
              "   757,\n",
              "   828,\n",
              "   953,\n",
              "   1002,\n",
              "   1024,\n",
              "   1030,\n",
              "   1088,\n",
              "   1098,\n",
              "   1186,\n",
              "   1222,\n",
              "   1292,\n",
              "   1346,\n",
              "   1399,\n",
              "   1431,\n",
              "   1505,\n",
              "   1659,\n",
              "   1671,\n",
              "   1673,\n",
              "   1682,\n",
              "   1688,\n",
              "   1727,\n",
              "   1730,\n",
              "   1779,\n",
              "   1792,\n",
              "   1796,\n",
              "   1821,\n",
              "   1828,\n",
              "   1873,\n",
              "   1955,\n",
              "   1962,\n",
              "   1965,\n",
              "   2027,\n",
              "   2030,\n",
              "   2032,\n",
              "   2041,\n",
              "   2057,\n",
              "   2076,\n",
              "   2097,\n",
              "   2102,\n",
              "   2131,\n",
              "   2256,\n",
              "   2313,\n",
              "   2367,\n",
              "   2608,\n",
              "   2617,\n",
              "   2631,\n",
              "   2649,\n",
              "   2744,\n",
              "   2823,\n",
              "   2831,\n",
              "   2915,\n",
              "   2964,\n",
              "   2966,\n",
              "   2989,\n",
              "   3015,\n",
              "   3042,\n",
              "   3097,\n",
              "   3143,\n",
              "   3168,\n",
              "   3200,\n",
              "   3233,\n",
              "   3240,\n",
              "   3339,\n",
              "   3386,\n",
              "   3392,\n",
              "   3414,\n",
              "   3448,\n",
              "   3474,\n",
              "   3577,\n",
              "   3603,\n",
              "   3686,\n",
              "   3716,\n",
              "   3722,\n",
              "   3728,\n",
              "   3844,\n",
              "   3858,\n",
              "   3861,\n",
              "   3957,\n",
              "   4089,\n",
              "   4107,\n",
              "   4118,\n",
              "   4148,\n",
              "   4198,\n",
              "   4226,\n",
              "   4232,\n",
              "   4240,\n",
              "   4268,\n",
              "   4306,\n",
              "   4315,\n",
              "   4365,\n",
              "   4396,\n",
              "   4414,\n",
              "   4426,\n",
              "   4490,\n",
              "   4561,\n",
              "   4626,\n",
              "   4672,\n",
              "   4778,\n",
              "   4784,\n",
              "   4795,\n",
              "   4866,\n",
              "   4931,\n",
              "   5016,\n",
              "   5026,\n",
              "   5070,\n",
              "   5103,\n",
              "   5126,\n",
              "   5145,\n",
              "   5186,\n",
              "   5241],\n",
              "  [452,\n",
              "   607,\n",
              "   724,\n",
              "   850,\n",
              "   939,\n",
              "   1301,\n",
              "   1310,\n",
              "   1341,\n",
              "   1600,\n",
              "   1715,\n",
              "   1740,\n",
              "   2026,\n",
              "   2150,\n",
              "   2231,\n",
              "   2248,\n",
              "   2891,\n",
              "   3056,\n",
              "   3091,\n",
              "   3330,\n",
              "   3335,\n",
              "   3352,\n",
              "   3705,\n",
              "   3822,\n",
              "   3994,\n",
              "   4167,\n",
              "   4733,\n",
              "   4744,\n",
              "   4821,\n",
              "   4891,\n",
              "   5077,\n",
              "   5215]],\n",
              " 'v': [[468,\n",
              "   469,\n",
              "   470,\n",
              "   471,\n",
              "   473,\n",
              "   474,\n",
              "   475,\n",
              "   476,\n",
              "   477,\n",
              "   478,\n",
              "   962,\n",
              "   1142,\n",
              "   1182,\n",
              "   1454,\n",
              "   1604,\n",
              "   1717,\n",
              "   1918,\n",
              "   1945,\n",
              "   2064,\n",
              "   2143,\n",
              "   2165,\n",
              "   2229,\n",
              "   2425,\n",
              "   2600,\n",
              "   2873,\n",
              "   3134,\n",
              "   3180,\n",
              "   3206,\n",
              "   3228,\n",
              "   3829,\n",
              "   4026,\n",
              "   4085,\n",
              "   4113,\n",
              "   4133,\n",
              "   4235,\n",
              "   4249,\n",
              "   4252,\n",
              "   4265,\n",
              "   4281,\n",
              "   4487,\n",
              "   4574,\n",
              "   4818,\n",
              "   4837,\n",
              "   5001,\n",
              "   5027,\n",
              "   5111,\n",
              "   5191,\n",
              "   5229],\n",
              "  [467, 472, 662, 804, 3406, 4072, 4310, 4389, 4539, 4732, 5011, 5142]],\n",
              " 'w': [[492,\n",
              "   493,\n",
              "   494,\n",
              "   495,\n",
              "   497,\n",
              "   498,\n",
              "   499,\n",
              "   501,\n",
              "   502,\n",
              "   664,\n",
              "   907,\n",
              "   997,\n",
              "   1084,\n",
              "   1252,\n",
              "   1270,\n",
              "   1390,\n",
              "   1532,\n",
              "   1591,\n",
              "   1675,\n",
              "   1705,\n",
              "   1736,\n",
              "   1859,\n",
              "   1972,\n",
              "   2045,\n",
              "   2325,\n",
              "   2472,\n",
              "   2588,\n",
              "   2772,\n",
              "   2809,\n",
              "   2876,\n",
              "   2911,\n",
              "   3021,\n",
              "   3035,\n",
              "   3036,\n",
              "   3219,\n",
              "   3254,\n",
              "   3272,\n",
              "   3463,\n",
              "   3475,\n",
              "   3594,\n",
              "   3860,\n",
              "   3878,\n",
              "   3887,\n",
              "   3889,\n",
              "   3991,\n",
              "   4075,\n",
              "   4307,\n",
              "   4401,\n",
              "   4508,\n",
              "   4858,\n",
              "   5251,\n",
              "   5254],\n",
              "  [491, 496, 500, 640, 1070, 2448, 2691, 3047, 3321, 3939, 4900, 5250, 5255]],\n",
              " 'x': [[516,\n",
              "   517,\n",
              "   518,\n",
              "   519,\n",
              "   520,\n",
              "   521,\n",
              "   522,\n",
              "   525,\n",
              "   526,\n",
              "   1127,\n",
              "   1262,\n",
              "   1364,\n",
              "   1404,\n",
              "   1456,\n",
              "   1553,\n",
              "   1579,\n",
              "   1609,\n",
              "   2324,\n",
              "   2329,\n",
              "   3833,\n",
              "   4632,\n",
              "   5209],\n",
              "  [515, 523, 524, 861, 1758, 4604]],\n",
              " 'y': [[541,\n",
              "   542,\n",
              "   543,\n",
              "   545,\n",
              "   546,\n",
              "   547,\n",
              "   548,\n",
              "   549,\n",
              "   551,\n",
              "   731,\n",
              "   767,\n",
              "   864,\n",
              "   916,\n",
              "   992,\n",
              "   1049,\n",
              "   1055,\n",
              "   1116,\n",
              "   1499,\n",
              "   1571,\n",
              "   1669,\n",
              "   2188,\n",
              "   2208,\n",
              "   2480,\n",
              "   2577,\n",
              "   3040,\n",
              "   3231,\n",
              "   3454,\n",
              "   3471,\n",
              "   3530,\n",
              "   3591,\n",
              "   3608,\n",
              "   3638,\n",
              "   3660,\n",
              "   3773,\n",
              "   3929,\n",
              "   4041,\n",
              "   4077,\n",
              "   4178,\n",
              "   4293,\n",
              "   4392,\n",
              "   4428,\n",
              "   4468,\n",
              "   4524,\n",
              "   4554,\n",
              "   4646,\n",
              "   4655,\n",
              "   4730,\n",
              "   4872,\n",
              "   4911,\n",
              "   4942,\n",
              "   4955,\n",
              "   4966,\n",
              "   4981,\n",
              "   4982,\n",
              "   5055,\n",
              "   5117,\n",
              "   5153,\n",
              "   5162,\n",
              "   5168,\n",
              "   5208,\n",
              "   5219,\n",
              "   5231,\n",
              "   5253],\n",
              "  [540,\n",
              "   544,\n",
              "   550,\n",
              "   696,\n",
              "   1026,\n",
              "   1379,\n",
              "   2226,\n",
              "   2497,\n",
              "   2499,\n",
              "   2657,\n",
              "   3198,\n",
              "   3863,\n",
              "   4172,\n",
              "   4986,\n",
              "   5036,\n",
              "   5060]],\n",
              " 'z': [[567,\n",
              "   568,\n",
              "   569,\n",
              "   571,\n",
              "   572,\n",
              "   573,\n",
              "   574,\n",
              "   575,\n",
              "   577,\n",
              "   1413,\n",
              "   1415,\n",
              "   1420,\n",
              "   1445,\n",
              "   3748,\n",
              "   4057],\n",
              "  [565, 566, 570, 576]]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splitIndexes = {}\n",
        "for i in alpha:\n",
        "    xrl, xtl = train_test_split(alphaIndexes[i], test_size=0.2, random_state=42)\n",
        "    xrl1 = xrl.copy()\n",
        "    while len(xrl) < 500:\n",
        "        xrl.append(xrl1[random.randint(0, len(xrl1)-1)])\n",
        "    splitIndexes[i] = [sorted(xrl1), sorted(xtl)]\n",
        "splitIndexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "rv8PIBLNqYME"
      },
      "outputs": [],
      "source": [
        "splitIndexes = {}\n",
        "for i in alpha:\n",
        "    xrl, xtl = train_test_split(alphaIndexes[i], test_size=0.2, random_state=42)\n",
        "    # print(i, len(xrl), len(xtl), sep=\", \")\n",
        "    # times = 500//len(xrl)\n",
        "    # print(times, end=\" \")\n",
        "    xrl1 = xrl.copy()\n",
        "    # for j in range(times): xrl1.extend(xrl)\n",
        "    # print(i, len(xrl1), len(xtl), sep=\", \")\n",
        "    splitIndexes[i] = [sorted(xrl1), sorted(xtl)]\n",
        "# splitIndexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5QwhmGBRqYME"
      },
      "outputs": [],
      "source": [
        "xrl, xtl = [], []\n",
        "for i in alpha:\n",
        "    xrl.extend(splitIndexes[i][0])\n",
        "    xtl.extend(splitIndexes[i][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2iy8aRIxqYME"
      },
      "outputs": [],
      "source": [
        "# xrl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YjBWuS92qYMF"
      },
      "outputs": [],
      "source": [
        "def lettersSplit(imgList, labelList, uniqueLabels=alpha):\n",
        "    labelToIdx = {label: idx for idx, label in enumerate(uniqueLabels)}\n",
        "    numericalLabel = np.array([labelToIdx[label] for label in labelList])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    x_train, x_test, y_train, y_test = [imgList[i] for i in xrl], [imgList[i] for i in xtl], [numericalLabel[i] for i in xrl], [numericalLabel[i] for i in xtl]\n",
        "\n",
        "    # Normalize the image data (scale pixel values to range [0, 1])\n",
        "    x_train = np.array(x_train) / 255.0\n",
        "    x_test = np.array(x_test) / 255.0\n",
        "\n",
        "    # Convert labels to categorical (one-hot encoding)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(uniqueLabels))\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(uniqueLabels))\n",
        "    x_train = np.expand_dims(x_train, axis=-1)  # (num_samples, height, width, 1)\n",
        "    x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "    # Set input shape based on your image data (e.g., (height, width, channels))\n",
        "    input_shape = x_train.shape[1:]  # Height, Width, Channels\n",
        "    return input_shape, x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EThmfUd6qYMG"
      },
      "outputs": [],
      "source": [
        "unique_labels = sorted(list(set(label_list)))  # Get unique classes\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "input_shape1, x_train_1, x_test_1, y_train_1, y_test_1 = lettersSplit(image_list1, label_list, unique_labels)\n",
        "input_shape2, x_train_2, x_test_2, y_train_2, y_test_2 = lettersSplit(image_list2, label_list, unique_labels)\n",
        "input_shape3, x_train_3, x_test_3, y_train_3, y_test_3 = lettersSplit(image_list3, label_list, unique_labels)\n",
        "input_shape4, x_train_4, x_test_4, y_train_4, y_test_4 = lettersSplit(image_list4, label_list, unique_labels)\n",
        "input_shape5, x_train_5, x_test_5, y_train_5, y_test_5 = lettersSplit(image_list5, label_list, unique_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IoL5BoleduVI",
        "outputId": "fb57dff2-75fd-4874-a8ee-73ff3539c54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 32, 2, 32, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 32, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 32, 0, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 64, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 64, 0, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 32, 2, 128, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 32, 2, 128, 0, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 32, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 32, 0, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 64, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 64, 0, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 2, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 2, 128, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 32, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 32, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 32, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 32, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 64, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 64, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 64, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 64, 0, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 128, 2, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 128, 2, 0, 0, 128, 64, 52],\n",
              " [1, 64, 2, 128, 0, 128, 0, 0, 0, 64, 64, 52],\n",
              " [1, 64, 2, 128, 0, 128, 0, 0, 0, 128, 64, 52]]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnnparams = [\n",
        "    [32, 64], # conv2d\n",
        "    [2], # pool\n",
        "    [32, 64, 128], # conv2d\n",
        "    [2, 0], # pool\n",
        "    [32, 64, 128], # conv2d\n",
        "    [2, 0], # pool\n",
        "    [0], # flatten\n",
        "    [0], # concat\n",
        "    [64, 128], # dense\n",
        "    [64], # dense\n",
        "    [num_classes] # dense\n",
        "]\n",
        "# actiparams = [\n",
        "#     [activations.relu, activations.leaky_relu],\n",
        "#     [],\n",
        "#     [activations.relu, activations.leaky_relu],\n",
        "#     [],\n",
        "#     [activations.relu, activations.leaky_relu],\n",
        "#     [],\n",
        "#     [],\n",
        "#     [],\n",
        "#     [activations.relu, activations.leaky_relu],\n",
        "#     [activations.relu, activations.leaky_relu],\n",
        "#     [activations.softmax]\n",
        "# ]\n",
        "params = [1]\n",
        "# print(params)\n",
        "for i in range(len(cnnparams)):\n",
        "    # if i in [0, 2, 4]:\n",
        "    #     subparams = list(itertools.product(cnnparams[i], actiparams[i]))\n",
        "    #     subparam = []\n",
        "    #     for a in subparams:\n",
        "    #         subparam.append(list(a))\n",
        "    #     # print(len(subparam), subparam)\n",
        "    # else:\n",
        "    subparam = cnnparams[i]\n",
        "    params = list(itertools.product(params, subparam))\n",
        "    params = [list(x) for x in params]\n",
        "    # print('params', params)\n",
        "    newa = []\n",
        "    if type(params[0][0]) == list:\n",
        "        for a in params:\n",
        "            newa.append([])\n",
        "            for b in a[0]:\n",
        "                newa[-1].append(b)\n",
        "            newa[-1].append(a[1])\n",
        "        params = newa\n",
        "    # print('params', params)\n",
        "print(len(params))\n",
        "params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cJsDUtDQlmYW"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "def cnnTraining(input_shape, params):\n",
        "    # First convolutional layer\n",
        "    x = layers.Conv2D(params[1], (3,3), activation = 'tanh')(input_shape)\n",
        "    x = layers.MaxPooling2D((params[2],params[2]))(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = layers.Conv2D(params[3],(3, 3), activation = 'tanh')(x)\n",
        "    if params[4] != 0:\n",
        "        x = layers.MaxPooling2D((params[4],params[4]))(x)\n",
        "\n",
        "    # Third convolutional layer\n",
        "    x = layers.Conv2D(params[5], (3,3), activation='tanh')(x)\n",
        "    if params[6] != 0:\n",
        "        x = layers.MaxPooling2D((params[6],params[6]))(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = layers.Flatten()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XP5bc-3ImRvZ"
      },
      "outputs": [],
      "source": [
        "def model_create_train(params, inputs):\n",
        "    # Create the model\n",
        "    cnn1 = cnnTraining(inputs[0], params)\n",
        "    cnn2 = cnnTraining(inputs[1], params)\n",
        "    cnn3 = cnnTraining(inputs[2], params)\n",
        "    cnn4 = cnnTraining(inputs[3], params)\n",
        "    cnn5 = cnnTraining(inputs[4], params)\n",
        "    concatenated = layers.Concatenate()([cnn1, cnn2, cnn3, cnn4, cnn5])\n",
        "    x = layers.Dense(params[9], activation = 'relu')(concatenated)\n",
        "    x = layers.Dense(params[10], activation='relu')(x)\n",
        "    output = layers.Dense(params[11], activation='softmax')(x)\n",
        "    model = Model(inputs=[inputs[0], inputs[1], inputs[2], inputs[3], inputs[4]], outputs = output)\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "    history = model.fit([x_train_1, x_train_2, x_train_3, x_train_4, x_train_5], [y_train_1, y_train_2, y_train_3, y_train_4, y_train_5], epochs = 20, batch_size=32, validation_data=([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5]))\n",
        "    test_loss, test_acc = model.evaluate([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5])\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    return test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "usERC173l8AU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.1642 - loss: 3.1292 - val_accuracy: 0.4419 - val_loss: 1.9540\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4999 - loss: 1.7131 - val_accuracy: 0.5779 - val_loss: 1.4192\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6859 - loss: 1.0749 - val_accuracy: 0.6261 - val_loss: 1.1769\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7547 - loss: 0.7703 - val_accuracy: 0.6689 - val_loss: 1.0945\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8307 - loss: 0.5260 - val_accuracy: 0.6875 - val_loss: 1.0268\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8927 - loss: 0.3542 - val_accuracy: 0.6974 - val_loss: 1.1316\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9480 - loss: 0.2056 - val_accuracy: 0.6941 - val_loss: 1.1084\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9729 - loss: 0.1275 - val_accuracy: 0.7116 - val_loss: 1.1021\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9937 - loss: 0.0576 - val_accuracy: 0.7204 - val_loss: 1.1681\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9982 - loss: 0.0322 - val_accuracy: 0.7325 - val_loss: 1.1344\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 0.0145 - val_accuracy: 0.7379 - val_loss: 1.1609\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.7456 - val_loss: 1.1841\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7390 - val_loss: 1.2131\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7489 - val_loss: 1.2306\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7533 - val_loss: 1.2482\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7434 - val_loss: 1.2633\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7456 - val_loss: 1.2791\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7434 - val_loss: 1.2918\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7434 - val_loss: 1.3094\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7489 - val_loss: 1.3236\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7615 - loss: 1.2213\n",
            "Test accuracy: 0.7489035129547119\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.1789 - loss: 3.0595 - val_accuracy: 0.4759 - val_loss: 1.8201\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5253 - loss: 1.5765 - val_accuracy: 0.6129 - val_loss: 1.2533\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7243 - loss: 0.8828 - val_accuracy: 0.6765 - val_loss: 1.0372\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8334 - loss: 0.5456 - val_accuracy: 0.7138 - val_loss: 0.9291\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9013 - loss: 0.2957 - val_accuracy: 0.6941 - val_loss: 0.9427\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9524 - loss: 0.1685 - val_accuracy: 0.7445 - val_loss: 0.9258\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9846 - loss: 0.0811 - val_accuracy: 0.7412 - val_loss: 0.9888\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9975 - loss: 0.0294 - val_accuracy: 0.7401 - val_loss: 0.9627\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9979 - loss: 0.0180 - val_accuracy: 0.7456 - val_loss: 0.9845\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7555 - val_loss: 0.9827\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7555 - val_loss: 1.0072\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7544 - val_loss: 1.0204\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7566 - val_loss: 1.0284\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7599 - val_loss: 1.0373\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7566 - val_loss: 1.0531\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7566 - val_loss: 1.0674\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7544 - val_loss: 1.0795\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.3961e-04 - val_accuracy: 0.7555 - val_loss: 1.0891\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.4539e-04 - val_accuracy: 0.7544 - val_loss: 1.0928\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.8190e-04 - val_accuracy: 0.7555 - val_loss: 1.1055\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7533 - loss: 1.1128\n",
            "Test accuracy: 0.7554824352264404\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2089 - loss: 2.9728 - val_accuracy: 0.5143 - val_loss: 1.6789\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5988 - loss: 1.3160 - val_accuracy: 0.5976 - val_loss: 1.3548\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7513 - loss: 0.7711 - val_accuracy: 0.6272 - val_loss: 1.2866\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8748 - loss: 0.3949 - val_accuracy: 0.6645 - val_loss: 1.2053\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9540 - loss: 0.1728 - val_accuracy: 0.6645 - val_loss: 1.4048\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9774 - loss: 0.0873 - val_accuracy: 0.6645 - val_loss: 1.5954\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9876 - loss: 0.0593 - val_accuracy: 0.6798 - val_loss: 1.5971\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9938 - loss: 0.0296 - val_accuracy: 0.6809 - val_loss: 1.6769\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0104 - val_accuracy: 0.7050 - val_loss: 1.6600\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0036 - val_accuracy: 0.7116 - val_loss: 1.6789\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7149 - val_loss: 1.7111\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.2637e-04 - val_accuracy: 0.7116 - val_loss: 1.7307\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.1088e-04 - val_accuracy: 0.7138 - val_loss: 1.7572\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.9106e-04 - val_accuracy: 0.7149 - val_loss: 1.7748\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.9150e-04 - val_accuracy: 0.7094 - val_loss: 1.7893\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.4402e-04 - val_accuracy: 0.7116 - val_loss: 1.8081\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.8484e-04 - val_accuracy: 0.7105 - val_loss: 1.8218\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.2933e-04 - val_accuracy: 0.7105 - val_loss: 1.8418\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.9225e-04 - val_accuracy: 0.7094 - val_loss: 1.8524\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7452e-04 - val_accuracy: 0.7116 - val_loss: 1.8657\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7135 - loss: 1.8039\n",
            "Test accuracy: 0.7116228342056274\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.2230 - loss: 2.8959 - val_accuracy: 0.5154 - val_loss: 1.6602\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6200 - loss: 1.2507 - val_accuracy: 0.6436 - val_loss: 1.1452\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.7771 - loss: 0.7065 - val_accuracy: 0.6425 - val_loss: 1.1882\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8930 - loss: 0.3555 - val_accuracy: 0.6469 - val_loss: 1.2112\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9571 - loss: 0.1553 - val_accuracy: 0.6634 - val_loss: 1.3449\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9785 - loss: 0.0724 - val_accuracy: 0.6689 - val_loss: 1.5924\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9924 - loss: 0.0344 - val_accuracy: 0.6743 - val_loss: 1.5524\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9855 - loss: 0.0550 - val_accuracy: 0.6700 - val_loss: 1.6988\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9875 - loss: 0.0404 - val_accuracy: 0.6590 - val_loss: 1.7718\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9891 - loss: 0.0518 - val_accuracy: 0.6711 - val_loss: 1.7107\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9801 - loss: 0.0535 - val_accuracy: 0.6612 - val_loss: 2.0034\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9674 - loss: 0.0993 - val_accuracy: 0.6261 - val_loss: 1.9431\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9491 - loss: 0.1574 - val_accuracy: 0.6700 - val_loss: 1.8933\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9703 - loss: 0.0828 - val_accuracy: 0.6667 - val_loss: 1.9126\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9903 - loss: 0.0342 - val_accuracy: 0.6809 - val_loss: 1.8894\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6908 - val_loss: 1.8078\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9945e-04 - val_accuracy: 0.6985 - val_loss: 1.8039\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4735e-04 - val_accuracy: 0.7029 - val_loss: 1.8125\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8914e-04 - val_accuracy: 0.7039 - val_loss: 1.8215\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1661e-04 - val_accuracy: 0.7039 - val_loss: 1.8290\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7082 - loss: 1.7725\n",
            "Test accuracy: 0.7039473652839661\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.1808 - loss: 2.9851 - val_accuracy: 0.4112 - val_loss: 1.9508\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5245 - loss: 1.5737 - val_accuracy: 0.6239 - val_loss: 1.2729\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7291 - loss: 0.9060 - val_accuracy: 0.6502 - val_loss: 1.1243\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8124 - loss: 0.6173 - val_accuracy: 0.7007 - val_loss: 1.0879\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8956 - loss: 0.3774 - val_accuracy: 0.6491 - val_loss: 1.2176\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9270 - loss: 0.2462 - val_accuracy: 0.7050 - val_loss: 1.1157\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9726 - loss: 0.1063 - val_accuracy: 0.7336 - val_loss: 1.1714\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9882 - loss: 0.0629 - val_accuracy: 0.7303 - val_loss: 1.2695\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0194 - val_accuracy: 0.7489 - val_loss: 1.2618\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.7478 - val_loss: 1.2927\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7467 - val_loss: 1.3563\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7500 - val_loss: 1.3762\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7478 - val_loss: 1.3925\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7500 - val_loss: 1.4288\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7489 - val_loss: 1.4499\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7478 - val_loss: 1.4638\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7467 - val_loss: 1.4833\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.1781e-04 - val_accuracy: 0.7500 - val_loss: 1.4958\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.3097e-04 - val_accuracy: 0.7500 - val_loss: 1.5179\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.7337e-04 - val_accuracy: 0.7434 - val_loss: 1.5374\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7661 - loss: 1.4482\n",
            "Test accuracy: 0.7434210777282715\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - accuracy: 0.1883 - loss: 3.0061 - val_accuracy: 0.4934 - val_loss: 1.6740\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5909 - loss: 1.3911 - val_accuracy: 0.6316 - val_loss: 1.2009\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7572 - loss: 0.7580 - val_accuracy: 0.6546 - val_loss: 1.1730\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8537 - loss: 0.4389 - val_accuracy: 0.6798 - val_loss: 1.1157\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9318 - loss: 0.2291 - val_accuracy: 0.6754 - val_loss: 1.1793\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0825 - val_accuracy: 0.6908 - val_loss: 1.2877\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9920 - loss: 0.0442 - val_accuracy: 0.7072 - val_loss: 1.2727\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0146 - val_accuracy: 0.7336 - val_loss: 1.2300\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7325 - val_loss: 1.2776\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7357 - val_loss: 1.3006\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7368 - val_loss: 1.3171\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7390 - val_loss: 1.3462\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7368 - val_loss: 1.3557\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.1936e-04 - val_accuracy: 0.7325 - val_loss: 1.3723\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.1520e-04 - val_accuracy: 0.7357 - val_loss: 1.3938\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.6698e-04 - val_accuracy: 0.7336 - val_loss: 1.4032\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.2575e-04 - val_accuracy: 0.7368 - val_loss: 1.4212\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.2591e-04 - val_accuracy: 0.7368 - val_loss: 1.4308\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.6158e-04 - val_accuracy: 0.7368 - val_loss: 1.4448\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2686e-04 - val_accuracy: 0.7357 - val_loss: 1.4579\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7371 - loss: 1.4119\n",
            "Test accuracy: 0.7357456088066101\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.1981 - loss: 3.0627 - val_accuracy: 0.5230 - val_loss: 1.6959\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6001 - loss: 1.3476 - val_accuracy: 0.6096 - val_loss: 1.3246\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.7650 - loss: 0.7612 - val_accuracy: 0.6184 - val_loss: 1.3699\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8762 - loss: 0.4091 - val_accuracy: 0.6502 - val_loss: 1.3699\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9400 - loss: 0.1960 - val_accuracy: 0.6480 - val_loss: 1.6223\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9726 - loss: 0.0866 - val_accuracy: 0.6469 - val_loss: 1.8124\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9845 - loss: 0.0562 - val_accuracy: 0.6382 - val_loss: 2.1360\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9736 - loss: 0.0851 - val_accuracy: 0.6228 - val_loss: 2.2775\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9802 - loss: 0.0615 - val_accuracy: 0.6239 - val_loss: 2.3887\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9758 - loss: 0.0731 - val_accuracy: 0.5899 - val_loss: 2.4255\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9636 - loss: 0.1074 - val_accuracy: 0.5921 - val_loss: 2.8260\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9590 - loss: 0.1391 - val_accuracy: 0.6195 - val_loss: 2.7152\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9695 - loss: 0.0958 - val_accuracy: 0.6382 - val_loss: 2.6514\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9805 - loss: 0.0524 - val_accuracy: 0.6305 - val_loss: 2.9675\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9813 - loss: 0.0677 - val_accuracy: 0.6360 - val_loss: 2.7019\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9943 - loss: 0.0164 - val_accuracy: 0.6568 - val_loss: 2.8877\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9951 - loss: 0.0152 - val_accuracy: 0.6502 - val_loss: 2.6150\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.6678 - val_loss: 2.6706\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6776 - val_loss: 2.6180\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.5443e-04 - val_accuracy: 0.6732 - val_loss: 2.6217\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6856 - loss: 2.5034\n",
            "Test accuracy: 0.6732456088066101\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - accuracy: 0.2329 - loss: 2.9172 - val_accuracy: 0.5691 - val_loss: 1.5548\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.6644 - loss: 1.1107 - val_accuracy: 0.6524 - val_loss: 1.1994\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8373 - loss: 0.5165 - val_accuracy: 0.6436 - val_loss: 1.2598\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9440 - loss: 0.1890 - val_accuracy: 0.6645 - val_loss: 1.4135\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9723 - loss: 0.0944 - val_accuracy: 0.6612 - val_loss: 1.6401\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9833 - loss: 0.0527 - val_accuracy: 0.6765 - val_loss: 1.5674\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9844 - loss: 0.0516 - val_accuracy: 0.6349 - val_loss: 1.8408\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9702 - loss: 0.0999 - val_accuracy: 0.6875 - val_loss: 1.7101\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9824 - loss: 0.0606 - val_accuracy: 0.6721 - val_loss: 1.7850\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.6502 - val_loss: 2.2719\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9869 - loss: 0.0453 - val_accuracy: 0.6458 - val_loss: 2.1925\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9839 - loss: 0.0513 - val_accuracy: 0.6129 - val_loss: 2.6714\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9755 - loss: 0.0882 - val_accuracy: 0.6283 - val_loss: 2.3177\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9655 - loss: 0.1218 - val_accuracy: 0.5888 - val_loss: 3.0356\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9561 - loss: 0.1512 - val_accuracy: 0.6162 - val_loss: 2.5969\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9775 - loss: 0.0719 - val_accuracy: 0.6404 - val_loss: 2.5261\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9865 - loss: 0.0353 - val_accuracy: 0.6436 - val_loss: 2.7037\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9988 - loss: 0.0102 - val_accuracy: 0.6645 - val_loss: 2.3597\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.6798 - val_loss: 2.3967\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.9339e-04 - val_accuracy: 0.6853 - val_loss: 2.3697\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7044 - loss: 2.1760\n",
            "Test accuracy: 0.6853070259094238\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.1811 - loss: 3.1275 - val_accuracy: 0.4803 - val_loss: 1.7091\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5697 - loss: 1.4074 - val_accuracy: 0.6042 - val_loss: 1.2669\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.7474 - loss: 0.8261 - val_accuracy: 0.6458 - val_loss: 1.1265\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.8400 - loss: 0.5062 - val_accuracy: 0.6787 - val_loss: 1.1380\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9118 - loss: 0.2688 - val_accuracy: 0.7007 - val_loss: 1.1472\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9683 - loss: 0.1156 - val_accuracy: 0.7105 - val_loss: 1.2456\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9862 - loss: 0.0599 - val_accuracy: 0.7061 - val_loss: 1.3402\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9913 - loss: 0.0295 - val_accuracy: 0.7018 - val_loss: 1.4232\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9900 - loss: 0.0404 - val_accuracy: 0.7039 - val_loss: 1.4749\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9953 - loss: 0.0252 - val_accuracy: 0.6853 - val_loss: 1.7163\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9803 - loss: 0.0573 - val_accuracy: 0.6875 - val_loss: 1.7766\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9611 - loss: 0.1257 - val_accuracy: 0.6491 - val_loss: 1.8793\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9705 - loss: 0.0746 - val_accuracy: 0.6765 - val_loss: 1.9203\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9682 - loss: 0.1040 - val_accuracy: 0.6524 - val_loss: 2.0395\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9671 - loss: 0.0955 - val_accuracy: 0.6776 - val_loss: 1.9410\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9750 - loss: 0.0807 - val_accuracy: 0.6897 - val_loss: 1.8314\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9921 - loss: 0.0262 - val_accuracy: 0.6941 - val_loss: 1.9409\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0275 - val_accuracy: 0.7029 - val_loss: 1.8928\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.7094 - val_loss: 1.8546\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0325e-04 - val_accuracy: 0.7171 - val_loss: 1.8077\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7401 - loss: 1.8221\n",
            "Test accuracy: 0.7171052694320679\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.2312 - loss: 2.9288 - val_accuracy: 0.5252 - val_loss: 1.5488\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.6410 - loss: 1.1957 - val_accuracy: 0.6721 - val_loss: 1.0930\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.7916 - loss: 0.6514 - val_accuracy: 0.6919 - val_loss: 1.0394\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8814 - loss: 0.3670 - val_accuracy: 0.6765 - val_loss: 1.1787\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9416 - loss: 0.1900 - val_accuracy: 0.6842 - val_loss: 1.2482\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9713 - loss: 0.0960 - val_accuracy: 0.6974 - val_loss: 1.2929\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9789 - loss: 0.0716 - val_accuracy: 0.7149 - val_loss: 1.2794\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9880 - loss: 0.0415 - val_accuracy: 0.7160 - val_loss: 1.3434\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9910 - loss: 0.0265 - val_accuracy: 0.7116 - val_loss: 1.4551\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9965 - loss: 0.0130 - val_accuracy: 0.7270 - val_loss: 1.3897\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0085 - val_accuracy: 0.7237 - val_loss: 1.6035\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9973 - loss: 0.0121 - val_accuracy: 0.7029 - val_loss: 1.5653\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9745 - loss: 0.1056 - val_accuracy: 0.6645 - val_loss: 1.7779\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9049 - loss: 0.2940 - val_accuracy: 0.6711 - val_loss: 1.7159\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9753 - loss: 0.0706 - val_accuracy: 0.7116 - val_loss: 1.5787\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9899 - loss: 0.0278 - val_accuracy: 0.7116 - val_loss: 1.6991\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9979 - loss: 0.0092 - val_accuracy: 0.7292 - val_loss: 1.6030\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7292 - val_loss: 1.6177\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.2015e-04 - val_accuracy: 0.7379 - val_loss: 1.6305\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.1973e-04 - val_accuracy: 0.7412 - val_loss: 1.6375\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7568 - loss: 1.6169\n",
            "Test accuracy: 0.7412280440330505\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.2251 - loss: 3.0923 - val_accuracy: 0.5099 - val_loss: 1.5800\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6511 - loss: 1.1825 - val_accuracy: 0.6316 - val_loss: 1.2646\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.8311 - loss: 0.5712 - val_accuracy: 0.6086 - val_loss: 1.3194\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9106 - loss: 0.2724 - val_accuracy: 0.6414 - val_loss: 1.4110\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9749 - loss: 0.0971 - val_accuracy: 0.6469 - val_loss: 1.6416\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9815 - loss: 0.0612 - val_accuracy: 0.6513 - val_loss: 1.6446\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9896 - loss: 0.0374 - val_accuracy: 0.6645 - val_loss: 1.8663\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9910 - loss: 0.0278 - val_accuracy: 0.6535 - val_loss: 2.0060\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9935 - loss: 0.0196 - val_accuracy: 0.6436 - val_loss: 2.4028\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9557 - loss: 0.1464 - val_accuracy: 0.5965 - val_loss: 2.1947\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9122 - loss: 0.2862 - val_accuracy: 0.5866 - val_loss: 2.1354\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9672 - loss: 0.1051 - val_accuracy: 0.6447 - val_loss: 2.4563\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9868 - loss: 0.0338 - val_accuracy: 0.6404 - val_loss: 2.3746\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9923 - loss: 0.0202 - val_accuracy: 0.6623 - val_loss: 2.5574\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.6765 - val_loss: 2.5878\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9981 - loss: 0.0048 - val_accuracy: 0.6590 - val_loss: 2.7120\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6721 - val_loss: 2.5777\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.3619e-04 - val_accuracy: 0.6721 - val_loss: 2.5860\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.3227e-04 - val_accuracy: 0.6711 - val_loss: 2.5980\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.2413e-04 - val_accuracy: 0.6743 - val_loss: 2.6092\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6954 - loss: 2.5204\n",
            "Test accuracy: 0.6743420958518982\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 77ms/step - accuracy: 0.2558 - loss: 2.8090 - val_accuracy: 0.5241 - val_loss: 1.4883\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.6945 - loss: 1.0135 - val_accuracy: 0.5921 - val_loss: 1.3230\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.8590 - loss: 0.4424 - val_accuracy: 0.6206 - val_loss: 1.4982\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9478 - loss: 0.1493 - val_accuracy: 0.6502 - val_loss: 1.7502\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9709 - loss: 0.0903 - val_accuracy: 0.6338 - val_loss: 1.7900\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9651 - loss: 0.1096 - val_accuracy: 0.6206 - val_loss: 2.0189\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9558 - loss: 0.1183 - val_accuracy: 0.6261 - val_loss: 2.1641\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9773 - loss: 0.0718 - val_accuracy: 0.6371 - val_loss: 2.0737\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9783 - loss: 0.0717 - val_accuracy: 0.6327 - val_loss: 2.1708\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9837 - loss: 0.0563 - val_accuracy: 0.6217 - val_loss: 2.4832\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9787 - loss: 0.0565 - val_accuracy: 0.6053 - val_loss: 2.8695\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9727 - loss: 0.0869 - val_accuracy: 0.5789 - val_loss: 3.0288\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9764 - loss: 0.0915 - val_accuracy: 0.5943 - val_loss: 3.1534\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9729 - loss: 0.0947 - val_accuracy: 0.6228 - val_loss: 3.0171\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9788 - loss: 0.0774 - val_accuracy: 0.5800 - val_loss: 3.6426\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9713 - loss: 0.1014 - val_accuracy: 0.6425 - val_loss: 3.4027\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9828 - loss: 0.0548 - val_accuracy: 0.6217 - val_loss: 3.1765\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9817 - loss: 0.0685 - val_accuracy: 0.5965 - val_loss: 3.8364\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9677 - loss: 0.1342 - val_accuracy: 0.5866 - val_loss: 3.6060\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9557 - loss: 0.1814 - val_accuracy: 0.6086 - val_loss: 3.0654\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6354 - loss: 2.8432\n",
            "Test accuracy: 0.6085526347160339\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.2306 - loss: 2.8863 - val_accuracy: 0.5241 - val_loss: 1.6596\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.6030 - loss: 1.2797 - val_accuracy: 0.5844 - val_loss: 1.3428\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.8045 - loss: 0.6309 - val_accuracy: 0.6173 - val_loss: 1.3317\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.9246 - loss: 0.2782 - val_accuracy: 0.6491 - val_loss: 1.4266\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9713 - loss: 0.1081 - val_accuracy: 0.6404 - val_loss: 1.4944\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9931 - loss: 0.0358 - val_accuracy: 0.6524 - val_loss: 1.5376\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.9984 - loss: 0.0186 - val_accuracy: 0.6798 - val_loss: 1.5424\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6875 - val_loss: 1.5752\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6875 - val_loss: 1.5985\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6908 - val_loss: 1.6182\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6919 - val_loss: 1.6472\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.2055e-04 - val_accuracy: 0.6908 - val_loss: 1.6625\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.4698e-04 - val_accuracy: 0.6908 - val_loss: 1.6805\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.4968e-04 - val_accuracy: 0.6919 - val_loss: 1.7002\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 5.2783e-04 - val_accuracy: 0.6930 - val_loss: 1.7169\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.8858e-04 - val_accuracy: 0.6930 - val_loss: 1.7301\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.1271e-04 - val_accuracy: 0.6941 - val_loss: 1.7469\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.8291e-04 - val_accuracy: 0.6941 - val_loss: 1.7578\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.4555e-04 - val_accuracy: 0.6908 - val_loss: 1.7746\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.2149e-04 - val_accuracy: 0.6930 - val_loss: 1.7858\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7223 - loss: 1.6005\n",
            "Test accuracy: 0.6929824352264404\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.2519 - loss: 2.7721 - val_accuracy: 0.5636 - val_loss: 1.4845\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6880 - loss: 1.0295 - val_accuracy: 0.6261 - val_loss: 1.2678\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8631 - loss: 0.4641 - val_accuracy: 0.6513 - val_loss: 1.3795\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9476 - loss: 0.1856 - val_accuracy: 0.6502 - val_loss: 1.4827\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9876 - loss: 0.0499 - val_accuracy: 0.6820 - val_loss: 1.4850\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9953 - loss: 0.0246 - val_accuracy: 0.6864 - val_loss: 1.5623\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9995 - loss: 0.0089 - val_accuracy: 0.7007 - val_loss: 1.5264\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6908 - val_loss: 1.5607\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.4907e-04 - val_accuracy: 0.6974 - val_loss: 1.5965\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.0371e-04 - val_accuracy: 0.6985 - val_loss: 1.6170\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.4679e-04 - val_accuracy: 0.6996 - val_loss: 1.6304\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.6193e-04 - val_accuracy: 0.6996 - val_loss: 1.6518\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.9366e-04 - val_accuracy: 0.7039 - val_loss: 1.6637\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.4525e-04 - val_accuracy: 0.7007 - val_loss: 1.6819\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.0959e-04 - val_accuracy: 0.7018 - val_loss: 1.6939\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.7237e-04 - val_accuracy: 0.7018 - val_loss: 1.7070\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.4608e-04 - val_accuracy: 0.7018 - val_loss: 1.7219\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.1006e-04 - val_accuracy: 0.7018 - val_loss: 1.7363\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8070e-04 - val_accuracy: 0.7007 - val_loss: 1.7461\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.7502e-04 - val_accuracy: 0.7007 - val_loss: 1.7588\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7145 - loss: 1.6261\n",
            "Test accuracy: 0.7006579041481018\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.1490 - loss: 3.3941 - val_accuracy: 0.4594 - val_loss: 1.8337\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.5837 - loss: 1.4052 - val_accuracy: 0.5428 - val_loss: 1.5617\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.7961 - loss: 0.6453 - val_accuracy: 0.5537 - val_loss: 1.7283\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9268 - loss: 0.2209 - val_accuracy: 0.5581 - val_loss: 1.8678\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9721 - loss: 0.0968 - val_accuracy: 0.5910 - val_loss: 2.0063\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9906 - loss: 0.0392 - val_accuracy: 0.5548 - val_loss: 2.3119\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.0181 - val_accuracy: 0.5647 - val_loss: 2.3713\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9987 - loss: 0.0076 - val_accuracy: 0.5822 - val_loss: 2.4300\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 0.5428 - val_loss: 3.1020\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9889 - loss: 0.0296 - val_accuracy: 0.5154 - val_loss: 3.4596\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9667 - loss: 0.1156 - val_accuracy: 0.5164 - val_loss: 3.1431\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 0.9012 - loss: 0.3690 - val_accuracy: 0.5175 - val_loss: 3.0504\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9378 - loss: 0.1766 - val_accuracy: 0.5493 - val_loss: 3.1915\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9854 - loss: 0.0444 - val_accuracy: 0.5548 - val_loss: 3.1267\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9957 - loss: 0.0203 - val_accuracy: 0.5493 - val_loss: 3.1872\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9961 - loss: 0.0180 - val_accuracy: 0.5570 - val_loss: 3.0784\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.3748e-04 - val_accuracy: 0.5702 - val_loss: 3.1217\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.3615e-04 - val_accuracy: 0.5592 - val_loss: 3.1477\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.7178e-04 - val_accuracy: 0.5592 - val_loss: 3.1687\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.5112e-04 - val_accuracy: 0.5603 - val_loss: 3.1865\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6042 - loss: 2.8602\n",
            "Test accuracy: 0.5603070259094238\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - accuracy: 0.2138 - loss: 3.0913 - val_accuracy: 0.5450 - val_loss: 1.5787\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.6831 - loss: 1.0709 - val_accuracy: 0.5954 - val_loss: 1.4815\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.8798 - loss: 0.3801 - val_accuracy: 0.5943 - val_loss: 1.5583\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9724 - loss: 0.1025 - val_accuracy: 0.6140 - val_loss: 1.6926\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9970 - loss: 0.0209 - val_accuracy: 0.6283 - val_loss: 2.0106\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9987 - loss: 0.0105 - val_accuracy: 0.6535 - val_loss: 1.8750\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.6568 - val_loss: 1.9758\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 6.1463e-04 - val_accuracy: 0.6568 - val_loss: 2.0033\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 3.9979e-04 - val_accuracy: 0.6590 - val_loss: 2.0306\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.0896e-04 - val_accuracy: 0.6579 - val_loss: 2.0582\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.4948e-04 - val_accuracy: 0.6601 - val_loss: 2.0813\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.2144e-04 - val_accuracy: 0.6612 - val_loss: 2.1018\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.7362e-04 - val_accuracy: 0.6612 - val_loss: 2.1218\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.5548e-04 - val_accuracy: 0.6612 - val_loss: 2.1403\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.2783e-04 - val_accuracy: 0.6623 - val_loss: 2.1579\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.0864e-04 - val_accuracy: 0.6623 - val_loss: 2.1744\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 9.7286e-05 - val_accuracy: 0.6634 - val_loss: 2.1907\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 9.2005e-05 - val_accuracy: 0.6634 - val_loss: 2.2074\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 7.9618e-05 - val_accuracy: 0.6634 - val_loss: 2.2218\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 6.9169e-05 - val_accuracy: 0.6667 - val_loss: 2.2363\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6910 - loss: 2.0970\n",
            "Test accuracy: 0.6666666865348816\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.2392 - loss: 2.8533 - val_accuracy: 0.4912 - val_loss: 1.7645\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.6201 - loss: 1.2614 - val_accuracy: 0.5779 - val_loss: 1.4562\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.8126 - loss: 0.6371 - val_accuracy: 0.6239 - val_loss: 1.3674\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9285 - loss: 0.2639 - val_accuracy: 0.6228 - val_loss: 1.5374\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9607 - loss: 0.1288 - val_accuracy: 0.6601 - val_loss: 1.6035\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9850 - loss: 0.0633 - val_accuracy: 0.6305 - val_loss: 1.8500\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9967 - loss: 0.0230 - val_accuracy: 0.6601 - val_loss: 1.8175\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9995 - loss: 0.0053 - val_accuracy: 0.6645 - val_loss: 1.8307\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6700 - val_loss: 1.8835\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6700 - val_loss: 1.9259\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 7.7273e-04 - val_accuracy: 0.6721 - val_loss: 1.9529\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 5.9806e-04 - val_accuracy: 0.6689 - val_loss: 1.9759\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 4.9524e-04 - val_accuracy: 0.6700 - val_loss: 2.0015\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 4.5382e-04 - val_accuracy: 0.6711 - val_loss: 2.0207\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.8831e-04 - val_accuracy: 0.6678 - val_loss: 2.0394\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.3878e-04 - val_accuracy: 0.6656 - val_loss: 2.0589\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.9422e-04 - val_accuracy: 0.6667 - val_loss: 2.0756\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.5961e-04 - val_accuracy: 0.6678 - val_loss: 2.0929\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.2977e-04 - val_accuracy: 0.6700 - val_loss: 2.1078\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.0439e-04 - val_accuracy: 0.6689 - val_loss: 2.1264\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6765 - loss: 2.0349\n",
            "Test accuracy: 0.6688596606254578\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - accuracy: 0.2560 - loss: 2.7130 - val_accuracy: 0.5713 - val_loss: 1.4419\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.7023 - loss: 1.0078 - val_accuracy: 0.6206 - val_loss: 1.3644\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.8942 - loss: 0.3664 - val_accuracy: 0.6239 - val_loss: 1.4615\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9606 - loss: 0.1349 - val_accuracy: 0.6360 - val_loss: 1.4789\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - accuracy: 0.9933 - loss: 0.0407 - val_accuracy: 0.6480 - val_loss: 1.6304\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9964 - loss: 0.0149 - val_accuracy: 0.6535 - val_loss: 1.8466\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9943 - loss: 0.0222 - val_accuracy: 0.6491 - val_loss: 1.9332\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 0.6502 - val_loss: 1.8900\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9961 - loss: 0.0171 - val_accuracy: 0.6623 - val_loss: 1.9733\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9917 - loss: 0.0261 - val_accuracy: 0.6009 - val_loss: 2.4901\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9405 - loss: 0.2090 - val_accuracy: 0.5570 - val_loss: 2.5729\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9423 - loss: 0.1852 - val_accuracy: 0.6064 - val_loss: 2.3799\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9638 - loss: 0.1265 - val_accuracy: 0.6053 - val_loss: 2.2696\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9862 - loss: 0.0493 - val_accuracy: 0.6338 - val_loss: 2.3920\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9933 - loss: 0.0244 - val_accuracy: 0.6294 - val_loss: 2.4850\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9935 - loss: 0.0199 - val_accuracy: 0.6360 - val_loss: 2.6766\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.9907 - loss: 0.0259 - val_accuracy: 0.6250 - val_loss: 2.5011\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.6425 - val_loss: 2.5647\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.6679e-04 - val_accuracy: 0.6546 - val_loss: 2.5328\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.7075e-04 - val_accuracy: 0.6568 - val_loss: 2.5406\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6708 - loss: 2.3444\n",
            "Test accuracy: 0.656798243522644\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.2004 - loss: 3.2161 - val_accuracy: 0.5066 - val_loss: 1.7103\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.6230 - loss: 1.2658 - val_accuracy: 0.5559 - val_loss: 1.4656\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.8480 - loss: 0.5130 - val_accuracy: 0.5943 - val_loss: 1.5321\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9564 - loss: 0.1613 - val_accuracy: 0.6009 - val_loss: 1.9522\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9881 - loss: 0.0520 - val_accuracy: 0.5636 - val_loss: 2.2508\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9984 - loss: 0.0140 - val_accuracy: 0.5888 - val_loss: 2.3164\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9967 - loss: 0.0195 - val_accuracy: 0.5526 - val_loss: 2.5579\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9951 - loss: 0.0170 - val_accuracy: 0.5526 - val_loss: 2.8482\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9755 - loss: 0.0920 - val_accuracy: 0.5461 - val_loss: 3.0811\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9277 - loss: 0.2342 - val_accuracy: 0.5461 - val_loss: 3.0550\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9445 - loss: 0.1953 - val_accuracy: 0.5219 - val_loss: 3.0549\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9793 - loss: 0.0687 - val_accuracy: 0.5614 - val_loss: 3.2064\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9822 - loss: 0.0523 - val_accuracy: 0.5515 - val_loss: 3.4206\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9919 - loss: 0.0225 - val_accuracy: 0.5603 - val_loss: 3.3989\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 0.5625 - val_loss: 3.8062\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9948 - loss: 0.0152 - val_accuracy: 0.5669 - val_loss: 3.7260\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9980 - loss: 0.0042 - val_accuracy: 0.5724 - val_loss: 3.5492\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9951 - loss: 0.0190 - val_accuracy: 0.5614 - val_loss: 3.6808\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9940 - loss: 0.0203 - val_accuracy: 0.5351 - val_loss: 4.0604\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9766 - loss: 0.0789 - val_accuracy: 0.4704 - val_loss: 5.9675\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5104 - loss: 5.2787\n",
            "Test accuracy: 0.47039473056793213\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 141ms/step - accuracy: 0.1673 - loss: 3.2466 - val_accuracy: 0.4923 - val_loss: 1.7340\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.6328 - loss: 1.1842 - val_accuracy: 0.5592 - val_loss: 1.4738\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.8794 - loss: 0.4160 - val_accuracy: 0.5197 - val_loss: 1.9067\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9591 - loss: 0.1466 - val_accuracy: 0.5493 - val_loss: 2.0452\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9822 - loss: 0.0711 - val_accuracy: 0.5779 - val_loss: 2.3951\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.9888 - loss: 0.0420 - val_accuracy: 0.5888 - val_loss: 2.2859\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - accuracy: 0.9939 - loss: 0.0250 - val_accuracy: 0.5537 - val_loss: 2.6065\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9949 - loss: 0.0223 - val_accuracy: 0.5406 - val_loss: 2.7848\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 138ms/step - accuracy: 0.9887 - loss: 0.0351 - val_accuracy: 0.5340 - val_loss: 3.3618\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9361 - loss: 0.2302 - val_accuracy: 0.4868 - val_loss: 3.5944\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9256 - loss: 0.2775 - val_accuracy: 0.5175 - val_loss: 2.9808\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 138ms/step - accuracy: 0.9611 - loss: 0.1395 - val_accuracy: 0.5439 - val_loss: 3.3922\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.9811 - loss: 0.0585 - val_accuracy: 0.5230 - val_loss: 3.5799\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.9906 - loss: 0.0260 - val_accuracy: 0.5526 - val_loss: 3.5141\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.9965 - loss: 0.0105 - val_accuracy: 0.5636 - val_loss: 3.4905\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.9998 - loss: 9.3306e-04 - val_accuracy: 0.5680 - val_loss: 3.4894\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 6.2950e-04 - val_accuracy: 0.5702 - val_loss: 3.5059\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.3138e-04 - val_accuracy: 0.5724 - val_loss: 3.5051\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 9.8995e-05 - val_accuracy: 0.5724 - val_loss: 3.5093\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 8.8823e-05 - val_accuracy: 0.5724 - val_loss: 3.5142\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6028 - loss: 3.1208\n",
            "Test accuracy: 0.5723684430122375\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 91ms/step - accuracy: 0.1564 - loss: 3.2229 - val_accuracy: 0.4561 - val_loss: 1.9032\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.5871 - loss: 1.4035 - val_accuracy: 0.5570 - val_loss: 1.5052\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.7837 - loss: 0.7045 - val_accuracy: 0.5954 - val_loss: 1.5070\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.8976 - loss: 0.3371 - val_accuracy: 0.5603 - val_loss: 1.7577\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9645 - loss: 0.1257 - val_accuracy: 0.5987 - val_loss: 1.9328\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9846 - loss: 0.0534 - val_accuracy: 0.5746 - val_loss: 2.1726\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9901 - loss: 0.0366 - val_accuracy: 0.6140 - val_loss: 2.3238\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9952 - loss: 0.0170 - val_accuracy: 0.5636 - val_loss: 2.5385\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9924 - loss: 0.0380 - val_accuracy: 0.5779 - val_loss: 2.6436\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9927 - loss: 0.0322 - val_accuracy: 0.5351 - val_loss: 2.9133\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9230 - loss: 0.2499 - val_accuracy: 0.5351 - val_loss: 2.9930\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9130 - loss: 0.2715 - val_accuracy: 0.5680 - val_loss: 2.7687\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9693 - loss: 0.0821 - val_accuracy: 0.5757 - val_loss: 2.9158\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9809 - loss: 0.0482 - val_accuracy: 0.5943 - val_loss: 3.0210\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9947 - loss: 0.0199 - val_accuracy: 0.5932 - val_loss: 2.9279\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9928 - loss: 0.0242 - val_accuracy: 0.5987 - val_loss: 2.9721\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9970 - loss: 0.0063 - val_accuracy: 0.5998 - val_loss: 3.0241\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 9.1300e-04 - val_accuracy: 0.6096 - val_loss: 2.9005\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.8780e-04 - val_accuracy: 0.6064 - val_loss: 2.9252\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.3994e-04 - val_accuracy: 0.6129 - val_loss: 2.9468\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6228 - loss: 2.7933\n",
            "Test accuracy: 0.6129385828971863\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.2138 - loss: 3.0193 - val_accuracy: 0.5307 - val_loss: 1.5841\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.6734 - loss: 1.1175 - val_accuracy: 0.6151 - val_loss: 1.2449\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.8641 - loss: 0.4211 - val_accuracy: 0.5779 - val_loss: 1.6406\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9419 - loss: 0.1913 - val_accuracy: 0.5998 - val_loss: 1.9554\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9743 - loss: 0.0843 - val_accuracy: 0.6283 - val_loss: 1.8583\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9905 - loss: 0.0323 - val_accuracy: 0.6360 - val_loss: 1.9451\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9914 - loss: 0.0274 - val_accuracy: 0.6491 - val_loss: 2.0300\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9958 - loss: 0.0197 - val_accuracy: 0.6425 - val_loss: 2.1953\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9935 - loss: 0.0276 - val_accuracy: 0.6316 - val_loss: 2.4850\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.9547 - loss: 0.1624 - val_accuracy: 0.6107 - val_loss: 2.4340\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9072 - loss: 0.2987 - val_accuracy: 0.6217 - val_loss: 2.2644\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9730 - loss: 0.0957 - val_accuracy: 0.6316 - val_loss: 2.3841\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 0.9921 - loss: 0.0314 - val_accuracy: 0.6623 - val_loss: 2.3433\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9959 - loss: 0.0094 - val_accuracy: 0.6612 - val_loss: 2.3272\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6645 - val_loss: 2.3136\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 2.2513e-04 - val_accuracy: 0.6645 - val_loss: 2.3372\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.7483e-04 - val_accuracy: 0.6634 - val_loss: 2.3522\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.5295e-04 - val_accuracy: 0.6634 - val_loss: 2.3649\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 1.4131e-04 - val_accuracy: 0.6634 - val_loss: 2.3767\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 1.2098e-04 - val_accuracy: 0.6623 - val_loss: 2.3893\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6868 - loss: 2.1272\n",
            "Test accuracy: 0.6622806787490845\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.2159 - loss: 3.2344 - val_accuracy: 0.5230 - val_loss: 1.6989\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.7125 - loss: 1.0106 - val_accuracy: 0.5285 - val_loss: 1.6324\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9136 - loss: 0.2810 - val_accuracy: 0.5614 - val_loss: 1.6768\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 160ms/step - accuracy: 0.9867 - loss: 0.0592 - val_accuracy: 0.5680 - val_loss: 2.0791\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9941 - loss: 0.0277 - val_accuracy: 0.5866 - val_loss: 2.1528\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9958 - loss: 0.0148 - val_accuracy: 0.5877 - val_loss: 2.2453\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.5603 - val_loss: 2.5218\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9923 - loss: 0.0312 - val_accuracy: 0.5088 - val_loss: 2.9903\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9142 - loss: 0.2813 - val_accuracy: 0.4901 - val_loss: 3.3217\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.8718 - loss: 0.4883 - val_accuracy: 0.4781 - val_loss: 4.0814\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9249 - loss: 0.2963 - val_accuracy: 0.5318 - val_loss: 3.8367\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9702 - loss: 0.1143 - val_accuracy: 0.5471 - val_loss: 3.7502\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9908 - loss: 0.0266 - val_accuracy: 0.5450 - val_loss: 4.1842\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9953 - loss: 0.0141 - val_accuracy: 0.5702 - val_loss: 3.8922\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.5647 - val_loss: 3.7536\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 3.2250e-04 - val_accuracy: 0.5658 - val_loss: 3.7730\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 1.2438e-04 - val_accuracy: 0.5702 - val_loss: 3.7748\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 7.1469e-05 - val_accuracy: 0.5713 - val_loss: 3.7784\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 6.4775e-05 - val_accuracy: 0.5735 - val_loss: 3.7826\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 6.2893e-05 - val_accuracy: 0.5746 - val_loss: 3.7868\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5737 - loss: 3.5450\n",
            "Test accuracy: 0.5745614171028137\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 249ms/step - accuracy: 0.1966 - loss: 4.0250 - val_accuracy: 0.5241 - val_loss: 1.6308\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.7059 - loss: 0.9973 - val_accuracy: 0.5636 - val_loss: 1.5325\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.8949 - loss: 0.3293 - val_accuracy: 0.5504 - val_loss: 1.7212\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.9785 - loss: 0.0757 - val_accuracy: 0.5976 - val_loss: 1.9566\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9949 - loss: 0.0185 - val_accuracy: 0.6075 - val_loss: 2.2291\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9976 - loss: 0.0122 - val_accuracy: 0.5932 - val_loss: 2.1928\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9957 - loss: 0.0175 - val_accuracy: 0.5713 - val_loss: 2.5137\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9898 - loss: 0.0372 - val_accuracy: 0.5428 - val_loss: 3.0457\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9195 - loss: 0.2990 - val_accuracy: 0.4868 - val_loss: 3.2239\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.8971 - loss: 0.3617 - val_accuracy: 0.5230 - val_loss: 2.8685\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 245ms/step - accuracy: 0.9600 - loss: 0.1276 - val_accuracy: 0.5570 - val_loss: 2.8992\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.9907 - loss: 0.0224 - val_accuracy: 0.5614 - val_loss: 3.0561\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.9953 - loss: 0.0129 - val_accuracy: 0.5428 - val_loss: 3.3366\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.5724 - val_loss: 3.3583\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 5.4279e-04 - val_accuracy: 0.5625 - val_loss: 3.3763\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 6.6309e-04 - val_accuracy: 0.5757 - val_loss: 3.2569\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 1.0936e-04 - val_accuracy: 0.5746 - val_loss: 3.2739\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 8.0949e-05 - val_accuracy: 0.5779 - val_loss: 3.2886\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 7.6628e-05 - val_accuracy: 0.5789 - val_loss: 3.3027\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 6.4135e-05 - val_accuracy: 0.5822 - val_loss: 3.3154\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6042 - loss: 2.8338\n",
            "Test accuracy: 0.5822368264198303\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.1776 - loss: 3.1156 - val_accuracy: 0.4474 - val_loss: 1.8721\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5037 - loss: 1.6028 - val_accuracy: 0.5647 - val_loss: 1.4558\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.6930 - loss: 0.9981 - val_accuracy: 0.6579 - val_loss: 1.1492\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.8121 - loss: 0.5864 - val_accuracy: 0.6689 - val_loss: 1.0931\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.8788 - loss: 0.3720 - val_accuracy: 0.6974 - val_loss: 1.0204\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9346 - loss: 0.2174 - val_accuracy: 0.7127 - val_loss: 1.1031\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9729 - loss: 0.1159 - val_accuracy: 0.7193 - val_loss: 1.1480\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9923 - loss: 0.0501 - val_accuracy: 0.7325 - val_loss: 1.1154\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9977 - loss: 0.0232 - val_accuracy: 0.7281 - val_loss: 1.1629\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.7423 - val_loss: 1.1839\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.7336 - val_loss: 1.2204\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7357 - val_loss: 1.2379\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7346 - val_loss: 1.2562\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7314 - val_loss: 1.2763\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7314 - val_loss: 1.2885\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7325 - val_loss: 1.3086\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7346 - val_loss: 1.3198\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7336 - val_loss: 1.3321\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7336 - val_loss: 1.3464\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7336 - val_loss: 1.3570\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7656 - loss: 1.2636\n",
            "Test accuracy: 0.7335526347160339\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.1955 - loss: 3.0134 - val_accuracy: 0.5077 - val_loss: 1.6184\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.6068 - loss: 1.2588 - val_accuracy: 0.6393 - val_loss: 1.1417\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.7782 - loss: 0.7096 - val_accuracy: 0.6996 - val_loss: 1.0297\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8681 - loss: 0.4188 - val_accuracy: 0.7160 - val_loss: 1.0088\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9288 - loss: 0.2272 - val_accuracy: 0.7160 - val_loss: 1.0794\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9715 - loss: 0.1106 - val_accuracy: 0.7390 - val_loss: 1.0562\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9803 - loss: 0.0754 - val_accuracy: 0.7412 - val_loss: 1.0465\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9970 - loss: 0.0225 - val_accuracy: 0.7456 - val_loss: 1.1341\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.7643 - val_loss: 1.0949\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7599 - val_loss: 1.1211\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7599 - val_loss: 1.1425\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7621 - val_loss: 1.1631\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7610 - val_loss: 1.1788\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7632 - val_loss: 1.1919\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.8651e-04 - val_accuracy: 0.7632 - val_loss: 1.2028\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.6090e-04 - val_accuracy: 0.7599 - val_loss: 1.2212\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.5039e-04 - val_accuracy: 0.7610 - val_loss: 1.2333\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.7677e-04 - val_accuracy: 0.7610 - val_loss: 1.2471\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 6.0423e-04 - val_accuracy: 0.7610 - val_loss: 1.2534\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.6602e-04 - val_accuracy: 0.7599 - val_loss: 1.2638\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7660 - loss: 1.2270\n",
            "Test accuracy: 0.7598684430122375\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.2042 - loss: 3.0179 - val_accuracy: 0.4989 - val_loss: 1.7803\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5844 - loss: 1.4455 - val_accuracy: 0.6283 - val_loss: 1.2758\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7649 - loss: 0.7673 - val_accuracy: 0.6667 - val_loss: 1.1766\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8722 - loss: 0.4026 - val_accuracy: 0.6601 - val_loss: 1.2026\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9400 - loss: 0.2136 - val_accuracy: 0.6820 - val_loss: 1.3867\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9694 - loss: 0.1047 - val_accuracy: 0.6689 - val_loss: 1.6018\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9829 - loss: 0.0550 - val_accuracy: 0.6612 - val_loss: 1.8019\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9793 - loss: 0.0697 - val_accuracy: 0.6623 - val_loss: 1.8105\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9882 - loss: 0.0496 - val_accuracy: 0.6732 - val_loss: 1.8989\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9917 - loss: 0.0285 - val_accuracy: 0.6732 - val_loss: 1.9510\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9981 - loss: 0.0137 - val_accuracy: 0.6425 - val_loss: 2.2328\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9731 - loss: 0.0903 - val_accuracy: 0.6360 - val_loss: 2.3181\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9342 - loss: 0.1910 - val_accuracy: 0.6524 - val_loss: 2.1925\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9570 - loss: 0.1524 - val_accuracy: 0.6414 - val_loss: 2.3133\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9768 - loss: 0.0642 - val_accuracy: 0.6656 - val_loss: 2.2219\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9881 - loss: 0.0360 - val_accuracy: 0.6711 - val_loss: 2.1094\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9931 - loss: 0.0180 - val_accuracy: 0.6667 - val_loss: 2.3287\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.6831 - val_loss: 2.1971\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.7663e-04 - val_accuracy: 0.6765 - val_loss: 2.1991\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.4311e-04 - val_accuracy: 0.6787 - val_loss: 2.2106\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6881 - loss: 1.9959\n",
            "Test accuracy: 0.6787280440330505\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.2116 - loss: 2.9633 - val_accuracy: 0.5844 - val_loss: 1.4652\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.6612 - loss: 1.1295 - val_accuracy: 0.6623 - val_loss: 1.1611\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.8101 - loss: 0.5813 - val_accuracy: 0.6721 - val_loss: 1.2173\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9070 - loss: 0.3055 - val_accuracy: 0.6875 - val_loss: 1.3008\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9644 - loss: 0.1189 - val_accuracy: 0.6754 - val_loss: 1.2906\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9861 - loss: 0.0600 - val_accuracy: 0.6974 - val_loss: 1.4337\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9933 - loss: 0.0299 - val_accuracy: 0.6886 - val_loss: 1.6262\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9734 - loss: 0.0917 - val_accuracy: 0.6809 - val_loss: 1.7466\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9688 - loss: 0.0978 - val_accuracy: 0.6743 - val_loss: 1.9212\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9752 - loss: 0.0694 - val_accuracy: 0.6743 - val_loss: 1.9682\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9845 - loss: 0.0467 - val_accuracy: 0.6842 - val_loss: 1.9274\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9788 - loss: 0.0572 - val_accuracy: 0.6721 - val_loss: 1.9050\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9657 - loss: 0.1286 - val_accuracy: 0.5998 - val_loss: 2.3713\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9743 - loss: 0.0802 - val_accuracy: 0.6678 - val_loss: 2.0372\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9847 - loss: 0.0531 - val_accuracy: 0.6590 - val_loss: 2.0728\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9831 - loss: 0.0564 - val_accuracy: 0.6732 - val_loss: 2.3431\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9917 - loss: 0.0267 - val_accuracy: 0.6612 - val_loss: 2.3623\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9931 - loss: 0.0233 - val_accuracy: 0.6765 - val_loss: 2.0964\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.6809 - val_loss: 2.2066\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.9819e-04 - val_accuracy: 0.6864 - val_loss: 2.1812\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7350 - loss: 1.8946\n",
            "Test accuracy: 0.6864035129547119\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.2065 - loss: 3.0045 - val_accuracy: 0.4638 - val_loss: 1.8041\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5520 - loss: 1.4961 - val_accuracy: 0.6086 - val_loss: 1.3007\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.6930 - loss: 0.9769 - val_accuracy: 0.6261 - val_loss: 1.2277\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.7911 - loss: 0.6572 - val_accuracy: 0.6557 - val_loss: 1.1191\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8847 - loss: 0.3931 - val_accuracy: 0.6667 - val_loss: 1.1833\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.9442 - loss: 0.1910 - val_accuracy: 0.6831 - val_loss: 1.1559\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9718 - loss: 0.1085 - val_accuracy: 0.6908 - val_loss: 1.2448\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9950 - loss: 0.0399 - val_accuracy: 0.6919 - val_loss: 1.3721\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9959 - loss: 0.0261 - val_accuracy: 0.7215 - val_loss: 1.2864\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7248 - val_loss: 1.3493\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.7270 - val_loss: 1.3716\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7270 - val_loss: 1.3959\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7270 - val_loss: 1.4150\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7292 - val_loss: 1.4345\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7292 - val_loss: 1.4548\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7325 - val_loss: 1.4740\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7336 - val_loss: 1.4873\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.9859e-04 - val_accuracy: 0.7314 - val_loss: 1.5038\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 8.7861e-04 - val_accuracy: 0.7303 - val_loss: 1.5188\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.5721e-04 - val_accuracy: 0.7325 - val_loss: 1.5265\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7440 - loss: 1.4312\n",
            "Test accuracy: 0.7324561476707458\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.2294 - loss: 2.7981 - val_accuracy: 0.5625 - val_loss: 1.4816\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.6383 - loss: 1.1993 - val_accuracy: 0.6404 - val_loss: 1.1862\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.7961 - loss: 0.6428 - val_accuracy: 0.6831 - val_loss: 1.0744\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9114 - loss: 0.3118 - val_accuracy: 0.6886 - val_loss: 1.1182\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9548 - loss: 0.1485 - val_accuracy: 0.7039 - val_loss: 1.2539\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9830 - loss: 0.0698 - val_accuracy: 0.7094 - val_loss: 1.2510\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9940 - loss: 0.0324 - val_accuracy: 0.7390 - val_loss: 1.2340\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9960 - loss: 0.0167 - val_accuracy: 0.7434 - val_loss: 1.2049\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9967 - loss: 0.0133 - val_accuracy: 0.7434 - val_loss: 1.2602\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9968 - loss: 0.0150 - val_accuracy: 0.7270 - val_loss: 1.2978\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9970 - loss: 0.0135 - val_accuracy: 0.7390 - val_loss: 1.3903\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9885 - loss: 0.0421 - val_accuracy: 0.7039 - val_loss: 1.6191\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9119 - loss: 0.2624 - val_accuracy: 0.6667 - val_loss: 1.7638\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9404 - loss: 0.1864 - val_accuracy: 0.6623 - val_loss: 1.7028\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9784 - loss: 0.0724 - val_accuracy: 0.6996 - val_loss: 1.5712\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0097 - val_accuracy: 0.7336 - val_loss: 1.5774\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9981 - loss: 0.0111 - val_accuracy: 0.7314 - val_loss: 1.5550\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7456 - val_loss: 1.5161\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.4458e-04 - val_accuracy: 0.7478 - val_loss: 1.5325\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.7458e-04 - val_accuracy: 0.7500 - val_loss: 1.5442\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7462 - loss: 1.6163\n",
            "Test accuracy: 0.75\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.2294 - loss: 2.9258 - val_accuracy: 0.5208 - val_loss: 1.6918\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6230 - loss: 1.2719 - val_accuracy: 0.6206 - val_loss: 1.3464\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7852 - loss: 0.7009 - val_accuracy: 0.6272 - val_loss: 1.2554\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.8703 - loss: 0.3933 - val_accuracy: 0.6491 - val_loss: 1.2937\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9361 - loss: 0.2034 - val_accuracy: 0.6360 - val_loss: 1.5935\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9586 - loss: 0.1185 - val_accuracy: 0.6535 - val_loss: 1.7797\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9809 - loss: 0.0637 - val_accuracy: 0.6425 - val_loss: 1.9407\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9907 - loss: 0.0279 - val_accuracy: 0.6053 - val_loss: 2.4330\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9668 - loss: 0.0928 - val_accuracy: 0.5724 - val_loss: 2.8510\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9303 - loss: 0.2133 - val_accuracy: 0.5724 - val_loss: 2.7849\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9300 - loss: 0.2275 - val_accuracy: 0.6031 - val_loss: 2.7057\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.9604 - loss: 0.1128 - val_accuracy: 0.6162 - val_loss: 2.4970\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9853 - loss: 0.0497 - val_accuracy: 0.6414 - val_loss: 2.6108\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9905 - loss: 0.0261 - val_accuracy: 0.6338 - val_loss: 2.7607\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9949 - loss: 0.0177 - val_accuracy: 0.6404 - val_loss: 2.6194\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9953 - loss: 0.0163 - val_accuracy: 0.6250 - val_loss: 2.8224\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.6371 - val_loss: 2.6725\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 7.9547e-04 - val_accuracy: 0.6436 - val_loss: 2.6811\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.1731e-04 - val_accuracy: 0.6491 - val_loss: 2.6902\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.5463e-04 - val_accuracy: 0.6491 - val_loss: 2.6994\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6634 - loss: 2.5123\n",
            "Test accuracy: 0.6491228342056274\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.2339 - loss: 2.8791 - val_accuracy: 0.5526 - val_loss: 1.4929\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.6671 - loss: 1.1286 - val_accuracy: 0.6568 - val_loss: 1.1600\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.8309 - loss: 0.5169 - val_accuracy: 0.6612 - val_loss: 1.2502\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9223 - loss: 0.2359 - val_accuracy: 0.6316 - val_loss: 1.4454\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9624 - loss: 0.1201 - val_accuracy: 0.6513 - val_loss: 1.5925\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9704 - loss: 0.0960 - val_accuracy: 0.6414 - val_loss: 1.8467\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9689 - loss: 0.0897 - val_accuracy: 0.6612 - val_loss: 1.9012\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9842 - loss: 0.0588 - val_accuracy: 0.6217 - val_loss: 2.1600\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.9700 - loss: 0.0990 - val_accuracy: 0.6349 - val_loss: 1.9758\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9712 - loss: 0.0946 - val_accuracy: 0.6667 - val_loss: 2.2742\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9580 - loss: 0.1332 - val_accuracy: 0.6096 - val_loss: 2.6266\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9732 - loss: 0.0865 - val_accuracy: 0.6656 - val_loss: 2.3498\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9823 - loss: 0.0618 - val_accuracy: 0.6327 - val_loss: 2.4638\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9825 - loss: 0.0569 - val_accuracy: 0.6480 - val_loss: 2.7671\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9893 - loss: 0.0530 - val_accuracy: 0.6305 - val_loss: 2.8782\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9874 - loss: 0.0431 - val_accuracy: 0.6645 - val_loss: 3.0465\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9767 - loss: 0.0957 - val_accuracy: 0.6151 - val_loss: 3.0958\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9679 - loss: 0.1158 - val_accuracy: 0.6206 - val_loss: 3.6645\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9643 - loss: 0.1106 - val_accuracy: 0.6042 - val_loss: 3.9080\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - accuracy: 0.9661 - loss: 0.1283 - val_accuracy: 0.6118 - val_loss: 3.3388\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6340 - loss: 3.0688\n",
            "Test accuracy: 0.6118420958518982\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.1983 - loss: 2.9969 - val_accuracy: 0.5263 - val_loss: 1.6472\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.5917 - loss: 1.3704 - val_accuracy: 0.5833 - val_loss: 1.3439\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.7231 - loss: 0.8736 - val_accuracy: 0.6601 - val_loss: 1.1385\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.8335 - loss: 0.5165 - val_accuracy: 0.6842 - val_loss: 1.1378\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9012 - loss: 0.3320 - val_accuracy: 0.6853 - val_loss: 1.2743\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9543 - loss: 0.1668 - val_accuracy: 0.6820 - val_loss: 1.4701\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9592 - loss: 0.1258 - val_accuracy: 0.6897 - val_loss: 1.4384\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9886 - loss: 0.0464 - val_accuracy: 0.6974 - val_loss: 1.4491\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9784 - loss: 0.0641 - val_accuracy: 0.7039 - val_loss: 1.4626\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9956 - loss: 0.0230 - val_accuracy: 0.6974 - val_loss: 1.5604\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9957 - loss: 0.0153 - val_accuracy: 0.7050 - val_loss: 1.5424\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7083 - val_loss: 1.6341\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7083 - val_loss: 1.5811\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 8.0959e-04 - val_accuracy: 0.7138 - val_loss: 1.6016\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 6.6545e-04 - val_accuracy: 0.7149 - val_loss: 1.6219\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 5.7883e-04 - val_accuracy: 0.7171 - val_loss: 1.6337\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.8303e-04 - val_accuracy: 0.7193 - val_loss: 1.6446\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.2004e-04 - val_accuracy: 0.7215 - val_loss: 1.6604\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.0466e-04 - val_accuracy: 0.7226 - val_loss: 1.6696\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 3.3362e-04 - val_accuracy: 0.7215 - val_loss: 1.6805\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7384 - loss: 1.5297\n",
            "Test accuracy: 0.7214912176132202\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.2405 - loss: 2.8601 - val_accuracy: 0.5811 - val_loss: 1.4639\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.6435 - loss: 1.1868 - val_accuracy: 0.6601 - val_loss: 1.1347\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.7833 - loss: 0.6694 - val_accuracy: 0.6820 - val_loss: 1.0935\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.8913 - loss: 0.3421 - val_accuracy: 0.6985 - val_loss: 1.1582\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9511 - loss: 0.1595 - val_accuracy: 0.6623 - val_loss: 1.3890\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9747 - loss: 0.0914 - val_accuracy: 0.7237 - val_loss: 1.3764\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9719 - loss: 0.0921 - val_accuracy: 0.6985 - val_loss: 1.4106\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9667 - loss: 0.0935 - val_accuracy: 0.6996 - val_loss: 1.5186\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9752 - loss: 0.0636 - val_accuracy: 0.6963 - val_loss: 1.5542\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9837 - loss: 0.0468 - val_accuracy: 0.7072 - val_loss: 1.6056\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9910 - loss: 0.0295 - val_accuracy: 0.7050 - val_loss: 1.6629\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9950 - loss: 0.0219 - val_accuracy: 0.6842 - val_loss: 1.9868\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9869 - loss: 0.0624 - val_accuracy: 0.6382 - val_loss: 2.3291\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9372 - loss: 0.2105 - val_accuracy: 0.6349 - val_loss: 2.2037\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9560 - loss: 0.1360 - val_accuracy: 0.6590 - val_loss: 2.2427\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9646 - loss: 0.1012 - val_accuracy: 0.6963 - val_loss: 2.0198\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9802 - loss: 0.0612 - val_accuracy: 0.6919 - val_loss: 2.1391\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9948 - loss: 0.0153 - val_accuracy: 0.7072 - val_loss: 2.0936\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.9957 - loss: 0.0145 - val_accuracy: 0.7018 - val_loss: 2.1225\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.7160 - val_loss: 1.9916\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7090 - loss: 2.0528\n",
            "Test accuracy: 0.7160087823867798\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.1982 - loss: 3.0631 - val_accuracy: 0.5241 - val_loss: 1.6432\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.5886 - loss: 1.3518 - val_accuracy: 0.5417 - val_loss: 1.5212\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7401 - loss: 0.8145 - val_accuracy: 0.5921 - val_loss: 1.3931\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8393 - loss: 0.5025 - val_accuracy: 0.5910 - val_loss: 1.6743\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9020 - loss: 0.2991 - val_accuracy: 0.6053 - val_loss: 1.6409\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9617 - loss: 0.1407 - val_accuracy: 0.5866 - val_loss: 2.1541\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9577 - loss: 0.1261 - val_accuracy: 0.5669 - val_loss: 2.3556\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9594 - loss: 0.1152 - val_accuracy: 0.5702 - val_loss: 2.6828\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9551 - loss: 0.1394 - val_accuracy: 0.5482 - val_loss: 3.0390\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9386 - loss: 0.1821 - val_accuracy: 0.5844 - val_loss: 2.7519\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9654 - loss: 0.1157 - val_accuracy: 0.5636 - val_loss: 3.1037\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9712 - loss: 0.0895 - val_accuracy: 0.5570 - val_loss: 3.1657\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9700 - loss: 0.1159 - val_accuracy: 0.5735 - val_loss: 3.1798\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9744 - loss: 0.0823 - val_accuracy: 0.5757 - val_loss: 3.4139\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9612 - loss: 0.1360 - val_accuracy: 0.5921 - val_loss: 3.3797\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9776 - loss: 0.0836 - val_accuracy: 0.5636 - val_loss: 4.1097\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9614 - loss: 0.1404 - val_accuracy: 0.5548 - val_loss: 4.1484\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9523 - loss: 0.1574 - val_accuracy: 0.5340 - val_loss: 4.5695\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9586 - loss: 0.1182 - val_accuracy: 0.5998 - val_loss: 4.0940\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9695 - loss: 0.1087 - val_accuracy: 0.5899 - val_loss: 3.8090\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6229 - loss: 3.4674\n",
            "Test accuracy: 0.5899122953414917\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.1938 - loss: 3.0787 - val_accuracy: 0.4912 - val_loss: 1.7231\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6369 - loss: 1.2216 - val_accuracy: 0.6107 - val_loss: 1.2713\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.8262 - loss: 0.5792 - val_accuracy: 0.6568 - val_loss: 1.2902\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.8877 - loss: 0.3216 - val_accuracy: 0.6469 - val_loss: 1.4345\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9517 - loss: 0.1510 - val_accuracy: 0.6491 - val_loss: 1.6178\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9599 - loss: 0.1200 - val_accuracy: 0.6480 - val_loss: 1.6483\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0512 - val_accuracy: 0.6732 - val_loss: 1.7340\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9877 - loss: 0.0445 - val_accuracy: 0.6546 - val_loss: 2.0503\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9903 - loss: 0.0266 - val_accuracy: 0.6634 - val_loss: 2.0634\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9927 - loss: 0.0251 - val_accuracy: 0.6458 - val_loss: 2.2502\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9587 - loss: 0.1502 - val_accuracy: 0.6107 - val_loss: 2.5418\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9186 - loss: 0.2965 - val_accuracy: 0.5702 - val_loss: 2.8792\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9286 - loss: 0.2448 - val_accuracy: 0.6042 - val_loss: 2.6476\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9630 - loss: 0.1064 - val_accuracy: 0.6382 - val_loss: 2.6764\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9855 - loss: 0.0478 - val_accuracy: 0.6535 - val_loss: 2.4954\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9896 - loss: 0.0359 - val_accuracy: 0.6447 - val_loss: 2.8489\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9939 - loss: 0.0184 - val_accuracy: 0.6360 - val_loss: 2.7592\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.6436 - val_loss: 2.8849\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.6590 - val_loss: 2.7920\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.6469 - val_loss: 3.1355\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6665 - loss: 2.9752\n",
            "Test accuracy: 0.6469298005104065\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.2020 - loss: 3.0817 - val_accuracy: 0.5197 - val_loss: 1.6303\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.6133 - loss: 1.2768 - val_accuracy: 0.6140 - val_loss: 1.2238\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.7953 - loss: 0.6591 - val_accuracy: 0.6151 - val_loss: 1.2835\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9055 - loss: 0.3204 - val_accuracy: 0.6634 - val_loss: 1.2960\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 0.9707 - loss: 0.1172 - val_accuracy: 0.6458 - val_loss: 1.4911\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 0.9922 - loss: 0.0481 - val_accuracy: 0.6513 - val_loss: 1.5346\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.9988 - loss: 0.0152 - val_accuracy: 0.6809 - val_loss: 1.5161\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6743 - val_loss: 1.5822\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6809 - val_loss: 1.5897\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6798 - val_loss: 1.6186\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6820 - val_loss: 1.6429\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 9.8790e-04 - val_accuracy: 0.6853 - val_loss: 1.6609\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 8.3245e-04 - val_accuracy: 0.6831 - val_loss: 1.6805\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.9421e-04 - val_accuracy: 0.6798 - val_loss: 1.7019\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.9574e-04 - val_accuracy: 0.6820 - val_loss: 1.7166\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.1937e-04 - val_accuracy: 0.6809 - val_loss: 1.7331\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.5250e-04 - val_accuracy: 0.6820 - val_loss: 1.7496\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.9547e-04 - val_accuracy: 0.6809 - val_loss: 1.7675\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.5580e-04 - val_accuracy: 0.6787 - val_loss: 1.7811\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.1396e-04 - val_accuracy: 0.6809 - val_loss: 1.7957\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7209 - loss: 1.5488\n",
            "Test accuracy: 0.6809210777282715\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.2005 - loss: 3.0393 - val_accuracy: 0.5154 - val_loss: 1.6170\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.6401 - loss: 1.1702 - val_accuracy: 0.6151 - val_loss: 1.2916\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.8425 - loss: 0.5137 - val_accuracy: 0.6349 - val_loss: 1.3563\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9459 - loss: 0.1989 - val_accuracy: 0.6250 - val_loss: 1.5790\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9839 - loss: 0.0711 - val_accuracy: 0.6623 - val_loss: 1.5638\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9967 - loss: 0.0237 - val_accuracy: 0.6820 - val_loss: 1.5856\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9982 - loss: 0.0085 - val_accuracy: 0.6776 - val_loss: 1.6468\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.9978 - loss: 0.0110 - val_accuracy: 0.6875 - val_loss: 1.6051\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6919 - val_loss: 1.6300\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.5079e-04 - val_accuracy: 0.6919 - val_loss: 1.6590\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.4809e-04 - val_accuracy: 0.6963 - val_loss: 1.6779\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.0145e-04 - val_accuracy: 0.6952 - val_loss: 1.6941\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.9429e-04 - val_accuracy: 0.6963 - val_loss: 1.7104\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.2923e-04 - val_accuracy: 0.6985 - val_loss: 1.7260\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.5429e-04 - val_accuracy: 0.6996 - val_loss: 1.7389\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1526e-04 - val_accuracy: 0.7039 - val_loss: 1.7547\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.9210e-04 - val_accuracy: 0.7050 - val_loss: 1.7646\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.4088e-04 - val_accuracy: 0.7050 - val_loss: 1.7765\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.2489e-04 - val_accuracy: 0.7050 - val_loss: 1.7915\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.9418e-04 - val_accuracy: 0.7061 - val_loss: 1.7998\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7100 - loss: 1.7783\n",
            "Test accuracy: 0.7061403393745422\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.1880 - loss: 3.2629 - val_accuracy: 0.4704 - val_loss: 1.8643\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.5838 - loss: 1.4202 - val_accuracy: 0.5658 - val_loss: 1.4530\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.7674 - loss: 0.7486 - val_accuracy: 0.5548 - val_loss: 1.7202\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8988 - loss: 0.3481 - val_accuracy: 0.5998 - val_loss: 1.9412\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9614 - loss: 0.1429 - val_accuracy: 0.5559 - val_loss: 2.1157\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9851 - loss: 0.0797 - val_accuracy: 0.5877 - val_loss: 2.2026\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9875 - loss: 0.0541 - val_accuracy: 0.5636 - val_loss: 2.6097\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9883 - loss: 0.0437 - val_accuracy: 0.5581 - val_loss: 3.1109\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9447 - loss: 0.1708 - val_accuracy: 0.5362 - val_loss: 2.9335\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9580 - loss: 0.1284 - val_accuracy: 0.5471 - val_loss: 3.1781\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9598 - loss: 0.1176 - val_accuracy: 0.5406 - val_loss: 3.2764\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9830 - loss: 0.0699 - val_accuracy: 0.5669 - val_loss: 3.3058\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9866 - loss: 0.0488 - val_accuracy: 0.5592 - val_loss: 3.5347\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9924 - loss: 0.0310 - val_accuracy: 0.5614 - val_loss: 3.3478\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9960 - loss: 0.0176 - val_accuracy: 0.5669 - val_loss: 3.5632\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9936 - loss: 0.0178 - val_accuracy: 0.5625 - val_loss: 3.6973\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.5406 - val_loss: 4.0857\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9813 - loss: 0.0790 - val_accuracy: 0.5493 - val_loss: 4.5094\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9563 - loss: 0.1701 - val_accuracy: 0.5351 - val_loss: 4.5054\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9570 - loss: 0.1813 - val_accuracy: 0.5395 - val_loss: 4.9085\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5843 - loss: 4.5496\n",
            "Test accuracy: 0.5394737124443054\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - accuracy: 0.2129 - loss: 3.1345 - val_accuracy: 0.5088 - val_loss: 1.6762\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.6415 - loss: 1.1761 - val_accuracy: 0.5800 - val_loss: 1.4813\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 0.8763 - loss: 0.4044 - val_accuracy: 0.6107 - val_loss: 1.5517\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9716 - loss: 0.1081 - val_accuracy: 0.5921 - val_loss: 2.0838\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9809 - loss: 0.0611 - val_accuracy: 0.6009 - val_loss: 2.0852\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9911 - loss: 0.0292 - val_accuracy: 0.6107 - val_loss: 2.1317\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.5965 - val_loss: 2.3735\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9955 - loss: 0.0187 - val_accuracy: 0.6064 - val_loss: 2.5558\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9950 - loss: 0.0201 - val_accuracy: 0.5768 - val_loss: 2.8872\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9523 - loss: 0.1555 - val_accuracy: 0.5954 - val_loss: 2.8542\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9389 - loss: 0.2053 - val_accuracy: 0.5329 - val_loss: 3.3252\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9275 - loss: 0.2412 - val_accuracy: 0.5669 - val_loss: 3.1001\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9747 - loss: 0.0853 - val_accuracy: 0.5811 - val_loss: 3.2932\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.9910 - loss: 0.0267 - val_accuracy: 0.5888 - val_loss: 3.3379\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.5833 - val_loss: 3.3202\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9989 - loss: 0.0014 - val_accuracy: 0.6009 - val_loss: 3.2716\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.5910 - val_loss: 3.2517\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.5932 - val_loss: 3.1190\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.5432e-04 - val_accuracy: 0.5987 - val_loss: 3.1412\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.0926e-04 - val_accuracy: 0.6020 - val_loss: 3.1609\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6254 - loss: 2.8768\n",
            "Test accuracy: 0.6019737124443054\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.1873 - loss: 3.0168 - val_accuracy: 0.4890 - val_loss: 1.7593\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.6022 - loss: 1.3351 - val_accuracy: 0.5746 - val_loss: 1.3983\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.8047 - loss: 0.6611 - val_accuracy: 0.6239 - val_loss: 1.3412\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9127 - loss: 0.2943 - val_accuracy: 0.6118 - val_loss: 1.5300\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9651 - loss: 0.1328 - val_accuracy: 0.5998 - val_loss: 1.8696\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9874 - loss: 0.0510 - val_accuracy: 0.6031 - val_loss: 1.9449\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9952 - loss: 0.0197 - val_accuracy: 0.6349 - val_loss: 2.0751\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9976 - loss: 0.0114 - val_accuracy: 0.6316 - val_loss: 2.0524\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6360 - val_loss: 2.0969\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6404 - val_loss: 2.0796\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 7.5177e-04 - val_accuracy: 0.6425 - val_loss: 2.1051\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 5.8492e-04 - val_accuracy: 0.6414 - val_loss: 2.1300\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 4.4659e-04 - val_accuracy: 0.6425 - val_loss: 2.1543\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 4.2614e-04 - val_accuracy: 0.6382 - val_loss: 2.1784\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 3.3147e-04 - val_accuracy: 0.6382 - val_loss: 2.1971\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.1108e-04 - val_accuracy: 0.6414 - val_loss: 2.2163\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.6479e-04 - val_accuracy: 0.6425 - val_loss: 2.2334\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.4012e-04 - val_accuracy: 0.6425 - val_loss: 2.2503\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.1012e-04 - val_accuracy: 0.6458 - val_loss: 2.2667\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.9299e-04 - val_accuracy: 0.6458 - val_loss: 2.2821\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6712 - loss: 2.0917\n",
            "Test accuracy: 0.6458333134651184\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - accuracy: 0.2434 - loss: 2.8155 - val_accuracy: 0.5658 - val_loss: 1.5011\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.6901 - loss: 1.0232 - val_accuracy: 0.6261 - val_loss: 1.2776\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.8647 - loss: 0.4206 - val_accuracy: 0.6140 - val_loss: 1.4632\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9626 - loss: 0.1346 - val_accuracy: 0.6184 - val_loss: 1.7118\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.9822 - loss: 0.0574 - val_accuracy: 0.6502 - val_loss: 1.7730\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.9917 - loss: 0.0343 - val_accuracy: 0.6513 - val_loss: 1.8757\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9979 - loss: 0.0111 - val_accuracy: 0.6612 - val_loss: 1.8440\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.6513 - val_loss: 1.9446\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.5998 - val_loss: 2.3732\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9480 - loss: 0.1788 - val_accuracy: 0.5439 - val_loss: 2.5614\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - accuracy: 0.8998 - loss: 0.3160 - val_accuracy: 0.5625 - val_loss: 2.8020\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9589 - loss: 0.1273 - val_accuracy: 0.6305 - val_loss: 2.2792\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9880 - loss: 0.0288 - val_accuracy: 0.6579 - val_loss: 2.4152\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.6546 - val_loss: 2.2724\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.6546 - val_loss: 2.2616\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 9.4519e-04 - val_accuracy: 0.6557 - val_loss: 2.2846\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 2.7127e-04 - val_accuracy: 0.6590 - val_loss: 2.2937\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.9649e-04 - val_accuracy: 0.6579 - val_loss: 2.3024\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.5980e-04 - val_accuracy: 0.6601 - val_loss: 2.3119\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.4720e-04 - val_accuracy: 0.6590 - val_loss: 2.3214\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6724 - loss: 2.2763\n",
            "Test accuracy: 0.6589912176132202\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.1832 - loss: 3.2790 - val_accuracy: 0.4781 - val_loss: 1.7896\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 123ms/step - accuracy: 0.6259 - loss: 1.2776 - val_accuracy: 0.5493 - val_loss: 1.5890\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.8637 - loss: 0.4786 - val_accuracy: 0.5461 - val_loss: 1.7753\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9545 - loss: 0.1498 - val_accuracy: 0.5603 - val_loss: 2.1627\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9775 - loss: 0.0815 - val_accuracy: 0.5318 - val_loss: 2.7006\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - accuracy: 0.9791 - loss: 0.0610 - val_accuracy: 0.5274 - val_loss: 2.7755\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9830 - loss: 0.0472 - val_accuracy: 0.5274 - val_loss: 3.1432\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9669 - loss: 0.1059 - val_accuracy: 0.5099 - val_loss: 3.4111\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9289 - loss: 0.2433 - val_accuracy: 0.5143 - val_loss: 3.5814\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9622 - loss: 0.1398 - val_accuracy: 0.5263 - val_loss: 3.5827\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9769 - loss: 0.0705 - val_accuracy: 0.5044 - val_loss: 4.1576\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9819 - loss: 0.0432 - val_accuracy: 0.5680 - val_loss: 4.2480\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9906 - loss: 0.0349 - val_accuracy: 0.5252 - val_loss: 4.2614\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9877 - loss: 0.0473 - val_accuracy: 0.5461 - val_loss: 4.3704\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9778 - loss: 0.0865 - val_accuracy: 0.5373 - val_loss: 4.7179\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9713 - loss: 0.1130 - val_accuracy: 0.5077 - val_loss: 4.4710\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - accuracy: 0.9751 - loss: 0.0925 - val_accuracy: 0.4803 - val_loss: 5.6393\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9674 - loss: 0.1355 - val_accuracy: 0.5186 - val_loss: 5.4166\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9639 - loss: 0.1619 - val_accuracy: 0.5395 - val_loss: 5.6462\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9693 - loss: 0.1153 - val_accuracy: 0.5066 - val_loss: 6.1724\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5536 - loss: 5.3951\n",
            "Test accuracy: 0.5065789222717285\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 165ms/step - accuracy: 0.2003 - loss: 3.4743 - val_accuracy: 0.5296 - val_loss: 1.6663\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.7036 - loss: 1.0270 - val_accuracy: 0.5833 - val_loss: 1.4799\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.9161 - loss: 0.2864 - val_accuracy: 0.5965 - val_loss: 1.6129\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.9825 - loss: 0.0719 - val_accuracy: 0.6086 - val_loss: 1.8549\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.9886 - loss: 0.0472 - val_accuracy: 0.6020 - val_loss: 2.1499\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.9967 - loss: 0.0128 - val_accuracy: 0.6261 - val_loss: 2.1141\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.6272 - val_loss: 2.2189\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 5.1748e-04 - val_accuracy: 0.6283 - val_loss: 2.1985\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 2.6841e-04 - val_accuracy: 0.6338 - val_loss: 2.2364\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 2.2163e-04 - val_accuracy: 0.6338 - val_loss: 2.2620\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 1.6528e-04 - val_accuracy: 0.6338 - val_loss: 2.2856\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 1.3681e-04 - val_accuracy: 0.6360 - val_loss: 2.3041\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 1.1869e-04 - val_accuracy: 0.6338 - val_loss: 2.3205\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 1.0687e-04 - val_accuracy: 0.6338 - val_loss: 2.3389\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 8.5724e-05 - val_accuracy: 0.6316 - val_loss: 2.3557\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 8.0609e-05 - val_accuracy: 0.6338 - val_loss: 2.3714\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 6.7617e-05 - val_accuracy: 0.6349 - val_loss: 2.3870\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 6.2373e-05 - val_accuracy: 0.6349 - val_loss: 2.4021\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 5.2924e-05 - val_accuracy: 0.6349 - val_loss: 2.4151\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 4.9068e-05 - val_accuracy: 0.6360 - val_loss: 2.4297\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6589 - loss: 2.1760\n",
            "Test accuracy: 0.6359649300575256\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 133ms/step - accuracy: 0.1992 - loss: 3.0603 - val_accuracy: 0.4868 - val_loss: 1.7638\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.6055 - loss: 1.3116 - val_accuracy: 0.5932 - val_loss: 1.3740\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - accuracy: 0.8031 - loss: 0.6414 - val_accuracy: 0.5800 - val_loss: 1.5265\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9178 - loss: 0.2671 - val_accuracy: 0.6272 - val_loss: 1.5738\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9659 - loss: 0.1065 - val_accuracy: 0.6173 - val_loss: 1.8291\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.9796 - loss: 0.0620 - val_accuracy: 0.6283 - val_loss: 2.0638\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9826 - loss: 0.0593 - val_accuracy: 0.6316 - val_loss: 2.2542\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9901 - loss: 0.0414 - val_accuracy: 0.6020 - val_loss: 2.4762\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9726 - loss: 0.0775 - val_accuracy: 0.5888 - val_loss: 2.5765\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9322 - loss: 0.2064 - val_accuracy: 0.5811 - val_loss: 2.6754\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9494 - loss: 0.1615 - val_accuracy: 0.6140 - val_loss: 2.9997\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9713 - loss: 0.0820 - val_accuracy: 0.5800 - val_loss: 3.2529\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9668 - loss: 0.1030 - val_accuracy: 0.6195 - val_loss: 3.0076\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9910 - loss: 0.0302 - val_accuracy: 0.6064 - val_loss: 2.9708\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9951 - loss: 0.0308 - val_accuracy: 0.6349 - val_loss: 3.0559\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.6414 - val_loss: 3.0451\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.6305 - val_loss: 3.1733\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 6.0335e-04 - val_accuracy: 0.6447 - val_loss: 3.0728\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 1.3116e-04 - val_accuracy: 0.6447 - val_loss: 3.0702\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 9.7807e-05 - val_accuracy: 0.6425 - val_loss: 3.0737\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6604 - loss: 3.1183\n",
            "Test accuracy: 0.6425438523292542\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 151ms/step - accuracy: 0.2470 - loss: 2.9599 - val_accuracy: 0.5504 - val_loss: 1.4743\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7142 - loss: 0.9380 - val_accuracy: 0.6469 - val_loss: 1.2510\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.8955 - loss: 0.3307 - val_accuracy: 0.6162 - val_loss: 1.5814\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9764 - loss: 0.0997 - val_accuracy: 0.6272 - val_loss: 1.7028\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9881 - loss: 0.0465 - val_accuracy: 0.6623 - val_loss: 1.9371\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9876 - loss: 0.0464 - val_accuracy: 0.6228 - val_loss: 2.2091\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9538 - loss: 0.1485 - val_accuracy: 0.6064 - val_loss: 2.4417\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9423 - loss: 0.1758 - val_accuracy: 0.6129 - val_loss: 2.3226\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9472 - loss: 0.1650 - val_accuracy: 0.6096 - val_loss: 2.2295\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9780 - loss: 0.0719 - val_accuracy: 0.6425 - val_loss: 2.3603\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9871 - loss: 0.0309 - val_accuracy: 0.6469 - val_loss: 2.3742\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9946 - loss: 0.0215 - val_accuracy: 0.6623 - val_loss: 2.1999\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9952 - loss: 0.0169 - val_accuracy: 0.6382 - val_loss: 2.4674\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9946 - loss: 0.0403 - val_accuracy: 0.6513 - val_loss: 2.5914\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9969 - loss: 0.0131 - val_accuracy: 0.6458 - val_loss: 2.7100\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9902 - loss: 0.0249 - val_accuracy: 0.6020 - val_loss: 3.1445\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9762 - loss: 0.0760 - val_accuracy: 0.5669 - val_loss: 4.0565\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9046 - loss: 0.4529 - val_accuracy: 0.5493 - val_loss: 5.6418\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.8636 - loss: 0.8331 - val_accuracy: 0.5998 - val_loss: 3.6431\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9587 - loss: 0.1624 - val_accuracy: 0.6184 - val_loss: 3.4631\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6081 - loss: 3.5016\n",
            "Test accuracy: 0.6184210777282715\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 200ms/step - accuracy: 0.1495 - loss: 3.5712 - val_accuracy: 0.4452 - val_loss: 1.9090\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.5778 - loss: 1.4219 - val_accuracy: 0.5197 - val_loss: 1.7411\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.8035 - loss: 0.6056 - val_accuracy: 0.5548 - val_loss: 1.6634\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9313 - loss: 0.2201 - val_accuracy: 0.5307 - val_loss: 2.2167\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9716 - loss: 0.0998 - val_accuracy: 0.5384 - val_loss: 2.3807\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9731 - loss: 0.0966 - val_accuracy: 0.5658 - val_loss: 2.5350\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 199ms/step - accuracy: 0.9744 - loss: 0.0761 - val_accuracy: 0.4989 - val_loss: 3.1295\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9578 - loss: 0.1366 - val_accuracy: 0.4616 - val_loss: 3.8081\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9285 - loss: 0.2440 - val_accuracy: 0.5384 - val_loss: 3.8747\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 199ms/step - accuracy: 0.9373 - loss: 0.2459 - val_accuracy: 0.5175 - val_loss: 4.1135\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9498 - loss: 0.2019 - val_accuracy: 0.5099 - val_loss: 4.7360\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 196ms/step - accuracy: 0.9428 - loss: 0.2567 - val_accuracy: 0.5132 - val_loss: 4.3798\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9653 - loss: 0.1310 - val_accuracy: 0.5493 - val_loss: 4.1980\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9786 - loss: 0.0698 - val_accuracy: 0.5592 - val_loss: 4.4246\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9884 - loss: 0.0446 - val_accuracy: 0.5746 - val_loss: 4.4902\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9963 - loss: 0.0091 - val_accuracy: 0.5493 - val_loss: 4.4065\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.5592 - val_loss: 4.7361\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9982 - loss: 0.0102 - val_accuracy: 0.5351 - val_loss: 4.4115\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.5340 - val_loss: 4.9594\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - accuracy: 0.9950 - loss: 0.0198 - val_accuracy: 0.5493 - val_loss: 5.2694\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5652 - loss: 4.7238\n",
            "Test accuracy: 0.5493420958518982\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 283ms/step - accuracy: 0.2277 - loss: 3.3152 - val_accuracy: 0.5340 - val_loss: 1.6148\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - accuracy: 0.7249 - loss: 0.9029 - val_accuracy: 0.5384 - val_loss: 1.5510\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 283ms/step - accuracy: 0.9212 - loss: 0.2576 - val_accuracy: 0.5658 - val_loss: 1.9104\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 281ms/step - accuracy: 0.9775 - loss: 0.0867 - val_accuracy: 0.5658 - val_loss: 2.1516\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - accuracy: 0.9881 - loss: 0.0480 - val_accuracy: 0.5822 - val_loss: 2.3522\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9849 - loss: 0.0451 - val_accuracy: 0.5296 - val_loss: 3.1373\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 281ms/step - accuracy: 0.9461 - loss: 0.1919 - val_accuracy: 0.5395 - val_loss: 3.0056\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9292 - loss: 0.2883 - val_accuracy: 0.5296 - val_loss: 3.8027\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - accuracy: 0.9359 - loss: 0.2468 - val_accuracy: 0.5121 - val_loss: 3.9263\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9480 - loss: 0.1936 - val_accuracy: 0.5450 - val_loss: 4.1253\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9709 - loss: 0.1008 - val_accuracy: 0.5285 - val_loss: 4.2938\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9691 - loss: 0.1276 - val_accuracy: 0.5088 - val_loss: 4.4390\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9832 - loss: 0.0570 - val_accuracy: 0.5208 - val_loss: 3.9907\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 282ms/step - accuracy: 0.9878 - loss: 0.0386 - val_accuracy: 0.5428 - val_loss: 4.6378\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 283ms/step - accuracy: 0.9965 - loss: 0.0087 - val_accuracy: 0.5559 - val_loss: 4.3666\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 281ms/step - accuracy: 0.9984 - loss: 0.0040 - val_accuracy: 0.5515 - val_loss: 4.4757\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 3.1214e-04 - val_accuracy: 0.5493 - val_loss: 4.4404\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 5.1837e-05 - val_accuracy: 0.5515 - val_loss: 4.4362\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 3.2799e-05 - val_accuracy: 0.5504 - val_loss: 4.4378\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 2.3753e-05 - val_accuracy: 0.5515 - val_loss: 4.4397\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5579 - loss: 4.4104\n",
            "Test accuracy: 0.5515350699424744\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.1744 - loss: 2.9726 - val_accuracy: 0.4309 - val_loss: 1.9056\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.5647 - loss: 1.4538 - val_accuracy: 0.5943 - val_loss: 1.3199\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7127 - loss: 0.9149 - val_accuracy: 0.6787 - val_loss: 1.0813\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.8289 - loss: 0.5581 - val_accuracy: 0.6634 - val_loss: 1.1131\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8871 - loss: 0.3630 - val_accuracy: 0.7072 - val_loss: 1.0296\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9428 - loss: 0.2116 - val_accuracy: 0.7007 - val_loss: 1.2210\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9687 - loss: 0.1238 - val_accuracy: 0.6908 - val_loss: 1.1486\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9870 - loss: 0.0817 - val_accuracy: 0.7346 - val_loss: 1.1689\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9973 - loss: 0.0328 - val_accuracy: 0.7346 - val_loss: 1.1935\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9999 - loss: 0.0116 - val_accuracy: 0.7445 - val_loss: 1.2055\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.7412 - val_loss: 1.2326\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.7390 - val_loss: 1.2526\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7434 - val_loss: 1.2614\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7401 - val_loss: 1.2814\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7423 - val_loss: 1.2881\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7456 - val_loss: 1.3064\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7423 - val_loss: 1.3182\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7456 - val_loss: 1.3287\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7467 - val_loss: 1.3388\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7445 - val_loss: 1.3486\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7508 - loss: 1.3022\n",
            "Test accuracy: 0.7445175647735596\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.1918 - loss: 2.9459 - val_accuracy: 0.5022 - val_loss: 1.7294\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.6012 - loss: 1.3662 - val_accuracy: 0.6513 - val_loss: 1.1492\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7751 - loss: 0.7421 - val_accuracy: 0.6963 - val_loss: 1.0152\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.8717 - loss: 0.4441 - val_accuracy: 0.7259 - val_loss: 0.9167\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9188 - loss: 0.2604 - val_accuracy: 0.7314 - val_loss: 1.0111\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9685 - loss: 0.1181 - val_accuracy: 0.7193 - val_loss: 1.0650\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9828 - loss: 0.0774 - val_accuracy: 0.7533 - val_loss: 1.0361\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9906 - loss: 0.0412 - val_accuracy: 0.7489 - val_loss: 1.0653\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.7588 - val_loss: 1.0442\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7555 - val_loss: 1.0769\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7588 - val_loss: 1.0952\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7555 - val_loss: 1.1119\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7599 - val_loss: 1.1216\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7555 - val_loss: 1.1416\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 9.6434e-04 - val_accuracy: 0.7610 - val_loss: 1.1542\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 8.7109e-04 - val_accuracy: 0.7621 - val_loss: 1.1600\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 7.4220e-04 - val_accuracy: 0.7621 - val_loss: 1.1727\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 6.6824e-04 - val_accuracy: 0.7643 - val_loss: 1.1875\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 5.8037e-04 - val_accuracy: 0.7610 - val_loss: 1.1898\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 5.2244e-04 - val_accuracy: 0.7643 - val_loss: 1.2025\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7852 - loss: 1.1342\n",
            "Test accuracy: 0.7642543911933899\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 81ms/step - accuracy: 0.1819 - loss: 3.0672 - val_accuracy: 0.4496 - val_loss: 1.7353\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.5478 - loss: 1.4822 - val_accuracy: 0.6173 - val_loss: 1.2703\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7221 - loss: 0.8778 - val_accuracy: 0.6689 - val_loss: 1.1425\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8252 - loss: 0.5337 - val_accuracy: 0.6809 - val_loss: 1.1552\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8972 - loss: 0.3240 - val_accuracy: 0.6404 - val_loss: 1.4524\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9299 - loss: 0.2234 - val_accuracy: 0.6480 - val_loss: 1.4392\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9618 - loss: 0.1154 - val_accuracy: 0.6743 - val_loss: 1.4302\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9790 - loss: 0.0769 - val_accuracy: 0.6787 - val_loss: 1.4812\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9850 - loss: 0.0564 - val_accuracy: 0.6612 - val_loss: 1.8190\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9898 - loss: 0.0382 - val_accuracy: 0.6842 - val_loss: 1.7674\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9953 - loss: 0.0206 - val_accuracy: 0.6700 - val_loss: 2.0591\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9649 - loss: 0.1095 - val_accuracy: 0.6667 - val_loss: 2.0044\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9390 - loss: 0.1982 - val_accuracy: 0.6404 - val_loss: 2.2736\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9304 - loss: 0.2435 - val_accuracy: 0.6162 - val_loss: 2.3812\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9452 - loss: 0.1788 - val_accuracy: 0.6568 - val_loss: 2.3020\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9764 - loss: 0.0719 - val_accuracy: 0.6754 - val_loss: 2.0865\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9893 - loss: 0.0372 - val_accuracy: 0.6590 - val_loss: 2.1229\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9910 - loss: 0.0271 - val_accuracy: 0.6886 - val_loss: 2.2464\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9950 - loss: 0.0190 - val_accuracy: 0.6721 - val_loss: 2.2793\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9983 - loss: 0.0133 - val_accuracy: 0.6842 - val_loss: 2.1651\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6848 - loss: 2.1781\n",
            "Test accuracy: 0.6842105388641357\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.2114 - loss: 2.9116 - val_accuracy: 0.5318 - val_loss: 1.5377\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.6429 - loss: 1.1609 - val_accuracy: 0.6425 - val_loss: 1.2794\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8045 - loss: 0.6371 - val_accuracy: 0.6776 - val_loss: 1.0833\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8993 - loss: 0.3333 - val_accuracy: 0.6645 - val_loss: 1.2444\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9574 - loss: 0.1368 - val_accuracy: 0.6842 - val_loss: 1.2869\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9838 - loss: 0.0630 - val_accuracy: 0.6875 - val_loss: 1.3879\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9857 - loss: 0.0544 - val_accuracy: 0.6864 - val_loss: 1.4982\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9874 - loss: 0.0465 - val_accuracy: 0.6941 - val_loss: 1.6787\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9860 - loss: 0.0406 - val_accuracy: 0.6535 - val_loss: 1.8210\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9683 - loss: 0.1073 - val_accuracy: 0.6458 - val_loss: 1.9261\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9543 - loss: 0.1364 - val_accuracy: 0.6524 - val_loss: 2.1518\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9527 - loss: 0.1454 - val_accuracy: 0.6371 - val_loss: 2.2937\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9719 - loss: 0.0857 - val_accuracy: 0.6765 - val_loss: 2.1641\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9734 - loss: 0.0789 - val_accuracy: 0.6404 - val_loss: 2.2130\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9923 - loss: 0.0194 - val_accuracy: 0.6700 - val_loss: 2.3394\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 0.6787 - val_loss: 2.1580\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.6919 - val_loss: 2.1090\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.6853 - val_loss: 2.1310\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 4.6762e-04 - val_accuracy: 0.6853 - val_loss: 2.1528\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 1.6776e-04 - val_accuracy: 0.6897 - val_loss: 2.1516\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7001 - loss: 2.1054\n",
            "Test accuracy: 0.6896929740905762\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.2139 - loss: 2.9577 - val_accuracy: 0.4956 - val_loss: 1.7335\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.5309 - loss: 1.5119 - val_accuracy: 0.6096 - val_loss: 1.3129\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.6939 - loss: 0.9074 - val_accuracy: 0.6546 - val_loss: 1.1042\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8150 - loss: 0.6108 - val_accuracy: 0.6952 - val_loss: 1.0501\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8970 - loss: 0.3298 - val_accuracy: 0.6985 - val_loss: 1.0796\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9590 - loss: 0.1597 - val_accuracy: 0.6798 - val_loss: 1.2026\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9711 - loss: 0.1194 - val_accuracy: 0.6996 - val_loss: 1.2105\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9884 - loss: 0.0566 - val_accuracy: 0.7303 - val_loss: 1.1531\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9990 - loss: 0.0146 - val_accuracy: 0.7270 - val_loss: 1.1946\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.7303 - val_loss: 1.2020\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7314 - val_loss: 1.2123\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7325 - val_loss: 1.2353\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7325 - val_loss: 1.2498\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7325 - val_loss: 1.2606\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7314 - val_loss: 1.2810\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7314 - val_loss: 1.2962\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7325 - val_loss: 1.3081\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 9.4948e-04 - val_accuracy: 0.7346 - val_loss: 1.3219\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 8.5454e-04 - val_accuracy: 0.7314 - val_loss: 1.3307\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 7.6769e-04 - val_accuracy: 0.7314 - val_loss: 1.3390\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7457 - loss: 1.2771\n",
            "Test accuracy: 0.7313596606254578\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.1838 - loss: 3.0930 - val_accuracy: 0.5011 - val_loss: 1.7148\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.5918 - loss: 1.4334 - val_accuracy: 0.6118 - val_loss: 1.3362\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.7529 - loss: 0.7881 - val_accuracy: 0.6502 - val_loss: 1.1970\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.8674 - loss: 0.4263 - val_accuracy: 0.6601 - val_loss: 1.1990\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9462 - loss: 0.2057 - val_accuracy: 0.6853 - val_loss: 1.2116\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9722 - loss: 0.1047 - val_accuracy: 0.7072 - val_loss: 1.2216\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9892 - loss: 0.0483 - val_accuracy: 0.7149 - val_loss: 1.2669\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9918 - loss: 0.0314 - val_accuracy: 0.6941 - val_loss: 1.3805\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.7346 - val_loss: 1.2744\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 0.7007 - val_loss: 1.4401\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9930 - loss: 0.0254 - val_accuracy: 0.7215 - val_loss: 1.4571\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9979 - loss: 0.0168 - val_accuracy: 0.7105 - val_loss: 1.5712\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9938 - loss: 0.0265 - val_accuracy: 0.6414 - val_loss: 2.1225\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9382 - loss: 0.1957 - val_accuracy: 0.6546 - val_loss: 1.8975\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9056 - loss: 0.2986 - val_accuracy: 0.6601 - val_loss: 1.7995\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9588 - loss: 0.1209 - val_accuracy: 0.6941 - val_loss: 1.8487\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9860 - loss: 0.0423 - val_accuracy: 0.7007 - val_loss: 1.7613\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9967 - loss: 0.0146 - val_accuracy: 0.7193 - val_loss: 1.6718\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.7259 - val_loss: 1.6017\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 5.1427e-04 - val_accuracy: 0.7292 - val_loss: 1.5978\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7294 - loss: 1.5664\n",
            "Test accuracy: 0.7291666865348816\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - accuracy: 0.2061 - loss: 2.9779 - val_accuracy: 0.4989 - val_loss: 1.7095\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.6047 - loss: 1.3735 - val_accuracy: 0.6195 - val_loss: 1.2713\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.7536 - loss: 0.7995 - val_accuracy: 0.6239 - val_loss: 1.3248\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.8628 - loss: 0.4264 - val_accuracy: 0.6360 - val_loss: 1.5412\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9206 - loss: 0.2283 - val_accuracy: 0.6436 - val_loss: 1.6066\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9519 - loss: 0.1464 - val_accuracy: 0.6064 - val_loss: 2.1244\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9535 - loss: 0.1330 - val_accuracy: 0.6711 - val_loss: 1.9538\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9697 - loss: 0.0906 - val_accuracy: 0.6250 - val_loss: 2.1630\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9729 - loss: 0.0772 - val_accuracy: 0.6360 - val_loss: 2.3271\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9695 - loss: 0.0880 - val_accuracy: 0.6393 - val_loss: 2.5938\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9715 - loss: 0.0976 - val_accuracy: 0.5888 - val_loss: 3.2897\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9536 - loss: 0.1451 - val_accuracy: 0.5800 - val_loss: 3.2155\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9436 - loss: 0.1846 - val_accuracy: 0.6349 - val_loss: 3.1629\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9534 - loss: 0.1776 - val_accuracy: 0.5899 - val_loss: 3.1597\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.9647 - loss: 0.1208 - val_accuracy: 0.5965 - val_loss: 3.4707\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9758 - loss: 0.0754 - val_accuracy: 0.6349 - val_loss: 3.0527\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9848 - loss: 0.0524 - val_accuracy: 0.6447 - val_loss: 3.1179\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9940 - loss: 0.0156 - val_accuracy: 0.6590 - val_loss: 2.8923\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.6557 - val_loss: 2.9660\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.6480 - val_loss: 3.0713\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6581 - loss: 2.9356\n",
            "Test accuracy: 0.6480262875556946\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.2311 - loss: 2.9863 - val_accuracy: 0.5910 - val_loss: 1.4192\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.6618 - loss: 1.1456 - val_accuracy: 0.6349 - val_loss: 1.1913\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.8229 - loss: 0.5634 - val_accuracy: 0.6623 - val_loss: 1.2303\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9040 - loss: 0.2960 - val_accuracy: 0.6469 - val_loss: 1.4704\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9345 - loss: 0.2003 - val_accuracy: 0.6700 - val_loss: 1.6717\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9602 - loss: 0.1181 - val_accuracy: 0.6568 - val_loss: 1.6766\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9672 - loss: 0.0986 - val_accuracy: 0.6645 - val_loss: 1.8426\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9763 - loss: 0.0743 - val_accuracy: 0.6414 - val_loss: 2.2639\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9653 - loss: 0.1133 - val_accuracy: 0.6414 - val_loss: 2.0319\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9749 - loss: 0.0700 - val_accuracy: 0.6458 - val_loss: 2.2954\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9846 - loss: 0.0571 - val_accuracy: 0.6535 - val_loss: 2.3488\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9500 - loss: 0.1650 - val_accuracy: 0.6239 - val_loss: 3.0216\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9372 - loss: 0.2556 - val_accuracy: 0.6338 - val_loss: 3.3430\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9017 - loss: 0.4523 - val_accuracy: 0.6250 - val_loss: 3.1152\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9463 - loss: 0.2061 - val_accuracy: 0.6360 - val_loss: 3.2601\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9767 - loss: 0.0965 - val_accuracy: 0.6743 - val_loss: 2.7868\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9941 - loss: 0.0298 - val_accuracy: 0.6886 - val_loss: 2.8233\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0065 - val_accuracy: 0.6645 - val_loss: 3.0798\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9971 - loss: 0.0232 - val_accuracy: 0.6623 - val_loss: 2.8735\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9962 - loss: 0.0154 - val_accuracy: 0.6765 - val_loss: 2.8694\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6994 - loss: 2.6035\n",
            "Test accuracy: 0.6765350699424744\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.1908 - loss: 3.0152 - val_accuracy: 0.4825 - val_loss: 1.8503\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.5879 - loss: 1.4236 - val_accuracy: 0.5943 - val_loss: 1.3771\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.7295 - loss: 0.8634 - val_accuracy: 0.6469 - val_loss: 1.2237\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.8526 - loss: 0.4623 - val_accuracy: 0.6568 - val_loss: 1.3840\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9069 - loss: 0.2882 - val_accuracy: 0.6700 - val_loss: 1.3659\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9479 - loss: 0.1538 - val_accuracy: 0.6798 - val_loss: 1.4727\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9766 - loss: 0.0773 - val_accuracy: 0.6765 - val_loss: 1.4587\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9876 - loss: 0.0364 - val_accuracy: 0.6875 - val_loss: 1.5706\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9974 - loss: 0.0161 - val_accuracy: 0.6765 - val_loss: 1.6579\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9932 - loss: 0.0207 - val_accuracy: 0.6952 - val_loss: 1.6299\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9967 - loss: 0.0155 - val_accuracy: 0.6963 - val_loss: 1.7167\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7029 - val_loss: 1.7189\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 7.8693e-04 - val_accuracy: 0.7018 - val_loss: 1.7279\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 6.3010e-04 - val_accuracy: 0.7039 - val_loss: 1.7413\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 5.0696e-04 - val_accuracy: 0.7061 - val_loss: 1.7545\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.4552e-04 - val_accuracy: 0.7007 - val_loss: 1.7667\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.7044e-04 - val_accuracy: 0.7007 - val_loss: 1.7793\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.3924e-04 - val_accuracy: 0.7007 - val_loss: 1.7900\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.8120e-04 - val_accuracy: 0.6996 - val_loss: 1.7993\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.5742e-04 - val_accuracy: 0.6996 - val_loss: 1.8110\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7133 - loss: 1.8224\n",
            "Test accuracy: 0.6995614171028137\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.2450 - loss: 2.8168 - val_accuracy: 0.5614 - val_loss: 1.4961\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.6523 - loss: 1.1357 - val_accuracy: 0.6776 - val_loss: 1.0863\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.8085 - loss: 0.6155 - val_accuracy: 0.6678 - val_loss: 1.1244\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.8891 - loss: 0.3482 - val_accuracy: 0.6919 - val_loss: 1.1681\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9433 - loss: 0.1756 - val_accuracy: 0.6985 - val_loss: 1.2611\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9803 - loss: 0.0809 - val_accuracy: 0.7215 - val_loss: 1.2579\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9949 - loss: 0.0257 - val_accuracy: 0.7248 - val_loss: 1.3885\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9933 - loss: 0.0262 - val_accuracy: 0.7368 - val_loss: 1.3071\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7533 - val_loss: 1.2958\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 9.6389e-04 - val_accuracy: 0.7533 - val_loss: 1.3140\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 6.7759e-04 - val_accuracy: 0.7566 - val_loss: 1.3266\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 5.0918e-04 - val_accuracy: 0.7588 - val_loss: 1.3406\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 4.1610e-04 - val_accuracy: 0.7599 - val_loss: 1.3555\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 3.6246e-04 - val_accuracy: 0.7621 - val_loss: 1.3670\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 3.1101e-04 - val_accuracy: 0.7621 - val_loss: 1.3769\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.5925e-04 - val_accuracy: 0.7643 - val_loss: 1.3879\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.3208e-04 - val_accuracy: 0.7643 - val_loss: 1.3963\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 2.1688e-04 - val_accuracy: 0.7643 - val_loss: 1.4075\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.8665e-04 - val_accuracy: 0.7632 - val_loss: 1.4177\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.7252e-04 - val_accuracy: 0.7632 - val_loss: 1.4256\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7739 - loss: 1.3426\n",
            "Test accuracy: 0.7631579041481018\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.1935 - loss: 3.0798 - val_accuracy: 0.5208 - val_loss: 1.6319\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.6112 - loss: 1.3653 - val_accuracy: 0.5691 - val_loss: 1.4823\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.7499 - loss: 0.7827 - val_accuracy: 0.6031 - val_loss: 1.3269\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - accuracy: 0.8617 - loss: 0.4535 - val_accuracy: 0.5976 - val_loss: 1.5228\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9258 - loss: 0.2315 - val_accuracy: 0.6173 - val_loss: 1.7417\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9525 - loss: 0.1277 - val_accuracy: 0.6239 - val_loss: 1.9797\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9676 - loss: 0.0957 - val_accuracy: 0.6195 - val_loss: 2.2553\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9570 - loss: 0.1223 - val_accuracy: 0.6151 - val_loss: 2.3821\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9337 - loss: 0.2138 - val_accuracy: 0.5548 - val_loss: 3.0018\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9192 - loss: 0.2649 - val_accuracy: 0.6075 - val_loss: 2.8583\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9620 - loss: 0.1308 - val_accuracy: 0.5987 - val_loss: 3.0971\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9686 - loss: 0.1221 - val_accuracy: 0.5757 - val_loss: 3.4403\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9568 - loss: 0.1606 - val_accuracy: 0.6053 - val_loss: 3.3229\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9651 - loss: 0.1155 - val_accuracy: 0.6140 - val_loss: 3.4400\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9729 - loss: 0.1064 - val_accuracy: 0.6129 - val_loss: 3.5275\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9776 - loss: 0.0706 - val_accuracy: 0.5954 - val_loss: 3.8042\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9841 - loss: 0.0516 - val_accuracy: 0.6195 - val_loss: 3.7575\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9898 - loss: 0.0343 - val_accuracy: 0.6042 - val_loss: 3.8433\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9809 - loss: 0.0568 - val_accuracy: 0.5768 - val_loss: 4.1006\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9814 - loss: 0.0750 - val_accuracy: 0.5833 - val_loss: 4.2468\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6239 - loss: 3.6510\n",
            "Test accuracy: 0.5833333134651184\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - accuracy: 0.2262 - loss: 3.0049 - val_accuracy: 0.5647 - val_loss: 1.5024\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.6431 - loss: 1.1797 - val_accuracy: 0.6294 - val_loss: 1.1949\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.8116 - loss: 0.6191 - val_accuracy: 0.6776 - val_loss: 1.1803\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9246 - loss: 0.2366 - val_accuracy: 0.6382 - val_loss: 1.4825\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9468 - loss: 0.1746 - val_accuracy: 0.6217 - val_loss: 1.6575\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9524 - loss: 0.1448 - val_accuracy: 0.6349 - val_loss: 1.8870\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9614 - loss: 0.1300 - val_accuracy: 0.6404 - val_loss: 2.1070\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9626 - loss: 0.1250 - val_accuracy: 0.6349 - val_loss: 2.2524\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9655 - loss: 0.1175 - val_accuracy: 0.6228 - val_loss: 2.6715\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9632 - loss: 0.1451 - val_accuracy: 0.6140 - val_loss: 2.7031\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9372 - loss: 0.2469 - val_accuracy: 0.6250 - val_loss: 2.7978\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.9423 - loss: 0.2194 - val_accuracy: 0.5811 - val_loss: 3.3457\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9567 - loss: 0.1687 - val_accuracy: 0.6491 - val_loss: 3.1471\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9690 - loss: 0.1175 - val_accuracy: 0.6140 - val_loss: 3.3785\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9656 - loss: 0.1368 - val_accuracy: 0.6206 - val_loss: 3.5209\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9819 - loss: 0.0647 - val_accuracy: 0.6118 - val_loss: 3.7884\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9623 - loss: 0.1664 - val_accuracy: 0.6228 - val_loss: 3.7591\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9815 - loss: 0.0653 - val_accuracy: 0.6195 - val_loss: 3.9555\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.9763 - loss: 0.0887 - val_accuracy: 0.6206 - val_loss: 4.4361\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9832 - loss: 0.0720 - val_accuracy: 0.6447 - val_loss: 3.6121\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6547 - loss: 3.4394\n",
            "Test accuracy: 0.6447368264198303\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.1790 - loss: 3.0412 - val_accuracy: 0.4748 - val_loss: 1.8447\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.5659 - loss: 1.4763 - val_accuracy: 0.5691 - val_loss: 1.4027\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.7532 - loss: 0.8124 - val_accuracy: 0.6086 - val_loss: 1.3934\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.8846 - loss: 0.3890 - val_accuracy: 0.6217 - val_loss: 1.4104\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9536 - loss: 0.1762 - val_accuracy: 0.6031 - val_loss: 1.5952\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9858 - loss: 0.0765 - val_accuracy: 0.6491 - val_loss: 1.6113\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9959 - loss: 0.0266 - val_accuracy: 0.6546 - val_loss: 1.6782\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9996 - loss: 0.0076 - val_accuracy: 0.6491 - val_loss: 1.7267\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.6557 - val_loss: 1.7129\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6579 - val_loss: 1.7497\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6557 - val_loss: 1.7783\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6546 - val_loss: 1.8042\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 9.8952e-04 - val_accuracy: 0.6524 - val_loss: 1.8266\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 8.3878e-04 - val_accuracy: 0.6579 - val_loss: 1.8443\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 6.9174e-04 - val_accuracy: 0.6535 - val_loss: 1.8678\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 6.0281e-04 - val_accuracy: 0.6546 - val_loss: 1.8850\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 5.3982e-04 - val_accuracy: 0.6590 - val_loss: 1.9049\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 4.8315e-04 - val_accuracy: 0.6546 - val_loss: 1.9212\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 4.2806e-04 - val_accuracy: 0.6524 - val_loss: 1.9367\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 3.9192e-04 - val_accuracy: 0.6579 - val_loss: 1.9483\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7035 - loss: 1.7291\n",
            "Test accuracy: 0.6578947305679321\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.2194 - loss: 2.9684 - val_accuracy: 0.5230 - val_loss: 1.6166\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.6670 - loss: 1.1662 - val_accuracy: 0.6162 - val_loss: 1.2479\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 0.8485 - loss: 0.5077 - val_accuracy: 0.6118 - val_loss: 1.3977\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.9462 - loss: 0.1772 - val_accuracy: 0.6458 - val_loss: 1.4358\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.9813 - loss: 0.0687 - val_accuracy: 0.6502 - val_loss: 1.5263\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.9967 - loss: 0.0199 - val_accuracy: 0.6864 - val_loss: 1.4546\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 0.9983 - loss: 0.0088 - val_accuracy: 0.6897 - val_loss: 1.4773\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6963 - val_loss: 1.4984\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7007 - val_loss: 1.5255\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 7.7836e-04 - val_accuracy: 0.7039 - val_loss: 1.5372\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 6.2584e-04 - val_accuracy: 0.7029 - val_loss: 1.5514\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 4.9137e-04 - val_accuracy: 0.7050 - val_loss: 1.5699\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 4.4585e-04 - val_accuracy: 0.7050 - val_loss: 1.5814\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 3.9195e-04 - val_accuracy: 0.7050 - val_loss: 1.5919\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 3.2570e-04 - val_accuracy: 0.7061 - val_loss: 1.6020\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.9115e-04 - val_accuracy: 0.7072 - val_loss: 1.6140\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.5522e-04 - val_accuracy: 0.7072 - val_loss: 1.6262\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.2568e-04 - val_accuracy: 0.7061 - val_loss: 1.6363\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.0443e-04 - val_accuracy: 0.7050 - val_loss: 1.6448\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.8363e-04 - val_accuracy: 0.7061 - val_loss: 1.6557\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7253 - loss: 1.5208\n",
            "Test accuracy: 0.7061403393745422\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.2272 - loss: 2.9832 - val_accuracy: 0.5274 - val_loss: 1.7205\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.6659 - loss: 1.1207 - val_accuracy: 0.5789 - val_loss: 1.3762\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.8590 - loss: 0.4652 - val_accuracy: 0.5680 - val_loss: 1.6040\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9464 - loss: 0.1926 - val_accuracy: 0.5910 - val_loss: 1.9320\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9814 - loss: 0.0618 - val_accuracy: 0.6173 - val_loss: 2.3391\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9851 - loss: 0.0451 - val_accuracy: 0.6173 - val_loss: 2.4845\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9833 - loss: 0.0504 - val_accuracy: 0.5186 - val_loss: 3.0255\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9460 - loss: 0.1705 - val_accuracy: 0.5274 - val_loss: 3.3028\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9276 - loss: 0.2481 - val_accuracy: 0.5175 - val_loss: 3.7120\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9458 - loss: 0.2144 - val_accuracy: 0.5504 - val_loss: 4.1703\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9613 - loss: 0.1515 - val_accuracy: 0.5044 - val_loss: 3.9521\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9722 - loss: 0.0960 - val_accuracy: 0.5526 - val_loss: 3.9479\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9876 - loss: 0.0386 - val_accuracy: 0.5384 - val_loss: 4.2449\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9957 - loss: 0.0255 - val_accuracy: 0.5351 - val_loss: 4.2805\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9928 - loss: 0.0303 - val_accuracy: 0.5581 - val_loss: 4.3225\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.5592 - val_loss: 4.3263\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 0.5921 - val_loss: 4.5965\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9965 - loss: 0.0147 - val_accuracy: 0.5570 - val_loss: 4.4857\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9756 - loss: 0.1162 - val_accuracy: 0.5417 - val_loss: 5.8131\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.9558 - loss: 0.2182 - val_accuracy: 0.5406 - val_loss: 5.0485\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5707 - loss: 4.4105\n",
            "Test accuracy: 0.5405701994895935\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.2293 - loss: 2.9151 - val_accuracy: 0.5450 - val_loss: 1.5608\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.7012 - loss: 1.0043 - val_accuracy: 0.6283 - val_loss: 1.2938\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.8969 - loss: 0.3327 - val_accuracy: 0.6020 - val_loss: 1.5333\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9665 - loss: 0.1196 - val_accuracy: 0.6502 - val_loss: 1.7789\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9888 - loss: 0.0452 - val_accuracy: 0.6217 - val_loss: 2.0635\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9837 - loss: 0.0620 - val_accuracy: 0.6140 - val_loss: 2.4230\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9463 - loss: 0.1914 - val_accuracy: 0.5899 - val_loss: 2.6435\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9449 - loss: 0.1844 - val_accuracy: 0.5757 - val_loss: 2.8068\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9522 - loss: 0.1290 - val_accuracy: 0.5559 - val_loss: 2.9458\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9729 - loss: 0.1098 - val_accuracy: 0.5932 - val_loss: 3.1065\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9850 - loss: 0.0522 - val_accuracy: 0.5614 - val_loss: 3.3874\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9807 - loss: 0.0709 - val_accuracy: 0.5811 - val_loss: 3.4603\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9863 - loss: 0.0379 - val_accuracy: 0.6009 - val_loss: 3.7389\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9934 - loss: 0.0202 - val_accuracy: 0.5855 - val_loss: 3.6436\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9910 - loss: 0.0279 - val_accuracy: 0.5230 - val_loss: 4.8141\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9742 - loss: 0.1048 - val_accuracy: 0.5011 - val_loss: 5.8056\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9211 - loss: 0.3782 - val_accuracy: 0.5186 - val_loss: 5.3040\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9014 - loss: 0.5141 - val_accuracy: 0.5482 - val_loss: 5.5574\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9514 - loss: 0.2830 - val_accuracy: 0.5559 - val_loss: 5.1139\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9656 - loss: 0.1707 - val_accuracy: 0.5658 - val_loss: 4.8419\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5702 - loss: 4.7157\n",
            "Test accuracy: 0.5657894611358643\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.1875 - loss: 2.9893 - val_accuracy: 0.5132 - val_loss: 1.6904\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 137ms/step - accuracy: 0.6134 - loss: 1.2733 - val_accuracy: 0.5910 - val_loss: 1.3755\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.7792 - loss: 0.6929 - val_accuracy: 0.6009 - val_loss: 1.3905\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 138ms/step - accuracy: 0.8961 - loss: 0.3602 - val_accuracy: 0.6053 - val_loss: 1.5312\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9499 - loss: 0.1507 - val_accuracy: 0.6086 - val_loss: 1.6939\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9795 - loss: 0.0767 - val_accuracy: 0.6239 - val_loss: 1.9325\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9909 - loss: 0.0400 - val_accuracy: 0.6173 - val_loss: 2.0758\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9879 - loss: 0.0417 - val_accuracy: 0.6009 - val_loss: 2.2340\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 138ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.6064 - val_loss: 2.2459\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9907 - loss: 0.0364 - val_accuracy: 0.5888 - val_loss: 2.4236\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9700 - loss: 0.0952 - val_accuracy: 0.5493 - val_loss: 2.8523\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9029 - loss: 0.3313 - val_accuracy: 0.5384 - val_loss: 2.8793\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 0.9375 - loss: 0.2057 - val_accuracy: 0.5976 - val_loss: 2.7395\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9735 - loss: 0.0721 - val_accuracy: 0.5844 - val_loss: 2.9309\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.5789 - val_loss: 3.1052\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9937 - loss: 0.0164 - val_accuracy: 0.6107 - val_loss: 2.7953\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6064 - val_loss: 2.7764\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 4.1468e-04 - val_accuracy: 0.6053 - val_loss: 2.7975\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.9919e-04 - val_accuracy: 0.6042 - val_loss: 2.8111\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.7420e-04 - val_accuracy: 0.6042 - val_loss: 2.8232\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6317 - loss: 2.6701\n",
            "Test accuracy: 0.6041666865348816\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 150ms/step - accuracy: 0.2335 - loss: 2.7872 - val_accuracy: 0.5559 - val_loss: 1.4663\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.6807 - loss: 1.0296 - val_accuracy: 0.5779 - val_loss: 1.4503\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.8558 - loss: 0.4535 - val_accuracy: 0.6042 - val_loss: 1.4227\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9398 - loss: 0.1924 - val_accuracy: 0.6283 - val_loss: 1.6945\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9729 - loss: 0.0845 - val_accuracy: 0.6250 - val_loss: 1.8855\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9758 - loss: 0.0854 - val_accuracy: 0.6425 - val_loss: 1.8920\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9920 - loss: 0.0331 - val_accuracy: 0.6338 - val_loss: 1.9593\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9896 - loss: 0.0405 - val_accuracy: 0.5833 - val_loss: 2.7236\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9601 - loss: 0.1378 - val_accuracy: 0.5998 - val_loss: 2.5127\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9344 - loss: 0.2098 - val_accuracy: 0.5833 - val_loss: 2.7468\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9313 - loss: 0.2569 - val_accuracy: 0.6042 - val_loss: 2.6266\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9539 - loss: 0.1425 - val_accuracy: 0.6107 - val_loss: 2.6731\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9802 - loss: 0.0605 - val_accuracy: 0.6020 - val_loss: 2.8154\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9970 - loss: 0.0114 - val_accuracy: 0.6414 - val_loss: 2.6638\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.6425 - val_loss: 2.8167\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 150ms/step - accuracy: 0.9977 - loss: 0.0050 - val_accuracy: 0.6305 - val_loss: 2.9005\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9965 - loss: 0.0126 - val_accuracy: 0.6086 - val_loss: 3.1051\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9957 - loss: 0.0106 - val_accuracy: 0.6491 - val_loss: 2.7681\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6590 - val_loss: 2.6523\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 1.4553e-04 - val_accuracy: 0.6601 - val_loss: 2.6820\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6813 - loss: 2.4220\n",
            "Test accuracy: 0.6600877046585083\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 172ms/step - accuracy: 0.1932 - loss: 3.3379 - val_accuracy: 0.4967 - val_loss: 1.7925\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.5865 - loss: 1.4197 - val_accuracy: 0.5088 - val_loss: 1.7290\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.8164 - loss: 0.5905 - val_accuracy: 0.5526 - val_loss: 1.6869\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9380 - loss: 0.2071 - val_accuracy: 0.5548 - val_loss: 2.2561\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9575 - loss: 0.1277 - val_accuracy: 0.5559 - val_loss: 2.5505\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9688 - loss: 0.1058 - val_accuracy: 0.5439 - val_loss: 2.7516\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9736 - loss: 0.0799 - val_accuracy: 0.5208 - val_loss: 3.1885\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9614 - loss: 0.1268 - val_accuracy: 0.5461 - val_loss: 3.6622\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9503 - loss: 0.1580 - val_accuracy: 0.4989 - val_loss: 4.0902\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9409 - loss: 0.2361 - val_accuracy: 0.5132 - val_loss: 4.7215\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9209 - loss: 0.3242 - val_accuracy: 0.5362 - val_loss: 4.2269\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9563 - loss: 0.1838 - val_accuracy: 0.5241 - val_loss: 4.4108\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9847 - loss: 0.0494 - val_accuracy: 0.5307 - val_loss: 4.6050\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9896 - loss: 0.0314 - val_accuracy: 0.5636 - val_loss: 4.1757\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.5603 - val_loss: 4.3908\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9990 - loss: 0.0016 - val_accuracy: 0.5779 - val_loss: 4.3438\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 1.3029e-04 - val_accuracy: 0.5789 - val_loss: 4.3161\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 9.7913e-05 - val_accuracy: 0.5800 - val_loss: 4.3310\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 7.0412e-05 - val_accuracy: 0.5800 - val_loss: 4.3440\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 5.9660e-05 - val_accuracy: 0.5811 - val_loss: 4.3540\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5954 - loss: 4.0592\n",
            "Test accuracy: 0.5811403393745422\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.1621 - loss: 3.6543 - val_accuracy: 0.5307 - val_loss: 1.5908\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.6187 - loss: 1.2661 - val_accuracy: 0.6184 - val_loss: 1.3255\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.8473 - loss: 0.4920 - val_accuracy: 0.5943 - val_loss: 1.5326\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9393 - loss: 0.1853 - val_accuracy: 0.5779 - val_loss: 1.8116\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9642 - loss: 0.1096 - val_accuracy: 0.5768 - val_loss: 2.1284\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9890 - loss: 0.0431 - val_accuracy: 0.6020 - val_loss: 2.2555\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9906 - loss: 0.0277 - val_accuracy: 0.5746 - val_loss: 2.4078\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 209ms/step - accuracy: 0.9896 - loss: 0.0329 - val_accuracy: 0.5691 - val_loss: 2.8722\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9606 - loss: 0.1393 - val_accuracy: 0.5263 - val_loss: 3.3807\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9193 - loss: 0.2804 - val_accuracy: 0.5515 - val_loss: 3.7358\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 209ms/step - accuracy: 0.9120 - loss: 0.3771 - val_accuracy: 0.5461 - val_loss: 3.5188\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9433 - loss: 0.2114 - val_accuracy: 0.5570 - val_loss: 3.8081\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9701 - loss: 0.1303 - val_accuracy: 0.5362 - val_loss: 3.7862\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9799 - loss: 0.0823 - val_accuracy: 0.5406 - val_loss: 3.9435\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9799 - loss: 0.0695 - val_accuracy: 0.5395 - val_loss: 4.0806\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9914 - loss: 0.0400 - val_accuracy: 0.5603 - val_loss: 4.2350\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9918 - loss: 0.0272 - val_accuracy: 0.5614 - val_loss: 4.2226\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9960 - loss: 0.0148 - val_accuracy: 0.5461 - val_loss: 4.4571\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - accuracy: 0.9899 - loss: 0.0443 - val_accuracy: 0.5844 - val_loss: 4.2507\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - accuracy: 0.9965 - loss: 0.0221 - val_accuracy: 0.5373 - val_loss: 4.7295\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5532 - loss: 4.1302\n",
            "Test accuracy: 0.5372806787490845\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 217ms/step - accuracy: 0.1564 - loss: 3.2322 - val_accuracy: 0.4561 - val_loss: 1.8287\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.5634 - loss: 1.4907 - val_accuracy: 0.5461 - val_loss: 1.5457\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.7237 - loss: 0.9184 - val_accuracy: 0.5976 - val_loss: 1.4774\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.8594 - loss: 0.4798 - val_accuracy: 0.5450 - val_loss: 1.9408\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.9162 - loss: 0.2747 - val_accuracy: 0.5548 - val_loss: 2.0426\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9634 - loss: 0.1189 - val_accuracy: 0.5746 - val_loss: 2.3622\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.9781 - loss: 0.0778 - val_accuracy: 0.5669 - val_loss: 2.5926\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.9819 - loss: 0.0646 - val_accuracy: 0.5537 - val_loss: 2.7717\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9632 - loss: 0.1110 - val_accuracy: 0.5307 - val_loss: 3.2428\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9526 - loss: 0.1618 - val_accuracy: 0.5537 - val_loss: 3.1818\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9606 - loss: 0.1362 - val_accuracy: 0.5296 - val_loss: 3.3058\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9516 - loss: 0.1416 - val_accuracy: 0.5373 - val_loss: 3.4622\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9680 - loss: 0.1009 - val_accuracy: 0.5757 - val_loss: 2.9828\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9908 - loss: 0.0321 - val_accuracy: 0.5800 - val_loss: 3.1648\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.9979 - loss: 0.0099 - val_accuracy: 0.5965 - val_loss: 3.0386\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.9991 - loss: 0.0072 - val_accuracy: 0.5822 - val_loss: 3.4971\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.5811 - val_loss: 3.2027\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.5757 - val_loss: 3.3342\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.9981 - loss: 0.0032 - val_accuracy: 0.5735 - val_loss: 3.5042\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 6.7589e-04 - val_accuracy: 0.5855 - val_loss: 3.3837\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6320 - loss: 2.9471\n",
            "Test accuracy: 0.5855262875556946\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 234ms/step - accuracy: 0.2334 - loss: 2.9374 - val_accuracy: 0.5691 - val_loss: 1.4211\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.7165 - loss: 0.9961 - val_accuracy: 0.6425 - val_loss: 1.2648\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.8803 - loss: 0.3881 - val_accuracy: 0.5987 - val_loss: 1.4392\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9518 - loss: 0.1567 - val_accuracy: 0.6480 - val_loss: 1.6551\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9731 - loss: 0.0849 - val_accuracy: 0.6305 - val_loss: 1.8487\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 231ms/step - accuracy: 0.9826 - loss: 0.0583 - val_accuracy: 0.5998 - val_loss: 2.1762\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 233ms/step - accuracy: 0.9876 - loss: 0.0466 - val_accuracy: 0.6162 - val_loss: 2.4096\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9537 - loss: 0.1618 - val_accuracy: 0.5811 - val_loss: 3.1219\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9190 - loss: 0.2878 - val_accuracy: 0.5713 - val_loss: 2.9850\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9396 - loss: 0.2124 - val_accuracy: 0.5537 - val_loss: 3.8463\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9334 - loss: 0.2588 - val_accuracy: 0.5899 - val_loss: 3.6969\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9513 - loss: 0.1747 - val_accuracy: 0.6086 - val_loss: 3.3616\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9718 - loss: 0.0871 - val_accuracy: 0.6327 - val_loss: 3.1000\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9906 - loss: 0.0228 - val_accuracy: 0.6228 - val_loss: 3.3500\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9955 - loss: 0.0128 - val_accuracy: 0.6502 - val_loss: 3.0779\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 233ms/step - accuracy: 0.9954 - loss: 0.0142 - val_accuracy: 0.6053 - val_loss: 3.6973\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9845 - loss: 0.0618 - val_accuracy: 0.6360 - val_loss: 3.6908\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9888 - loss: 0.0391 - val_accuracy: 0.6382 - val_loss: 3.5991\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 233ms/step - accuracy: 0.9901 - loss: 0.0329 - val_accuracy: 0.6107 - val_loss: 3.9630\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 232ms/step - accuracy: 0.9842 - loss: 0.0527 - val_accuracy: 0.6228 - val_loss: 3.9055\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.6673 - loss: 3.2983\n",
            "Test accuracy: 0.6228070259094238\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 279ms/step - accuracy: 0.1320 - loss: 4.0283 - val_accuracy: 0.3925 - val_loss: 2.0457\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.5269 - loss: 1.5711 - val_accuracy: 0.5197 - val_loss: 1.7039\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.7873 - loss: 0.6986 - val_accuracy: 0.5471 - val_loss: 1.8539\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9267 - loss: 0.2606 - val_accuracy: 0.5669 - val_loss: 2.0052\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9612 - loss: 0.1497 - val_accuracy: 0.5603 - val_loss: 2.2290\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9778 - loss: 0.0730 - val_accuracy: 0.5735 - val_loss: 2.7231\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9752 - loss: 0.0813 - val_accuracy: 0.5439 - val_loss: 3.2867\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9637 - loss: 0.1152 - val_accuracy: 0.4704 - val_loss: 3.5270\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.9418 - loss: 0.1993 - val_accuracy: 0.5121 - val_loss: 3.4675\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9184 - loss: 0.2925 - val_accuracy: 0.4978 - val_loss: 4.5713\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.9238 - loss: 0.3430 - val_accuracy: 0.4145 - val_loss: 5.1272\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.8956 - loss: 0.5576 - val_accuracy: 0.4836 - val_loss: 5.1736\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9326 - loss: 0.3034 - val_accuracy: 0.5143 - val_loss: 5.1942\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9543 - loss: 0.2088 - val_accuracy: 0.5208 - val_loss: 5.2878\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 277ms/step - accuracy: 0.9748 - loss: 0.1042 - val_accuracy: 0.5154 - val_loss: 5.2551\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9889 - loss: 0.0488 - val_accuracy: 0.5439 - val_loss: 5.1611\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9887 - loss: 0.0383 - val_accuracy: 0.5241 - val_loss: 5.3880\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9932 - loss: 0.0236 - val_accuracy: 0.5384 - val_loss: 5.5928\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9967 - loss: 0.0066 - val_accuracy: 0.5570 - val_loss: 5.3941\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.9987 - loss: 0.0028 - val_accuracy: 0.5439 - val_loss: 5.2887\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5946 - loss: 4.6347\n",
            "Test accuracy: 0.5438596606254578\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 358ms/step - accuracy: 0.1675 - loss: 4.4979 - val_accuracy: 0.4671 - val_loss: 1.7582\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.6216 - loss: 1.2577 - val_accuracy: 0.5636 - val_loss: 1.5419\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.8632 - loss: 0.4579 - val_accuracy: 0.5395 - val_loss: 1.7528\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 357ms/step - accuracy: 0.9597 - loss: 0.1480 - val_accuracy: 0.5614 - val_loss: 2.2713\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9620 - loss: 0.1210 - val_accuracy: 0.5219 - val_loss: 2.5281\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9660 - loss: 0.1063 - val_accuracy: 0.5373 - val_loss: 2.7586\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9666 - loss: 0.1013 - val_accuracy: 0.5406 - val_loss: 3.7550\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 355ms/step - accuracy: 0.9467 - loss: 0.1805 - val_accuracy: 0.4825 - val_loss: 3.6672\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 355ms/step - accuracy: 0.9420 - loss: 0.2248 - val_accuracy: 0.4890 - val_loss: 4.1827\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9482 - loss: 0.1794 - val_accuracy: 0.4605 - val_loss: 4.8697\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9425 - loss: 0.2498 - val_accuracy: 0.5219 - val_loss: 5.3130\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 361ms/step - accuracy: 0.9379 - loss: 0.2809 - val_accuracy: 0.5011 - val_loss: 4.9567\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9540 - loss: 0.2271 - val_accuracy: 0.4989 - val_loss: 5.7513\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 357ms/step - accuracy: 0.9498 - loss: 0.2408 - val_accuracy: 0.4759 - val_loss: 6.8452\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 356ms/step - accuracy: 0.9647 - loss: 0.1682 - val_accuracy: 0.4879 - val_loss: 6.7572\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 355ms/step - accuracy: 0.9638 - loss: 0.2036 - val_accuracy: 0.5428 - val_loss: 5.7369\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 357ms/step - accuracy: 0.9727 - loss: 0.1588 - val_accuracy: 0.5395 - val_loss: 6.4338\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 362ms/step - accuracy: 0.9725 - loss: 0.1175 - val_accuracy: 0.5164 - val_loss: 7.1345\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22824s\u001b[0m 204s/step - accuracy: 0.9813 - loss: 0.0959 - val_accuracy: 0.5373 - val_loss: 6.8379\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 360ms/step - accuracy: 0.9843 - loss: 0.0706 - val_accuracy: 0.5241 - val_loss: 7.2723\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5537 - loss: 6.3251\n",
            "Test accuracy: 0.5241228342056274\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.1716 - loss: 3.0682 - val_accuracy: 0.4923 - val_loss: 1.8005\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.5176 - loss: 1.5947 - val_accuracy: 0.5789 - val_loss: 1.3606\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.6877 - loss: 1.0143 - val_accuracy: 0.6217 - val_loss: 1.1968\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7728 - loss: 0.7132 - val_accuracy: 0.6941 - val_loss: 1.0598\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.8552 - loss: 0.4682 - val_accuracy: 0.6787 - val_loss: 1.0754\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9021 - loss: 0.3232 - val_accuracy: 0.7007 - val_loss: 1.0927\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9526 - loss: 0.1809 - val_accuracy: 0.7204 - val_loss: 1.1258\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9827 - loss: 0.0971 - val_accuracy: 0.6908 - val_loss: 1.1807\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.9937 - loss: 0.0517 - val_accuracy: 0.7303 - val_loss: 1.1651\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9983 - loss: 0.0226 - val_accuracy: 0.7270 - val_loss: 1.2036\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.7401 - val_loss: 1.2048\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7379 - val_loss: 1.2385\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7357 - val_loss: 1.2672\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7445 - val_loss: 1.2839\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7379 - val_loss: 1.3063\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7445 - val_loss: 1.3154\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7456 - val_loss: 1.3368\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7445 - val_loss: 1.3565\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7401 - val_loss: 1.3765\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7434 - val_loss: 1.3751\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7511 - loss: 1.3089\n",
            "Test accuracy: 0.7434210777282715\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.1745 - loss: 3.1327 - val_accuracy: 0.4781 - val_loss: 1.7380\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.5653 - loss: 1.4274 - val_accuracy: 0.6228 - val_loss: 1.3048\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7374 - loss: 0.8296 - val_accuracy: 0.7018 - val_loss: 1.0382\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.8452 - loss: 0.4703 - val_accuracy: 0.7029 - val_loss: 1.0353\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9114 - loss: 0.2685 - val_accuracy: 0.7204 - val_loss: 1.0130\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9659 - loss: 0.1382 - val_accuracy: 0.7336 - val_loss: 1.0399\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9866 - loss: 0.0599 - val_accuracy: 0.7292 - val_loss: 1.1050\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9961 - loss: 0.0247 - val_accuracy: 0.7303 - val_loss: 1.1394\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9906 - loss: 0.0353 - val_accuracy: 0.7456 - val_loss: 1.1090\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.7544 - val_loss: 1.1195\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7544 - val_loss: 1.1104\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7533 - val_loss: 1.1384\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7555 - val_loss: 1.1471\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7588 - val_loss: 1.1608\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7555 - val_loss: 1.1780\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7599 - val_loss: 1.1872\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 8.9542e-04 - val_accuracy: 0.7610 - val_loss: 1.1909\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 7.9106e-04 - val_accuracy: 0.7588 - val_loss: 1.2070\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 7.1226e-04 - val_accuracy: 0.7555 - val_loss: 1.2175\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 6.2894e-04 - val_accuracy: 0.7599 - val_loss: 1.2253\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7735 - loss: 1.1030\n",
            "Test accuracy: 0.7598684430122375\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.1785 - loss: 3.0476 - val_accuracy: 0.4693 - val_loss: 1.8177\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.5453 - loss: 1.5170 - val_accuracy: 0.5548 - val_loss: 1.5220\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7100 - loss: 0.9253 - val_accuracy: 0.6107 - val_loss: 1.3557\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8532 - loss: 0.4584 - val_accuracy: 0.6250 - val_loss: 1.3543\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9394 - loss: 0.2160 - val_accuracy: 0.6557 - val_loss: 1.3640\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9749 - loss: 0.0904 - val_accuracy: 0.6689 - val_loss: 1.5957\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9832 - loss: 0.0628 - val_accuracy: 0.6656 - val_loss: 1.6842\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9955 - loss: 0.0238 - val_accuracy: 0.6689 - val_loss: 1.8309\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9962 - loss: 0.0198 - val_accuracy: 0.6579 - val_loss: 2.0527\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9842 - loss: 0.0523 - val_accuracy: 0.6404 - val_loss: 1.9877\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9806 - loss: 0.0598 - val_accuracy: 0.6360 - val_loss: 2.1740\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9590 - loss: 0.1200 - val_accuracy: 0.6107 - val_loss: 2.6445\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9353 - loss: 0.2104 - val_accuracy: 0.6195 - val_loss: 2.1842\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9695 - loss: 0.0952 - val_accuracy: 0.6382 - val_loss: 2.3696\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9806 - loss: 0.0564 - val_accuracy: 0.6425 - val_loss: 2.5531\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9979 - loss: 0.0087 - val_accuracy: 0.6513 - val_loss: 2.4607\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9954 - loss: 0.0185 - val_accuracy: 0.6349 - val_loss: 2.3926\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.6404 - val_loss: 2.4123\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.6480 - val_loss: 2.3617\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 3.5818e-04 - val_accuracy: 0.6502 - val_loss: 2.3794\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6648 - loss: 2.3019\n",
            "Test accuracy: 0.6502193212509155\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.2013 - loss: 3.0083 - val_accuracy: 0.5077 - val_loss: 1.7048\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.6065 - loss: 1.2910 - val_accuracy: 0.6239 - val_loss: 1.2688\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.7718 - loss: 0.6842 - val_accuracy: 0.6568 - val_loss: 1.1531\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9196 - loss: 0.2836 - val_accuracy: 0.6601 - val_loss: 1.3624\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9606 - loss: 0.1329 - val_accuracy: 0.6491 - val_loss: 1.5622\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9727 - loss: 0.0858 - val_accuracy: 0.6711 - val_loss: 1.6289\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9933 - loss: 0.0289 - val_accuracy: 0.6787 - val_loss: 1.6940\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9946 - loss: 0.0208 - val_accuracy: 0.6974 - val_loss: 1.7455\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.6974 - val_loss: 1.7664\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7029 - val_loss: 1.7914\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 6.8141e-04 - val_accuracy: 0.7050 - val_loss: 1.8095\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 5.2621e-04 - val_accuracy: 0.7083 - val_loss: 1.8290\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 4.1641e-04 - val_accuracy: 0.7072 - val_loss: 1.8472\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.7203e-04 - val_accuracy: 0.7083 - val_loss: 1.8657\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 3.1853e-04 - val_accuracy: 0.7083 - val_loss: 1.8830\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.7359e-04 - val_accuracy: 0.7094 - val_loss: 1.8960\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.3685e-04 - val_accuracy: 0.7094 - val_loss: 1.9106\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.1489e-04 - val_accuracy: 0.7105 - val_loss: 1.9225\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.9312e-04 - val_accuracy: 0.7105 - val_loss: 1.9326\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.6776e-04 - val_accuracy: 0.7094 - val_loss: 1.9445\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7294 - loss: 1.9987\n",
            "Test accuracy: 0.7094298005104065\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.1832 - loss: 3.0640 - val_accuracy: 0.4616 - val_loss: 1.8071\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.5711 - loss: 1.4264 - val_accuracy: 0.6009 - val_loss: 1.3227\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7339 - loss: 0.8585 - val_accuracy: 0.6765 - val_loss: 1.1148\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.8456 - loss: 0.4867 - val_accuracy: 0.6787 - val_loss: 1.0933\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9208 - loss: 0.2623 - val_accuracy: 0.6809 - val_loss: 1.2072\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9556 - loss: 0.1427 - val_accuracy: 0.7039 - val_loss: 1.2073\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9740 - loss: 0.0904 - val_accuracy: 0.7029 - val_loss: 1.2775\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9937 - loss: 0.0277 - val_accuracy: 0.7226 - val_loss: 1.2767\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9986 - loss: 0.0115 - val_accuracy: 0.7423 - val_loss: 1.2463\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9999 - loss: 0.0033 - val_accuracy: 0.7379 - val_loss: 1.2927\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7368 - val_loss: 1.3116\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7445 - val_loss: 1.3219\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7412 - val_loss: 1.3498\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7434 - val_loss: 1.3612\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 9.4959e-04 - val_accuracy: 0.7412 - val_loss: 1.3775\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 8.1844e-04 - val_accuracy: 0.7401 - val_loss: 1.3983\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 7.2862e-04 - val_accuracy: 0.7412 - val_loss: 1.4088\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 6.4544e-04 - val_accuracy: 0.7423 - val_loss: 1.4185\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 6.0064e-04 - val_accuracy: 0.7412 - val_loss: 1.4291\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 5.1911e-04 - val_accuracy: 0.7390 - val_loss: 1.4420\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7604 - loss: 1.3668\n",
            "Test accuracy: 0.7390350699424744\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 81ms/step - accuracy: 0.2292 - loss: 2.9169 - val_accuracy: 0.5340 - val_loss: 1.5638\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6196 - loss: 1.3097 - val_accuracy: 0.6053 - val_loss: 1.2748\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7670 - loss: 0.7421 - val_accuracy: 0.6754 - val_loss: 1.1290\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8902 - loss: 0.3726 - val_accuracy: 0.6996 - val_loss: 1.0460\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9454 - loss: 0.1919 - val_accuracy: 0.7368 - val_loss: 1.0549\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9826 - loss: 0.0834 - val_accuracy: 0.7314 - val_loss: 1.1727\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9920 - loss: 0.0410 - val_accuracy: 0.7357 - val_loss: 1.2169\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9976 - loss: 0.0134 - val_accuracy: 0.7412 - val_loss: 1.2220\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.7522 - val_loss: 1.2452\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7566 - val_loss: 1.2745\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7588 - val_loss: 1.2889\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7621 - val_loss: 1.3084\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 9.0084e-04 - val_accuracy: 0.7599 - val_loss: 1.3272\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 7.4459e-04 - val_accuracy: 0.7621 - val_loss: 1.3397\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 6.6698e-04 - val_accuracy: 0.7599 - val_loss: 1.3562\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.7286e-04 - val_accuracy: 0.7632 - val_loss: 1.3687\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.0997e-04 - val_accuracy: 0.7632 - val_loss: 1.3856\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 4.1472e-04 - val_accuracy: 0.7621 - val_loss: 1.3944\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 4.0283e-04 - val_accuracy: 0.7632 - val_loss: 1.4033\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 3.5260e-04 - val_accuracy: 0.7632 - val_loss: 1.4136\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7770 - loss: 1.3681\n",
            "Test accuracy: 0.7631579041481018\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.2033 - loss: 3.1341 - val_accuracy: 0.5362 - val_loss: 1.5716\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.6478 - loss: 1.2153 - val_accuracy: 0.6031 - val_loss: 1.4259\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.7830 - loss: 0.6974 - val_accuracy: 0.6261 - val_loss: 1.3125\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9004 - loss: 0.3061 - val_accuracy: 0.6557 - val_loss: 1.4300\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9543 - loss: 0.1500 - val_accuracy: 0.6349 - val_loss: 1.7395\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9742 - loss: 0.0896 - val_accuracy: 0.6414 - val_loss: 1.8383\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9763 - loss: 0.0674 - val_accuracy: 0.6393 - val_loss: 1.9921\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9896 - loss: 0.0395 - val_accuracy: 0.6535 - val_loss: 2.0661\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9896 - loss: 0.0367 - val_accuracy: 0.6557 - val_loss: 2.1344\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9819 - loss: 0.0611 - val_accuracy: 0.6042 - val_loss: 2.7462\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9501 - loss: 0.1511 - val_accuracy: 0.6042 - val_loss: 2.5415\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9572 - loss: 0.1505 - val_accuracy: 0.6316 - val_loss: 2.6269\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9624 - loss: 0.1299 - val_accuracy: 0.6217 - val_loss: 2.5232\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9875 - loss: 0.0433 - val_accuracy: 0.6535 - val_loss: 2.6271\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9918 - loss: 0.0392 - val_accuracy: 0.6535 - val_loss: 2.4961\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 0.6425 - val_loss: 2.6505\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9961 - loss: 0.0118 - val_accuracy: 0.6404 - val_loss: 2.8187\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9975 - loss: 0.0103 - val_accuracy: 0.6261 - val_loss: 2.8645\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.6327 - val_loss: 2.8075\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9970 - loss: 0.0069 - val_accuracy: 0.6327 - val_loss: 3.2811\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6500 - loss: 3.1299\n",
            "Test accuracy: 0.6326754093170166\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.2241 - loss: 2.9536 - val_accuracy: 0.5395 - val_loss: 1.6234\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.6676 - loss: 1.0913 - val_accuracy: 0.6184 - val_loss: 1.2444\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.8580 - loss: 0.4830 - val_accuracy: 0.6700 - val_loss: 1.2345\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9304 - loss: 0.2053 - val_accuracy: 0.6612 - val_loss: 1.4600\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9613 - loss: 0.1261 - val_accuracy: 0.6458 - val_loss: 1.5830\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9708 - loss: 0.0974 - val_accuracy: 0.6316 - val_loss: 2.0274\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9710 - loss: 0.0867 - val_accuracy: 0.6217 - val_loss: 1.9446\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9820 - loss: 0.0583 - val_accuracy: 0.6469 - val_loss: 1.9023\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9854 - loss: 0.0510 - val_accuracy: 0.6425 - val_loss: 2.1449\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9833 - loss: 0.0578 - val_accuracy: 0.6404 - val_loss: 2.3932\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9866 - loss: 0.0422 - val_accuracy: 0.6524 - val_loss: 2.2453\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9885 - loss: 0.0396 - val_accuracy: 0.6414 - val_loss: 2.4864\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9673 - loss: 0.0941 - val_accuracy: 0.6195 - val_loss: 2.5507\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.9584 - loss: 0.1262 - val_accuracy: 0.5910 - val_loss: 3.1822\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9538 - loss: 0.1690 - val_accuracy: 0.6195 - val_loss: 2.9654\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9675 - loss: 0.1056 - val_accuracy: 0.5877 - val_loss: 2.8934\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9839 - loss: 0.0596 - val_accuracy: 0.6129 - val_loss: 2.8612\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.9871 - loss: 0.0327 - val_accuracy: 0.6327 - val_loss: 2.9746\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.9974 - loss: 0.0054 - val_accuracy: 0.6425 - val_loss: 2.6778\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 8.0346e-04 - val_accuracy: 0.6579 - val_loss: 2.6538\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6891 - loss: 2.2998\n",
            "Test accuracy: 0.6578947305679321\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.1822 - loss: 3.0578 - val_accuracy: 0.4529 - val_loss: 1.8191\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.5742 - loss: 1.4413 - val_accuracy: 0.5921 - val_loss: 1.3176\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.7197 - loss: 0.9266 - val_accuracy: 0.6513 - val_loss: 1.1774\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8062 - loss: 0.6104 - val_accuracy: 0.6678 - val_loss: 1.2033\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8763 - loss: 0.3833 - val_accuracy: 0.6557 - val_loss: 1.2470\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9326 - loss: 0.2176 - val_accuracy: 0.6458 - val_loss: 1.3567\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9682 - loss: 0.1067 - val_accuracy: 0.6623 - val_loss: 1.5176\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9902 - loss: 0.0501 - val_accuracy: 0.6776 - val_loss: 1.5033\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9920 - loss: 0.0359 - val_accuracy: 0.6842 - val_loss: 1.5251\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9970 - loss: 0.0152 - val_accuracy: 0.6919 - val_loss: 1.5801\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.6963 - val_loss: 1.6053\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6952 - val_loss: 1.6256\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6930 - val_loss: 1.6559\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6985 - val_loss: 1.6818\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6963 - val_loss: 1.6998\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 8.0228e-04 - val_accuracy: 0.6963 - val_loss: 1.7228\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 7.1521e-04 - val_accuracy: 0.6996 - val_loss: 1.7421\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 6.7698e-04 - val_accuracy: 0.6996 - val_loss: 1.7607\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 5.9137e-04 - val_accuracy: 0.6985 - val_loss: 1.7765\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 5.3090e-04 - val_accuracy: 0.6985 - val_loss: 1.7940\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7049 - loss: 1.7832\n",
            "Test accuracy: 0.6984649300575256\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - accuracy: 0.2077 - loss: 2.9329 - val_accuracy: 0.5154 - val_loss: 1.5863\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.6122 - loss: 1.2850 - val_accuracy: 0.6601 - val_loss: 1.1281\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.7813 - loss: 0.6828 - val_accuracy: 0.6436 - val_loss: 1.1378\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.8722 - loss: 0.3960 - val_accuracy: 0.7094 - val_loss: 1.0891\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9389 - loss: 0.2008 - val_accuracy: 0.7072 - val_loss: 1.2599\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.9667 - loss: 0.1068 - val_accuracy: 0.7281 - val_loss: 1.2432\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9847 - loss: 0.0546 - val_accuracy: 0.7149 - val_loss: 1.3792\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9907 - loss: 0.0325 - val_accuracy: 0.7281 - val_loss: 1.3555\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7281 - val_loss: 1.4228\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7281 - val_loss: 1.4523\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 8.4641e-04 - val_accuracy: 0.7292 - val_loss: 1.4731\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 7.2492e-04 - val_accuracy: 0.7292 - val_loss: 1.4935\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 5.7380e-04 - val_accuracy: 0.7303 - val_loss: 1.5144\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 4.8876e-04 - val_accuracy: 0.7259 - val_loss: 1.5299\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 4.1444e-04 - val_accuracy: 0.7259 - val_loss: 1.5475\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.4341e-04 - val_accuracy: 0.7237 - val_loss: 1.5589\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.1131e-04 - val_accuracy: 0.7237 - val_loss: 1.5757\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 2.7501e-04 - val_accuracy: 0.7237 - val_loss: 1.5853\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 2.4346e-04 - val_accuracy: 0.7270 - val_loss: 1.5975\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.1539e-04 - val_accuracy: 0.7270 - val_loss: 1.6097\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7473 - loss: 1.5274\n",
            "Test accuracy: 0.7269737124443054\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 100ms/step - accuracy: 0.2187 - loss: 3.0208 - val_accuracy: 0.5307 - val_loss: 1.6298\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.6292 - loss: 1.2637 - val_accuracy: 0.5921 - val_loss: 1.3779\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.7913 - loss: 0.6917 - val_accuracy: 0.6075 - val_loss: 1.4324\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9063 - loss: 0.3081 - val_accuracy: 0.5998 - val_loss: 1.7424\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9441 - loss: 0.1729 - val_accuracy: 0.6107 - val_loss: 1.8950\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9710 - loss: 0.0881 - val_accuracy: 0.6140 - val_loss: 2.1943\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9761 - loss: 0.0710 - val_accuracy: 0.6086 - val_loss: 2.2289\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9464 - loss: 0.1793 - val_accuracy: 0.5877 - val_loss: 2.4881\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9506 - loss: 0.1350 - val_accuracy: 0.5921 - val_loss: 2.7183\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9634 - loss: 0.1112 - val_accuracy: 0.6064 - val_loss: 2.6379\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9577 - loss: 0.1287 - val_accuracy: 0.5987 - val_loss: 3.0710\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9587 - loss: 0.1508 - val_accuracy: 0.6338 - val_loss: 2.6811\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9855 - loss: 0.0396 - val_accuracy: 0.5954 - val_loss: 2.9743\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9789 - loss: 0.0686 - val_accuracy: 0.6261 - val_loss: 3.1543\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9872 - loss: 0.0382 - val_accuracy: 0.6162 - val_loss: 3.3568\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.9897 - loss: 0.0332 - val_accuracy: 0.6195 - val_loss: 3.4754\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9902 - loss: 0.0382 - val_accuracy: 0.6272 - val_loss: 3.2121\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - accuracy: 0.9972 - loss: 0.0145 - val_accuracy: 0.6217 - val_loss: 3.3754\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9948 - loss: 0.0176 - val_accuracy: 0.6075 - val_loss: 3.7284\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.6272 - val_loss: 3.4741\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6668 - loss: 2.9626\n",
            "Test accuracy: 0.6271929740905762\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - accuracy: 0.2389 - loss: 2.8862 - val_accuracy: 0.5362 - val_loss: 1.5109\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.6873 - loss: 1.0576 - val_accuracy: 0.6173 - val_loss: 1.3943\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.8508 - loss: 0.5211 - val_accuracy: 0.6228 - val_loss: 1.4901\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9387 - loss: 0.1977 - val_accuracy: 0.6502 - val_loss: 1.5590\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9626 - loss: 0.1156 - val_accuracy: 0.6327 - val_loss: 1.8638\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9600 - loss: 0.1056 - val_accuracy: 0.6118 - val_loss: 2.1073\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9705 - loss: 0.0855 - val_accuracy: 0.6382 - val_loss: 2.1604\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9561 - loss: 0.1291 - val_accuracy: 0.6162 - val_loss: 2.3805\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9844 - loss: 0.0526 - val_accuracy: 0.6272 - val_loss: 2.7106\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9748 - loss: 0.0846 - val_accuracy: 0.5855 - val_loss: 2.7497\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9622 - loss: 0.1353 - val_accuracy: 0.6075 - val_loss: 2.9500\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - accuracy: 0.9575 - loss: 0.1399 - val_accuracy: 0.5713 - val_loss: 3.7023\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9500 - loss: 0.1789 - val_accuracy: 0.6075 - val_loss: 3.3870\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9663 - loss: 0.1164 - val_accuracy: 0.6195 - val_loss: 2.9870\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9837 - loss: 0.0448 - val_accuracy: 0.6009 - val_loss: 3.4249\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9841 - loss: 0.0428 - val_accuracy: 0.5844 - val_loss: 3.6357\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9895 - loss: 0.0320 - val_accuracy: 0.6042 - val_loss: 3.2914\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9927 - loss: 0.0255 - val_accuracy: 0.6184 - val_loss: 3.6144\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9921 - loss: 0.0270 - val_accuracy: 0.6491 - val_loss: 3.4841\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.9882 - loss: 0.0360 - val_accuracy: 0.5910 - val_loss: 4.1980\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6412 - loss: 3.3871\n",
            "Test accuracy: 0.5910087823867798\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.1826 - loss: 3.0118 - val_accuracy: 0.4814 - val_loss: 1.7499\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.5773 - loss: 1.3963 - val_accuracy: 0.5976 - val_loss: 1.3843\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.7549 - loss: 0.7588 - val_accuracy: 0.6382 - val_loss: 1.3284\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.8816 - loss: 0.3917 - val_accuracy: 0.6053 - val_loss: 1.5399\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9330 - loss: 0.2092 - val_accuracy: 0.6349 - val_loss: 1.5776\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9881 - loss: 0.0563 - val_accuracy: 0.6568 - val_loss: 1.5647\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6689 - val_loss: 1.6417\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6689 - val_loss: 1.6907\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6645 - val_loss: 1.7375\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6656 - val_loss: 1.7749\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6689 - val_loss: 1.8009\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 9.8646e-04 - val_accuracy: 0.6743 - val_loss: 1.8328\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 8.1789e-04 - val_accuracy: 0.6721 - val_loss: 1.8601\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 7.0821e-04 - val_accuracy: 0.6711 - val_loss: 1.8834\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 5.9736e-04 - val_accuracy: 0.6721 - val_loss: 1.9033\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 5.1818e-04 - val_accuracy: 0.6721 - val_loss: 1.9245\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 4.6375e-04 - val_accuracy: 0.6721 - val_loss: 1.9481\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 3.9657e-04 - val_accuracy: 0.6721 - val_loss: 1.9664\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 3.5644e-04 - val_accuracy: 0.6721 - val_loss: 1.9889\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 3.1158e-04 - val_accuracy: 0.6732 - val_loss: 2.0049\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7025 - loss: 1.8199\n",
            "Test accuracy: 0.6732456088066101\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.1981 - loss: 3.0340 - val_accuracy: 0.4803 - val_loss: 1.7022\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6376 - loss: 1.2214 - val_accuracy: 0.6075 - val_loss: 1.3400\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.8365 - loss: 0.5295 - val_accuracy: 0.6393 - val_loss: 1.3137\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9462 - loss: 0.1944 - val_accuracy: 0.6513 - val_loss: 1.4157\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9801 - loss: 0.0797 - val_accuracy: 0.6447 - val_loss: 1.6673\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9938 - loss: 0.0324 - val_accuracy: 0.6612 - val_loss: 1.6087\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.6689 - val_loss: 1.6431\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6623 - val_loss: 1.7661\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6678 - val_loss: 1.7381\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 8.7077e-04 - val_accuracy: 0.6689 - val_loss: 1.7676\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 7.1879e-04 - val_accuracy: 0.6711 - val_loss: 1.7918\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 5.8664e-04 - val_accuracy: 0.6732 - val_loss: 1.8149\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 5.2259e-04 - val_accuracy: 0.6743 - val_loss: 1.8299\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 4.3339e-04 - val_accuracy: 0.6765 - val_loss: 1.8448\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 3.6669e-04 - val_accuracy: 0.6776 - val_loss: 1.8627\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 3.3429e-04 - val_accuracy: 0.6754 - val_loss: 1.8812\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.7478e-04 - val_accuracy: 0.6776 - val_loss: 1.8955\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.4864e-04 - val_accuracy: 0.6754 - val_loss: 1.9092\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.3402e-04 - val_accuracy: 0.6765 - val_loss: 1.9217\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 1.9487e-04 - val_accuracy: 0.6765 - val_loss: 1.9341\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6904 - loss: 1.8627\n",
            "Test accuracy: 0.6765350699424744\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - accuracy: 0.2062 - loss: 3.1325 - val_accuracy: 0.5373 - val_loss: 1.5956\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.6662 - loss: 1.1364 - val_accuracy: 0.5768 - val_loss: 1.4132\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.8571 - loss: 0.4453 - val_accuracy: 0.6009 - val_loss: 1.5430\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9631 - loss: 0.1239 - val_accuracy: 0.6294 - val_loss: 1.8409\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.9918 - loss: 0.0390 - val_accuracy: 0.6195 - val_loss: 2.0364\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.9848 - loss: 0.0503 - val_accuracy: 0.6020 - val_loss: 2.3699\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9777 - loss: 0.0717 - val_accuracy: 0.5647 - val_loss: 2.4328\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9584 - loss: 0.1379 - val_accuracy: 0.5603 - val_loss: 2.9400\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9594 - loss: 0.1263 - val_accuracy: 0.5471 - val_loss: 3.2748\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9694 - loss: 0.0947 - val_accuracy: 0.5439 - val_loss: 3.5234\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9723 - loss: 0.0864 - val_accuracy: 0.6009 - val_loss: 3.1245\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9828 - loss: 0.0470 - val_accuracy: 0.5702 - val_loss: 3.5361\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9859 - loss: 0.0453 - val_accuracy: 0.5658 - val_loss: 3.2777\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9961 - loss: 0.0113 - val_accuracy: 0.5877 - val_loss: 3.2613\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.9945 - loss: 0.0151 - val_accuracy: 0.5844 - val_loss: 3.4089\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9937 - loss: 0.0209 - val_accuracy: 0.5493 - val_loss: 3.7910\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9847 - loss: 0.0674 - val_accuracy: 0.5022 - val_loss: 4.3265\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9691 - loss: 0.1201 - val_accuracy: 0.5296 - val_loss: 4.8613\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 0.9589 - loss: 0.1791 - val_accuracy: 0.5482 - val_loss: 4.3970\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9635 - loss: 0.1537 - val_accuracy: 0.5110 - val_loss: 4.8432\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5637 - loss: 4.3488\n",
            "Test accuracy: 0.5109649300575256\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.2352 - loss: 3.0012 - val_accuracy: 0.5493 - val_loss: 1.5375\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.6819 - loss: 1.0357 - val_accuracy: 0.6162 - val_loss: 1.4093\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.8929 - loss: 0.3163 - val_accuracy: 0.6239 - val_loss: 1.5621\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9671 - loss: 0.1090 - val_accuracy: 0.6184 - val_loss: 1.8300\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9897 - loss: 0.0321 - val_accuracy: 0.6283 - val_loss: 2.0604\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9907 - loss: 0.0386 - val_accuracy: 0.6096 - val_loss: 2.1778\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9879 - loss: 0.0401 - val_accuracy: 0.5603 - val_loss: 2.6006\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9499 - loss: 0.1469 - val_accuracy: 0.5789 - val_loss: 2.8905\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9487 - loss: 0.1659 - val_accuracy: 0.5757 - val_loss: 3.0407\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9643 - loss: 0.1239 - val_accuracy: 0.5910 - val_loss: 2.7937\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9687 - loss: 0.0859 - val_accuracy: 0.6075 - val_loss: 2.9945\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.9904 - loss: 0.0280 - val_accuracy: 0.5746 - val_loss: 2.8719\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.9931 - loss: 0.0246 - val_accuracy: 0.6217 - val_loss: 3.1406\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.6206 - val_loss: 3.1704\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.6261 - val_loss: 3.0337\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 1.0747e-04 - val_accuracy: 0.6261 - val_loss: 3.0422\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 8.0642e-05 - val_accuracy: 0.6294 - val_loss: 3.0502\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 6.4576e-05 - val_accuracy: 0.6305 - val_loss: 3.0585\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 5.1425e-05 - val_accuracy: 0.6316 - val_loss: 3.0671\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 4.9168e-05 - val_accuracy: 0.6316 - val_loss: 3.0744\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6305 - loss: 3.0998\n",
            "Test accuracy: 0.6315789222717285\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.2205 - loss: 2.9635 - val_accuracy: 0.5175 - val_loss: 1.6668\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.6705 - loss: 1.0923 - val_accuracy: 0.6086 - val_loss: 1.2946\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.8483 - loss: 0.4909 - val_accuracy: 0.6151 - val_loss: 1.3619\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9395 - loss: 0.1978 - val_accuracy: 0.6195 - val_loss: 1.4203\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9794 - loss: 0.0738 - val_accuracy: 0.6283 - val_loss: 1.8324\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.9892 - loss: 0.0406 - val_accuracy: 0.6382 - val_loss: 1.7406\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.9969 - loss: 0.0174 - val_accuracy: 0.6601 - val_loss: 1.7938\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6623 - val_loss: 1.7660\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 7.5874e-04 - val_accuracy: 0.6634 - val_loss: 1.8010\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 5.5217e-04 - val_accuracy: 0.6634 - val_loss: 1.8285\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 4.3831e-04 - val_accuracy: 0.6656 - val_loss: 1.8510\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 3.5122e-04 - val_accuracy: 0.6645 - val_loss: 1.8718\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 3.0807e-04 - val_accuracy: 0.6678 - val_loss: 1.8897\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.6550e-04 - val_accuracy: 0.6656 - val_loss: 1.9086\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.2924e-04 - val_accuracy: 0.6656 - val_loss: 1.9244\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 2.0173e-04 - val_accuracy: 0.6667 - val_loss: 1.9396\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.8196e-04 - val_accuracy: 0.6667 - val_loss: 1.9546\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.5787e-04 - val_accuracy: 0.6667 - val_loss: 1.9690\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.4401e-04 - val_accuracy: 0.6667 - val_loss: 1.9833\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.3340e-04 - val_accuracy: 0.6667 - val_loss: 1.9971\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6845 - loss: 1.9094\n",
            "Test accuracy: 0.6666666865348816\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.2379 - loss: 2.8630 - val_accuracy: 0.5439 - val_loss: 1.5972\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.6524 - loss: 1.1928 - val_accuracy: 0.6064 - val_loss: 1.3576\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.8514 - loss: 0.5092 - val_accuracy: 0.6009 - val_loss: 1.4362\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.9175 - loss: 0.2494 - val_accuracy: 0.6458 - val_loss: 1.5220\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 0.9727 - loss: 0.0958 - val_accuracy: 0.6360 - val_loss: 1.7312\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9944 - loss: 0.0314 - val_accuracy: 0.6294 - val_loss: 1.7847\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9946 - loss: 0.0200 - val_accuracy: 0.6535 - val_loss: 1.8146\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.6689 - val_loss: 1.8143\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.6743 - val_loss: 1.8728\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 7.5645e-04 - val_accuracy: 0.6743 - val_loss: 1.8994\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 4.7322e-04 - val_accuracy: 0.6798 - val_loss: 1.9152\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 3.9736e-04 - val_accuracy: 0.6864 - val_loss: 1.9320\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 2.9326e-04 - val_accuracy: 0.6875 - val_loss: 1.9450\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 2.6521e-04 - val_accuracy: 0.6897 - val_loss: 1.9606\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 2.1274e-04 - val_accuracy: 0.6897 - val_loss: 1.9745\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.8844e-04 - val_accuracy: 0.6919 - val_loss: 1.9880\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.7478e-04 - val_accuracy: 0.6919 - val_loss: 2.0001\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.4898e-04 - val_accuracy: 0.6897 - val_loss: 2.0135\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.3530e-04 - val_accuracy: 0.6897 - val_loss: 2.0258\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 1.2666e-04 - val_accuracy: 0.6886 - val_loss: 2.0387\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7154 - loss: 1.8968\n",
            "Test accuracy: 0.6885964870452881\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.1585 - loss: 3.4680 - val_accuracy: 0.4989 - val_loss: 1.7626\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.5900 - loss: 1.3799 - val_accuracy: 0.5493 - val_loss: 1.5187\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.7939 - loss: 0.6454 - val_accuracy: 0.5921 - val_loss: 1.5058\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9368 - loss: 0.2042 - val_accuracy: 0.5603 - val_loss: 1.9711\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9723 - loss: 0.1071 - val_accuracy: 0.5537 - val_loss: 2.3185\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9794 - loss: 0.0699 - val_accuracy: 0.5603 - val_loss: 2.5933\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9785 - loss: 0.0769 - val_accuracy: 0.5395 - val_loss: 2.6500\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9711 - loss: 0.0919 - val_accuracy: 0.5110 - val_loss: 3.1997\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9518 - loss: 0.1748 - val_accuracy: 0.5625 - val_loss: 3.2059\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9655 - loss: 0.1153 - val_accuracy: 0.5526 - val_loss: 3.2674\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9682 - loss: 0.0951 - val_accuracy: 0.5340 - val_loss: 3.5576\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9854 - loss: 0.0513 - val_accuracy: 0.5548 - val_loss: 3.5652\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - accuracy: 0.9831 - loss: 0.0543 - val_accuracy: 0.5362 - val_loss: 4.0388\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9818 - loss: 0.0619 - val_accuracy: 0.5197 - val_loss: 4.1220\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9808 - loss: 0.0610 - val_accuracy: 0.5230 - val_loss: 4.4255\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - accuracy: 0.9732 - loss: 0.1088 - val_accuracy: 0.4507 - val_loss: 5.4468\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - accuracy: 0.9596 - loss: 0.1619 - val_accuracy: 0.4901 - val_loss: 4.9822\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.9473 - loss: 0.2285 - val_accuracy: 0.4901 - val_loss: 4.9474\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - accuracy: 0.9744 - loss: 0.0880 - val_accuracy: 0.5307 - val_loss: 5.7081\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - accuracy: 0.9876 - loss: 0.0523 - val_accuracy: 0.5033 - val_loss: 5.5716\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5020 - loss: 5.4916\n",
            "Test accuracy: 0.5032894611358643\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.2118 - loss: 3.1640 - val_accuracy: 0.5318 - val_loss: 1.7005\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 181ms/step - accuracy: 0.6399 - loss: 1.2094 - val_accuracy: 0.5954 - val_loss: 1.3942\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 181ms/step - accuracy: 0.8745 - loss: 0.4001 - val_accuracy: 0.5899 - val_loss: 1.7176\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9644 - loss: 0.1188 - val_accuracy: 0.6064 - val_loss: 1.8277\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 184ms/step - accuracy: 0.9867 - loss: 0.0454 - val_accuracy: 0.5965 - val_loss: 2.0966\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9818 - loss: 0.0562 - val_accuracy: 0.5581 - val_loss: 2.3687\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 0.9901 - loss: 0.0407 - val_accuracy: 0.5504 - val_loss: 2.8264\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9728 - loss: 0.0876 - val_accuracy: 0.5318 - val_loss: 3.7253\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 0.9378 - loss: 0.2105 - val_accuracy: 0.5450 - val_loss: 3.1233\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9436 - loss: 0.2310 - val_accuracy: 0.5680 - val_loss: 3.2039\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9642 - loss: 0.1328 - val_accuracy: 0.5757 - val_loss: 3.2445\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9925 - loss: 0.0344 - val_accuracy: 0.5658 - val_loss: 3.2390\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 0.9981 - loss: 0.0101 - val_accuracy: 0.5800 - val_loss: 3.2583\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9970 - loss: 0.0065 - val_accuracy: 0.5855 - val_loss: 3.3662\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 9.6607e-04 - val_accuracy: 0.5866 - val_loss: 3.3708\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 1.3984e-04 - val_accuracy: 0.5932 - val_loss: 3.3722\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 1.0056e-04 - val_accuracy: 0.5954 - val_loss: 3.3807\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 8.0958e-05 - val_accuracy: 0.5976 - val_loss: 3.3900\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 6.8004e-05 - val_accuracy: 0.5976 - val_loss: 3.3995\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 5.7190e-05 - val_accuracy: 0.5976 - val_loss: 3.4081\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6116 - loss: 3.1260\n",
            "Test accuracy: 0.5975877046585083\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 133ms/step - accuracy: 0.2097 - loss: 3.0604 - val_accuracy: 0.5110 - val_loss: 1.6633\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.6230 - loss: 1.2664 - val_accuracy: 0.5735 - val_loss: 1.3763\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.8249 - loss: 0.5632 - val_accuracy: 0.5888 - val_loss: 1.5476\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9146 - loss: 0.2621 - val_accuracy: 0.6414 - val_loss: 1.6069\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9677 - loss: 0.1139 - val_accuracy: 0.6228 - val_loss: 1.8421\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9854 - loss: 0.0497 - val_accuracy: 0.6316 - val_loss: 1.8837\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9976 - loss: 0.0184 - val_accuracy: 0.6360 - val_loss: 1.9614\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9941 - loss: 0.0296 - val_accuracy: 0.5976 - val_loss: 2.3235\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9675 - loss: 0.1094 - val_accuracy: 0.5581 - val_loss: 2.8570\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9135 - loss: 0.3010 - val_accuracy: 0.5954 - val_loss: 2.6147\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - accuracy: 0.9393 - loss: 0.2135 - val_accuracy: 0.6096 - val_loss: 2.7027\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9589 - loss: 0.1255 - val_accuracy: 0.6086 - val_loss: 2.4906\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - accuracy: 0.9897 - loss: 0.0325 - val_accuracy: 0.6261 - val_loss: 2.4799\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - accuracy: 0.9891 - loss: 0.0332 - val_accuracy: 0.6140 - val_loss: 2.6796\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9965 - loss: 0.0135 - val_accuracy: 0.6327 - val_loss: 2.6267\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.6360 - val_loss: 2.6152\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 2.7293e-04 - val_accuracy: 0.6404 - val_loss: 2.6214\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4053s\u001b[0m 36s/step - accuracy: 1.0000 - loss: 1.9118e-04 - val_accuracy: 0.6393 - val_loss: 2.6313\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1136s\u001b[0m 10s/step - accuracy: 1.0000 - loss: 1.4354e-04 - val_accuracy: 0.6382 - val_loss: 2.6413\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 1.2811e-04 - val_accuracy: 0.6382 - val_loss: 2.6518\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6503 - loss: 2.5875\n",
            "Test accuracy: 0.6381579041481018\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 176ms/step - accuracy: 0.2402 - loss: 2.9080 - val_accuracy: 0.5614 - val_loss: 1.4817\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 193ms/step - accuracy: 0.6902 - loss: 1.0767 - val_accuracy: 0.6053 - val_loss: 1.3077\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 191ms/step - accuracy: 0.8583 - loss: 0.4440 - val_accuracy: 0.5998 - val_loss: 1.5373\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 184ms/step - accuracy: 0.9443 - loss: 0.1709 - val_accuracy: 0.6360 - val_loss: 1.6483\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 183ms/step - accuracy: 0.9712 - loss: 0.0941 - val_accuracy: 0.6480 - val_loss: 1.8584\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9881 - loss: 0.0445 - val_accuracy: 0.6535 - val_loss: 1.9643\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 217ms/step - accuracy: 0.9930 - loss: 0.0225 - val_accuracy: 0.6524 - val_loss: 2.1956\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 234ms/step - accuracy: 0.9856 - loss: 0.0453 - val_accuracy: 0.5713 - val_loss: 2.8981\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 250ms/step - accuracy: 0.9412 - loss: 0.1786 - val_accuracy: 0.5932 - val_loss: 2.3867\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 280ms/step - accuracy: 0.9430 - loss: 0.1923 - val_accuracy: 0.5954 - val_loss: 2.5696\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 281ms/step - accuracy: 0.9619 - loss: 0.1255 - val_accuracy: 0.6075 - val_loss: 2.7707\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 200ms/step - accuracy: 0.9637 - loss: 0.1104 - val_accuracy: 0.6195 - val_loss: 2.7310\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - accuracy: 0.9861 - loss: 0.0438 - val_accuracy: 0.6524 - val_loss: 2.5124\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.9981 - loss: 0.0097 - val_accuracy: 0.6162 - val_loss: 2.7976\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 159ms/step - accuracy: 0.9916 - loss: 0.0229 - val_accuracy: 0.6546 - val_loss: 2.6548\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - accuracy: 0.9950 - loss: 0.0163 - val_accuracy: 0.6436 - val_loss: 2.8842\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - accuracy: 0.9992 - loss: 0.0058 - val_accuracy: 0.6414 - val_loss: 2.8957\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 158ms/step - accuracy: 0.9956 - loss: 0.0153 - val_accuracy: 0.6404 - val_loss: 3.0581\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 159ms/step - accuracy: 0.9946 - loss: 0.0259 - val_accuracy: 0.6075 - val_loss: 3.4124\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.9739 - loss: 0.1048 - val_accuracy: 0.5910 - val_loss: 3.8035\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5921 - loss: 3.7305\n",
            "Test accuracy: 0.5910087823867798\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.1837 - loss: 3.3360 - val_accuracy: 0.4605 - val_loss: 1.8419\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 211ms/step - accuracy: 0.5972 - loss: 1.3429 - val_accuracy: 0.5471 - val_loss: 1.5074\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 214ms/step - accuracy: 0.8397 - loss: 0.5212 - val_accuracy: 0.5636 - val_loss: 1.6910\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 215ms/step - accuracy: 0.9459 - loss: 0.1975 - val_accuracy: 0.5724 - val_loss: 2.1320\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9643 - loss: 0.1062 - val_accuracy: 0.5647 - val_loss: 2.4253\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 212ms/step - accuracy: 0.9821 - loss: 0.0649 - val_accuracy: 0.5439 - val_loss: 2.7675\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 215ms/step - accuracy: 0.9837 - loss: 0.0513 - val_accuracy: 0.5285 - val_loss: 3.4239\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 209ms/step - accuracy: 0.9682 - loss: 0.1026 - val_accuracy: 0.4759 - val_loss: 3.5276\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 212ms/step - accuracy: 0.9342 - loss: 0.2281 - val_accuracy: 0.5175 - val_loss: 3.5949\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - accuracy: 0.9093 - loss: 0.3651 - val_accuracy: 0.4748 - val_loss: 5.0427\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9094 - loss: 0.3758 - val_accuracy: 0.4934 - val_loss: 4.9336\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9508 - loss: 0.1882 - val_accuracy: 0.5285 - val_loss: 4.4583\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9721 - loss: 0.1107 - val_accuracy: 0.5011 - val_loss: 5.0897\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 208ms/step - accuracy: 0.9815 - loss: 0.0635 - val_accuracy: 0.5471 - val_loss: 4.6964\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9921 - loss: 0.0388 - val_accuracy: 0.5493 - val_loss: 5.2247\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9914 - loss: 0.0404 - val_accuracy: 0.5329 - val_loss: 5.1040\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 208ms/step - accuracy: 0.9950 - loss: 0.0162 - val_accuracy: 0.5318 - val_loss: 5.0849\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.5450 - val_loss: 5.1347\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 208ms/step - accuracy: 0.9976 - loss: 0.0107 - val_accuracy: 0.5450 - val_loss: 4.9831\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 208ms/step - accuracy: 0.9974 - loss: 0.0130 - val_accuracy: 0.5274 - val_loss: 5.5833\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5473 - loss: 5.0672\n",
            "Test accuracy: 0.5274122953414917\n",
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 295ms/step - accuracy: 0.2133 - loss: 3.3272 - val_accuracy: 0.5439 - val_loss: 1.5130\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 295ms/step - accuracy: 0.7098 - loss: 0.9675 - val_accuracy: 0.5833 - val_loss: 1.4586\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 293ms/step - accuracy: 0.8872 - loss: 0.3301 - val_accuracy: 0.5910 - val_loss: 1.6937\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 292ms/step - accuracy: 0.9685 - loss: 0.1144 - val_accuracy: 0.5932 - val_loss: 2.0366\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 291ms/step - accuracy: 0.9867 - loss: 0.0474 - val_accuracy: 0.6042 - val_loss: 2.5754\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 293ms/step - accuracy: 0.9757 - loss: 0.0844 - val_accuracy: 0.5373 - val_loss: 2.5713\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 293ms/step - accuracy: 0.9416 - loss: 0.2012 - val_accuracy: 0.5329 - val_loss: 3.1894\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 294ms/step - accuracy: 0.9608 - loss: 0.1496 - val_accuracy: 0.5779 - val_loss: 2.7750\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 292ms/step - accuracy: 0.9598 - loss: 0.1463 - val_accuracy: 0.5263 - val_loss: 3.4161\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 293ms/step - accuracy: 0.9674 - loss: 0.1486 - val_accuracy: 0.5482 - val_loss: 3.3292\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 292ms/step - accuracy: 0.9843 - loss: 0.0523 - val_accuracy: 0.5713 - val_loss: 3.6508\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 296ms/step - accuracy: 0.9812 - loss: 0.0709 - val_accuracy: 0.5647 - val_loss: 4.0983\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 297ms/step - accuracy: 0.9784 - loss: 0.0751 - val_accuracy: 0.5537 - val_loss: 3.9390\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 300ms/step - accuracy: 0.9770 - loss: 0.0872 - val_accuracy: 0.5274 - val_loss: 4.4884\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 296ms/step - accuracy: 0.9770 - loss: 0.0947 - val_accuracy: 0.5110 - val_loss: 4.4124\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 295ms/step - accuracy: 0.9565 - loss: 0.2132 - val_accuracy: 0.5439 - val_loss: 5.8109\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 295ms/step - accuracy: 0.9152 - loss: 0.5105 - val_accuracy: 0.4265 - val_loss: 9.3040\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 296ms/step - accuracy: 0.9142 - loss: 0.6745 - val_accuracy: 0.4945 - val_loss: 8.5913\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 297ms/step - accuracy: 0.9485 - loss: 0.4162 - val_accuracy: 0.5022 - val_loss: 8.4389\n",
            "Epoch 20/20\n",
            "\u001b[1m 41/113\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 284ms/step - accuracy: 0.9637 - loss: 0.2768"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m accuracylist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m----> 9\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_create_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput5\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     accuracylist\u001b[38;5;241m.\u001b[39mappend([[param], accuracy])\n\u001b[0;32m     11\u001b[0m accuracylist\n",
            "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mmodel_create_train\u001b[1;34m(params, inputs)\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_5\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_5\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_5\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_test_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_5\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "input1 = Input(shape = input_shape1)\n",
        "input2 = Input(shape= input_shape2)\n",
        "input3 = Input(shape= input_shape3)\n",
        "input4 = Input(shape= input_shape4)\n",
        "input5 = Input(shape= input_shape5)\n",
        "\n",
        "accuracylist = []\n",
        "for param in params:\n",
        "    accuracy = model_create_train(param, [input1, input2, input3, input4, input5])\n",
        "    accuracylist.append([[param], accuracy])\n",
        "accuracylist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[[[1, 32, 2, 32, 2, 32, 2, 0, 0, 64, 64, 52]], 0.7489035129547119],\n",
              " [[[1, 32, 2, 32, 2, 32, 2, 0, 0, 128, 64, 52]], 0.7554824352264404],\n",
              " [[[1, 32, 2, 32, 2, 32, 0, 0, 0, 64, 64, 52]], 0.7116228342056274],\n",
              " [[[1, 32, 2, 32, 2, 32, 0, 0, 0, 128, 64, 52]], 0.7039473652839661],\n",
              " [[[1, 32, 2, 32, 2, 64, 2, 0, 0, 64, 64, 52]], 0.7434210777282715],\n",
              " [[[1, 32, 2, 32, 2, 64, 2, 0, 0, 128, 64, 52]], 0.7357456088066101],\n",
              " [[[1, 32, 2, 32, 2, 64, 0, 0, 0, 64, 64, 52]], 0.6732456088066101],\n",
              " [[[1, 32, 2, 32, 2, 64, 0, 0, 0, 128, 64, 52]], 0.6853070259094238],\n",
              " [[[1, 32, 2, 32, 2, 128, 2, 0, 0, 64, 64, 52]], 0.7171052694320679],\n",
              " [[[1, 32, 2, 32, 2, 128, 2, 0, 0, 128, 64, 52]], 0.7412280440330505],\n",
              " [[[1, 32, 2, 32, 2, 128, 0, 0, 0, 64, 64, 52]], 0.6743420958518982],\n",
              " [[[1, 32, 2, 32, 2, 128, 0, 0, 0, 128, 64, 52]], 0.6085526347160339],\n",
              " [[[1, 32, 2, 32, 0, 32, 2, 0, 0, 64, 64, 52]], 0.6929824352264404],\n",
              " [[[1, 32, 2, 32, 0, 32, 2, 0, 0, 128, 64, 52]], 0.7006579041481018],\n",
              " [[[1, 32, 2, 32, 0, 32, 0, 0, 0, 64, 64, 52]], 0.5603070259094238],\n",
              " [[[1, 32, 2, 32, 0, 32, 0, 0, 0, 128, 64, 52]], 0.6666666865348816],\n",
              " [[[1, 32, 2, 32, 0, 64, 2, 0, 0, 64, 64, 52]], 0.6688596606254578],\n",
              " [[[1, 32, 2, 32, 0, 64, 2, 0, 0, 128, 64, 52]], 0.656798243522644],\n",
              " [[[1, 32, 2, 32, 0, 64, 0, 0, 0, 64, 64, 52]], 0.47039473056793213],\n",
              " [[[1, 32, 2, 32, 0, 64, 0, 0, 0, 128, 64, 52]], 0.5723684430122375],\n",
              " [[[1, 32, 2, 32, 0, 128, 2, 0, 0, 64, 64, 52]], 0.6129385828971863],\n",
              " [[[1, 32, 2, 32, 0, 128, 2, 0, 0, 128, 64, 52]], 0.6622806787490845],\n",
              " [[[1, 32, 2, 32, 0, 128, 0, 0, 0, 64, 64, 52]], 0.5745614171028137],\n",
              " [[[1, 32, 2, 32, 0, 128, 0, 0, 0, 128, 64, 52]], 0.5822368264198303],\n",
              " [[[1, 32, 2, 64, 2, 32, 2, 0, 0, 64, 64, 52]], 0.7335526347160339],\n",
              " [[[1, 32, 2, 64, 2, 32, 2, 0, 0, 128, 64, 52]], 0.7598684430122375],\n",
              " [[[1, 32, 2, 64, 2, 32, 0, 0, 0, 64, 64, 52]], 0.6787280440330505],\n",
              " [[[1, 32, 2, 64, 2, 32, 0, 0, 0, 128, 64, 52]], 0.6864035129547119],\n",
              " [[[1, 32, 2, 64, 2, 64, 2, 0, 0, 64, 64, 52]], 0.7324561476707458],\n",
              " [[[1, 32, 2, 64, 2, 64, 2, 0, 0, 128, 64, 52]], 0.75],\n",
              " [[[1, 32, 2, 64, 2, 64, 0, 0, 0, 64, 64, 52]], 0.6491228342056274],\n",
              " [[[1, 32, 2, 64, 2, 64, 0, 0, 0, 128, 64, 52]], 0.6118420958518982],\n",
              " [[[1, 32, 2, 64, 2, 128, 2, 0, 0, 64, 64, 52]], 0.7214912176132202],\n",
              " [[[1, 32, 2, 64, 2, 128, 2, 0, 0, 128, 64, 52]], 0.7160087823867798],\n",
              " [[[1, 32, 2, 64, 2, 128, 0, 0, 0, 64, 64, 52]], 0.5899122953414917],\n",
              " [[[1, 32, 2, 64, 2, 128, 0, 0, 0, 128, 64, 52]], 0.6469298005104065],\n",
              " [[[1, 32, 2, 64, 0, 32, 2, 0, 0, 64, 64, 52]], 0.6809210777282715],\n",
              " [[[1, 32, 2, 64, 0, 32, 2, 0, 0, 128, 64, 52]], 0.7061403393745422],\n",
              " [[[1, 32, 2, 64, 0, 32, 0, 0, 0, 64, 64, 52]], 0.5394737124443054],\n",
              " [[[1, 32, 2, 64, 0, 32, 0, 0, 0, 128, 64, 52]], 0.6019737124443054],\n",
              " [[[1, 32, 2, 64, 0, 64, 2, 0, 0, 64, 64, 52]], 0.6458333134651184],\n",
              " [[[1, 32, 2, 64, 0, 64, 2, 0, 0, 128, 64, 52]], 0.6589912176132202],\n",
              " [[[1, 32, 2, 64, 0, 64, 0, 0, 0, 64, 64, 52]], 0.5065789222717285],\n",
              " [[[1, 32, 2, 64, 0, 64, 0, 0, 0, 128, 64, 52]], 0.6359649300575256],\n",
              " [[[1, 32, 2, 64, 0, 128, 2, 0, 0, 64, 64, 52]], 0.6425438523292542],\n",
              " [[[1, 32, 2, 64, 0, 128, 2, 0, 0, 128, 64, 52]], 0.6184210777282715],\n",
              " [[[1, 32, 2, 64, 0, 128, 0, 0, 0, 64, 64, 52]], 0.5493420958518982],\n",
              " [[[1, 32, 2, 64, 0, 128, 0, 0, 0, 128, 64, 52]], 0.5515350699424744],\n",
              " [[[1, 32, 2, 128, 2, 32, 2, 0, 0, 64, 64, 52]], 0.7445175647735596],\n",
              " [[[1, 32, 2, 128, 2, 32, 2, 0, 0, 128, 64, 52]], 0.7642543911933899],\n",
              " [[[1, 32, 2, 128, 2, 32, 0, 0, 0, 64, 64, 52]], 0.6842105388641357],\n",
              " [[[1, 32, 2, 128, 2, 32, 0, 0, 0, 128, 64, 52]], 0.6896929740905762],\n",
              " [[[1, 32, 2, 128, 2, 64, 2, 0, 0, 64, 64, 52]], 0.7313596606254578],\n",
              " [[[1, 32, 2, 128, 2, 64, 2, 0, 0, 128, 64, 52]], 0.7291666865348816],\n",
              " [[[1, 32, 2, 128, 2, 64, 0, 0, 0, 64, 64, 52]], 0.6480262875556946],\n",
              " [[[1, 32, 2, 128, 2, 64, 0, 0, 0, 128, 64, 52]], 0.6765350699424744],\n",
              " [[[1, 32, 2, 128, 2, 128, 2, 0, 0, 64, 64, 52]], 0.6995614171028137],\n",
              " [[[1, 32, 2, 128, 2, 128, 2, 0, 0, 128, 64, 52]], 0.7631579041481018],\n",
              " [[[1, 32, 2, 128, 2, 128, 0, 0, 0, 64, 64, 52]], 0.5833333134651184],\n",
              " [[[1, 32, 2, 128, 2, 128, 0, 0, 0, 128, 64, 52]], 0.6447368264198303],\n",
              " [[[1, 32, 2, 128, 0, 32, 2, 0, 0, 64, 64, 52]], 0.6578947305679321],\n",
              " [[[1, 32, 2, 128, 0, 32, 2, 0, 0, 128, 64, 52]], 0.7061403393745422],\n",
              " [[[1, 32, 2, 128, 0, 32, 0, 0, 0, 64, 64, 52]], 0.5405701994895935],\n",
              " [[[1, 32, 2, 128, 0, 32, 0, 0, 0, 128, 64, 52]], 0.5657894611358643],\n",
              " [[[1, 32, 2, 128, 0, 64, 2, 0, 0, 64, 64, 52]], 0.6041666865348816],\n",
              " [[[1, 32, 2, 128, 0, 64, 2, 0, 0, 128, 64, 52]], 0.6600877046585083],\n",
              " [[[1, 32, 2, 128, 0, 64, 0, 0, 0, 64, 64, 52]], 0.5811403393745422],\n",
              " [[[1, 32, 2, 128, 0, 64, 0, 0, 0, 128, 64, 52]], 0.5372806787490845],\n",
              " [[[1, 32, 2, 128, 0, 128, 2, 0, 0, 64, 64, 52]], 0.5855262875556946],\n",
              " [[[1, 32, 2, 128, 0, 128, 2, 0, 0, 128, 64, 52]], 0.6228070259094238],\n",
              " [[[1, 32, 2, 128, 0, 128, 0, 0, 0, 64, 64, 52]], 0.5438596606254578],\n",
              " [[[1, 32, 2, 128, 0, 128, 0, 0, 0, 128, 64, 52]], 0.5241228342056274],\n",
              " [[[1, 64, 2, 32, 2, 32, 2, 0, 0, 64, 64, 52]], 0.7434210777282715],\n",
              " [[[1, 64, 2, 32, 2, 32, 2, 0, 0, 128, 64, 52]], 0.7598684430122375],\n",
              " [[[1, 64, 2, 32, 2, 32, 0, 0, 0, 64, 64, 52]], 0.6502193212509155],\n",
              " [[[1, 64, 2, 32, 2, 32, 0, 0, 0, 128, 64, 52]], 0.7094298005104065],\n",
              " [[[1, 64, 2, 32, 2, 64, 2, 0, 0, 64, 64, 52]], 0.7390350699424744],\n",
              " [[[1, 64, 2, 32, 2, 64, 2, 0, 0, 128, 64, 52]], 0.7631579041481018],\n",
              " [[[1, 64, 2, 32, 2, 64, 0, 0, 0, 64, 64, 52]], 0.6326754093170166],\n",
              " [[[1, 64, 2, 32, 2, 64, 0, 0, 0, 128, 64, 52]], 0.6578947305679321],\n",
              " [[[1, 64, 2, 32, 2, 128, 2, 0, 0, 64, 64, 52]], 0.6984649300575256],\n",
              " [[[1, 64, 2, 32, 2, 128, 2, 0, 0, 128, 64, 52]], 0.7269737124443054],\n",
              " [[[1, 64, 2, 32, 2, 128, 0, 0, 0, 64, 64, 52]], 0.6271929740905762],\n",
              " [[[1, 64, 2, 32, 2, 128, 0, 0, 0, 128, 64, 52]], 0.5910087823867798],\n",
              " [[[1, 64, 2, 32, 0, 32, 2, 0, 0, 64, 64, 52]], 0.6732456088066101],\n",
              " [[[1, 64, 2, 32, 0, 32, 2, 0, 0, 128, 64, 52]], 0.6765350699424744],\n",
              " [[[1, 64, 2, 32, 0, 32, 0, 0, 0, 64, 64, 52]], 0.5109649300575256],\n",
              " [[[1, 64, 2, 32, 0, 32, 0, 0, 0, 128, 64, 52]], 0.6315789222717285],\n",
              " [[[1, 64, 2, 32, 0, 64, 2, 0, 0, 64, 64, 52]], 0.6666666865348816],\n",
              " [[[1, 64, 2, 32, 0, 64, 2, 0, 0, 128, 64, 52]], 0.6885964870452881],\n",
              " [[[1, 64, 2, 32, 0, 64, 0, 0, 0, 64, 64, 52]], 0.5032894611358643],\n",
              " [[[1, 64, 2, 32, 0, 64, 0, 0, 0, 128, 64, 52]], 0.5975877046585083],\n",
              " [[[1, 64, 2, 32, 0, 128, 2, 0, 0, 64, 64, 52]], 0.6381579041481018],\n",
              " [[[1, 64, 2, 32, 0, 128, 2, 0, 0, 128, 64, 52]], 0.5910087823867798],\n",
              " [[[1, 64, 2, 32, 0, 128, 0, 0, 0, 64, 64, 52]], 0.5274122953414917]]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracylist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([[1, 32, 2, 128, 2, 32, 2, 0, 0, 128, 64, 52]], 0.7642543911933899)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "maxacc = 0\n",
        "for i in accuracylist:\n",
        "    if i[1] > maxacc:\n",
        "        chosenparam = i[0]\n",
        "        maxacc = i[1]\n",
        "chosenparam, maxacc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1JcCWZ4WqYMF"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "def cnnTraining(input_shape):\n",
        "    # First convolutional layer\n",
        "    x = layers.Conv2D(32, (3,3), activation = 'relu')(input_shape)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = layers.Conv2D(128,(3, 3), activation = 'relu')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Third convolutional layer\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = layers.Flatten()(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "PKfWVtWkqYMG",
        "outputId": "da31fcc9-6044-41a3-8eb0-18be38fb3c21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_98\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_98\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1470         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1473         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1476         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1479         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1482         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_990   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1470[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_993   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1473[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_996   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1476[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_999   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1479[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1002  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1482[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1471         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1474         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1477         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1480         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1483         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │ max_pooling2d_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_991   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1471[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_994   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1474[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_997   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1477[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1000  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1480[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1003  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1483[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1472         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1475         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1478         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1481         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ max_pooling2d_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1484         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ max_pooling2d_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_992   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1472[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_995   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1475[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_998   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1478[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1001  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1481[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1004  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1484[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_490         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_491         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_492         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_99… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_493         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_494         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_98      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_490[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_491[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ flatten_492[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ flatten_493[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ flatten_494[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_294 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">737,408</span> │ concatenate_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_295 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_294[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_296 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,380</span> │ dense_295[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1470         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1473         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1476         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1479         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1482         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m320\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_990   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1470[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_993   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1473[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_996   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1476[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_999   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1479[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1002  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1482[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1471         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m36,992\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1474         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m36,992\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1477         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m36,992\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1480         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m36,992\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1483         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m36,992\u001b[0m │ max_pooling2d_10… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_991   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1471[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_994   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1474[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_997   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1477[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1000  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1480[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1003  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1483[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1472         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1475         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1478         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1481         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ max_pooling2d_10… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1484         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m,    │     \u001b[38;5;34m36,896\u001b[0m │ max_pooling2d_10… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_992   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1472[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_995   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1475[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_998   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1478[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1001  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1481[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1004  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1484[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_490         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_491         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_492         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_99… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_493         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_10… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_494         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_10… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_98      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5760\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_490[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_491[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ flatten_492[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ flatten_493[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ flatten_494[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_294 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m737,408\u001b[0m │ concatenate_98[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_295 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_294[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_296 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)        │      \u001b[38;5;34m3,380\u001b[0m │ dense_295[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,084</span> (4.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,120,084\u001b[0m (4.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,084</span> (4.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,120,084\u001b[0m (4.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input1 = Input(shape = input_shape1)\n",
        "input2 = Input(shape= input_shape2)\n",
        "input3 = Input(shape= input_shape3)\n",
        "input4 = Input(shape= input_shape4)\n",
        "input5 = Input(shape= input_shape5)\n",
        "\n",
        "# Create the model\n",
        "cnn1 = cnnTraining(input1)\n",
        "cnn2 = cnnTraining(input2)\n",
        "cnn3 = cnnTraining(input3)\n",
        "cnn4 = cnnTraining(input4)\n",
        "cnn5 = cnnTraining(input5)\n",
        "\n",
        "concatenated = layers.Concatenate()([cnn1, cnn2, cnn3, cnn4, cnn5])\n",
        "\n",
        "x = layers.Dense(128, activation = 'relu')(concatenated)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[input1, input2, input3, input4, input5], outputs = output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "4f88QtOHqYMH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.1922 - loss: 2.9414 - val_accuracy: 0.5088 - val_loss: 1.5928\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.6014 - loss: 1.3002 - val_accuracy: 0.6524 - val_loss: 1.1623\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7554 - loss: 0.7732 - val_accuracy: 0.6864 - val_loss: 0.9843\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.8800 - loss: 0.3986 - val_accuracy: 0.6886 - val_loss: 1.0460\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9271 - loss: 0.2292 - val_accuracy: 0.7303 - val_loss: 0.9830\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.9778 - loss: 0.1036 - val_accuracy: 0.7379 - val_loss: 1.0427\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9903 - loss: 0.0451 - val_accuracy: 0.7511 - val_loss: 1.0674\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9953 - loss: 0.0239 - val_accuracy: 0.7599 - val_loss: 1.1062\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9984 - loss: 0.0130 - val_accuracy: 0.7599 - val_loss: 1.1460\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7708 - val_loss: 1.1225\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7741 - val_loss: 1.1450\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7708 - val_loss: 1.1661\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7686 - val_loss: 1.1775\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7697 - val_loss: 1.1943\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7675 - val_loss: 1.2096\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 8.8485e-04 - val_accuracy: 0.7686 - val_loss: 1.2201\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 7.7725e-04 - val_accuracy: 0.7730 - val_loss: 1.2290\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 6.7320e-04 - val_accuracy: 0.7741 - val_loss: 1.2431\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 6.0563e-04 - val_accuracy: 0.7719 - val_loss: 1.2494\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 5.4346e-04 - val_accuracy: 0.7708 - val_loss: 1.2598\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7751 - loss: 1.2687\n",
            "Test accuracy: 0.7708333134651184\n"
          ]
        }
      ],
      "source": [
        "# tanh activation\n",
        "history = model.fit([x_train_1, x_train_2, x_train_3, x_train_4, x_train_5], [y_train_1, y_train_2, y_train_3, y_train_4, y_train_5], epochs = 20, batch_size=32, validation_data=([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5]))\n",
        "\n",
        "test_loss, test_acc = model.evaluate([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5])\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.1921 - loss: 3.0011 - val_accuracy: 0.4737 - val_loss: 1.7109\n",
            "Epoch 2/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.5864 - loss: 1.3491 - val_accuracy: 0.6546 - val_loss: 1.2031\n",
            "Epoch 3/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.7670 - loss: 0.7610 - val_accuracy: 0.6798 - val_loss: 1.1189\n",
            "Epoch 4/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - accuracy: 0.8602 - loss: 0.4704 - val_accuracy: 0.6831 - val_loss: 1.1044\n",
            "Epoch 5/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - accuracy: 0.9242 - loss: 0.2600 - val_accuracy: 0.7050 - val_loss: 1.2391\n",
            "Epoch 6/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9470 - loss: 0.1549 - val_accuracy: 0.6842 - val_loss: 1.4177\n",
            "Epoch 7/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9663 - loss: 0.1170 - val_accuracy: 0.6897 - val_loss: 1.5541\n",
            "Epoch 8/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9784 - loss: 0.0727 - val_accuracy: 0.7050 - val_loss: 1.6640\n",
            "Epoch 9/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9823 - loss: 0.0582 - val_accuracy: 0.6875 - val_loss: 1.5948\n",
            "Epoch 10/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9739 - loss: 0.0846 - val_accuracy: 0.7083 - val_loss: 1.7440\n",
            "Epoch 11/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9932 - loss: 0.0308 - val_accuracy: 0.6743 - val_loss: 1.9268\n",
            "Epoch 12/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9883 - loss: 0.0447 - val_accuracy: 0.6864 - val_loss: 1.9181\n",
            "Epoch 13/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9772 - loss: 0.0608 - val_accuracy: 0.6743 - val_loss: 1.9634\n",
            "Epoch 14/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9702 - loss: 0.0835 - val_accuracy: 0.6952 - val_loss: 1.7634\n",
            "Epoch 15/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.9810 - loss: 0.0504 - val_accuracy: 0.7204 - val_loss: 1.6342\n",
            "Epoch 16/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9978 - loss: 0.0092 - val_accuracy: 0.7314 - val_loss: 1.7548\n",
            "Epoch 17/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 6.5724e-04 - val_accuracy: 0.7259 - val_loss: 1.8276\n",
            "Epoch 18/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.0130e-04 - val_accuracy: 0.7325 - val_loss: 1.8574\n",
            "Epoch 19/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.3607e-04 - val_accuracy: 0.7325 - val_loss: 1.8848\n",
            "Epoch 20/20\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.8679e-04 - val_accuracy: 0.7325 - val_loss: 1.9087\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7379 - loss: 1.8547\n",
            "Test accuracy: 0.7324561476707458\n"
          ]
        }
      ],
      "source": [
        "#relu activation\n",
        "history = model.fit([x_train_1, x_train_2, x_train_3, x_train_4, x_train_5], [y_train_1, y_train_2, y_train_3, y_train_4, y_train_5], epochs = 20, batch_size=32, validation_data=([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5]))\n",
        "\n",
        "test_loss, test_acc = model.evaluate([x_test_1, x_test_2, x_test_3, x_test_4, x_test_5], [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5])\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1_FGjd_qYMH",
        "outputId": "25a8b0fd-657a-442a-e5b5-0992a657c831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\arjun_tm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from visualkeras) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\arjun_tm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from visualkeras) (1.26.4)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.19-cp312-cp312-win_amd64.whl.metadata (673 bytes)\n",
            "Downloading visualkeras-0.1.3-py3-none-any.whl (16 kB)\n",
            "Downloading aggdraw-1.3.19-cp312-cp312-win_amd64.whl (45 kB)\n",
            "Installing collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.19 visualkeras-0.1.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VJ-XONJHVjec"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, InputLayer, ZeroPadding2D, Concatenate\n",
        "from collections import defaultdict\n",
        "import visualkeras\n",
        "from PIL import ImageFont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lDaTkwDDZr_O"
      },
      "outputs": [],
      "source": [
        "color_map = defaultdict(dict)\n",
        "color_map[Input]['fill'] = 'gray'\n",
        "color_map[layers.Conv2D]['fill'] = 'red'\n",
        "color_map[layers.MaxPooling2D]['fill'] = 'blue'\n",
        "color_map[layers.Dropout]['fill'] = 'black'\n",
        "color_map[layers.Flatten]['fill'] = 'green'\n",
        "color_map[layers.Concatenate]['fill'] = 'gray'\n",
        "color_map[layers.Dense]['fill'] = 'yellow'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "HXhMMCyhV8FK",
        "outputId": "15368920-ad04-46f1-a0ba-189c4be01996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\visualkeras\\layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
            "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=2232x380>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "visualkeras.layered_view(model, color_map=color_map, show_dimension=True, legend=True, to_file='vgg16.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "EIAwivRWkcW4",
        "outputId": "4252cbec-314f-4d58-f1b5-d731c9a51029"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=3506x380>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "visualkeras.layered_view(model, legend=True, show_dimension=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXdC-r2HZnx8"
      },
      "outputs": [],
      "source": [
        "# create VGG16\n",
        "image_size = 224\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer(input_shape=(image_size, image_size, 3)))\n",
        "\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(64, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(64, activation='relu', kernel_size=(3, 3)))\n",
        "\n",
        "model1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(128, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(128, activation='relu', kernel_size=(3, 3)))\n",
        "\n",
        "model1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(256, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(256, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(256, activation='relu', kernel_size=(3, 3)))\n",
        "\n",
        "model1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "\n",
        "model1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(ZeroPadding2D((1, 1)))\n",
        "model1.add(Conv2D(512, activation='relu', kernel_size=(3, 3)))\n",
        "model1.add(MaxPooling2D())\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "model1.add(Dense(4096, activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(4096, activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(1000, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF8pvrH0gmCd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
