{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import shutil\n",
    "from skimage.feature import hog\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import exposure\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "annotation_csv = 'annotations.csv'\n",
    "dataset_folder = 'dataset'  # Folder containing original images\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_csv, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    annotations = list(reader)[1:]  # Skip header\n",
    "    # annotations = list(reader)[2880:]  # Skip header\n",
    "    # annotations = list(reader)[1:100]  # Skip header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(image_list, label_list, unique_labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state=42)\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}  # Map labels to index\n",
    "    idx_to_label = {idx: label for idx, label in enumerate(unique_labels)}  # Map index to labels\n",
    "    # Convert labels to numerical indices\n",
    "    numerical_labels = np.array([label_to_idx[label] for label in label_list])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(image_list, numerical_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Normalize the image data (scale pixel values to range [0, 1])\n",
    "    X_train = np.array(X_train) / 255.0\n",
    "    X_test = np.array(X_test) / 255.0\n",
    "\n",
    "    # Convert labels to categorical (one-hot encoding)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(unique_labels))\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(unique_labels))\n",
    "    X_train = np.expand_dims(X_train, axis=-1)  # (num_samples, height, width, 1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    # Set input shape based on your image data (e.g., (height, width, channels))\n",
    "    input_shape = X_train.shape[1:]  # Height, Width, Channels\n",
    "    return input_shape, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = annotations[0][0]\n",
    "c = 0\n",
    "image_list1, image_list2, image_list3, image_list4, image_list5 = [], [], [], [], []\n",
    "label_list = []\n",
    "\n",
    "# Feature extraction steps\n",
    "for annotation in annotations:\n",
    "    c += 1\n",
    "    image_name, letter, center_x, center_y, dist_x, dist_y = annotation\n",
    "\n",
    "    # Load original image\n",
    "    # image_path = os.path.join(dataset_folder, image_name)\n",
    "    img = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    image_name = image_name[image_name.find('\\\\')+1:image_name.find('.')]\n",
    "    # img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: {image_name}_{c} not found!\")\n",
    "        continue\n",
    "\n",
    "    # Crop the letter using the annotation box\n",
    "    start_x = int(float(center_x) - float(dist_x) / 2)\n",
    "    start_y = int(float(center_y) - float(dist_y) / 2)\n",
    "    end_x = int(float(center_x) + float(dist_x) / 2)\n",
    "    end_y = int(float(center_y) + float(dist_y) / 2)\n",
    "    cropped = img[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    # 1. Image Enhancement & Normalization (Histogram Equalization)\n",
    "    resized = cv2.resize(cropped, (64, 64))\n",
    "    enhanced = cv2.equalizeHist(resized)\n",
    "    norm_image = cv2.normalize(enhanced, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    image_list1.append(norm_image)\n",
    "    label_list.append(letter)\n",
    "\n",
    "    # 2. Segmentation (Thresholding)\n",
    "    _, segmented = cv2.threshold(norm_image, 30, 255, cv2.THRESH_BINARY_INV)\n",
    "    image_list2.append(segmented)\n",
    "\n",
    "    # 3. Edge Detection (Canny)\n",
    "    edges = cv2.Canny(segmented, 100, 200)\n",
    "    image_list3.append(edges)\n",
    "\n",
    "    # 4. Skeletonization\n",
    "    binary = segmented / 255  # Convert to binary (0, 1)\n",
    "    skeleton = skeletonize(binary).astype(np.uint8) * 255\n",
    "    image_list4.append(skeleton)\n",
    "\n",
    "    # 5. HOG (Histogram of Oriented Gradients)\n",
    "    hog_features, hog_image = hog(segmented, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=True)\n",
    "    image_list5.append(hog_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_train_split(image_list1, label_list1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(image_list1, label_list1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_labels = sorted(list(set(label_list1)))  # Get unique classes\n",
    "# label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}  # Map labels to index\n",
    "# idx_to_label = {idx: label for idx, label in enumerate(unique_labels)}  # Map index to labels\n",
    "\n",
    "# # Convert labels to numerical indices\n",
    "# numerical_labels = np.array([label_to_idx[label] for label in label_list1])\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(image_list1, numerical_labels, test_size=0.1, random_state=42)\n",
    "# # X_train, X_test = image_list, image_list\n",
    "# # y_train, y_test = numerical_labels, numerical_labels\n",
    "\n",
    "# # Normalize the image data (scale pixel values to range [0, 1])\n",
    "# X_train = np.array(X_train) / 255.0\n",
    "# X_test = np.array(X_test) / 255.0\n",
    "\n",
    "# # Convert labels to categorical (one-hot encoding)\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(unique_labels))\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(unique_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def cnn_training(input_shape):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Third convolutional layer\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Flatten the output\n",
    "    model.add(layers.Flatten())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(list(set(label_list)))  # Get unique classes\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "input_shape1, x_train_1, x_test_1, y_train_1, y_test_1 = test_train_split(image_list1, label_list, unique_labels)\n",
    "input_shape2, x_train_2, x_test_2, y_train_2, y_test_2 = test_train_split(image_list2, label_list, unique_labels)\n",
    "input_shape3, x_train_3, x_test_3, y_train_3, y_test_3 = test_train_split(image_list3, label_list, unique_labels)\n",
    "input_shape4, x_train_4, x_test_4, y_train_4, y_test_4 = test_train_split(image_list4, label_list, unique_labels)\n",
    "input_shape5, x_train_5, x_test_5, y_train_5, y_test_5 = test_train_split(image_list5, label_list, unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mKernel shape must have the same length as input, but received kernel of shape (3, 3, 64, 32) and input of shape (None, 64, 64).\u001b[0m\n\nArguments received by Sequential.call():\n  • args=('<KerasTensor shape=(None, 64, 64), dtype=float32, sparse=None, name=keras_tensor_35>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m input5 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mimage_list5[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m cnn1 \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m cnn2 \u001b[38;5;241m=\u001b[39m cnn_training(input_shape2)(input2)\n\u001b[0;32m     17\u001b[0m cnn3 \u001b[38;5;241m=\u001b[39m cnn_training(input_shape3)(input3)\n",
      "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Arjun_TM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\operation_utils.py:184\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[1;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m    182\u001b[0m     kernel_shape \u001b[38;5;241m=\u001b[39m kernel_size \u001b[38;5;241m+\u001b[39m (input_shape[\u001b[38;5;241m1\u001b[39m], filters)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kernel_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_shape):\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel shape must have the same length as input, but received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dilation_rate, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    190\u001b[0m     dilation_rate \u001b[38;5;241m=\u001b[39m (dilation_rate,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(spatial_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mKernel shape must have the same length as input, but received kernel of shape (3, 3, 64, 32) and input of shape (None, 64, 64).\u001b[0m\n\nArguments received by Sequential.call():\n  • args=('<KerasTensor shape=(None, 64, 64), dtype=float32, sparse=None, name=keras_tensor_35>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "# X_train = np.expand_dims(X_train, axis=-1)  # (num_samples, height, width, 1)\n",
    "# X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# # Set input shape based on your image data (e.g., (height, width, channels))\n",
    "# input_shape = X_train.shape[1:]  # Height, Width, Channels\n",
    "# num_classes = len(unique_labels)\n",
    "\n",
    "input1 = layers.Input(shape=image_list1[0].shape)\n",
    "input2 = layers.Input(shape=image_list2[0].shape)\n",
    "input3 = layers.Input(shape=image_list3[0].shape)\n",
    "input4 = layers.Input(shape=image_list4[0].shape)\n",
    "input5 = layers.Input(shape=image_list5[0].shape)\n",
    "\n",
    "# Create the model\n",
    "cnn1 = cnn_training(input_shape1)(input1)\n",
    "cnn2 = cnn_training(input_shape2)(input2)\n",
    "cnn3 = cnn_training(input_shape3)(input3)\n",
    "cnn4 = cnn_training(input_shape4)(input4)\n",
    "cnn5 = cnn_training(input_shape5)(input5)\n",
    "\n",
    "x = layers.Concatenate([cnn1, cnn2, cnn3, cnn4, cnn5])\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = layers.Model(inputs=[input1, input2, input3, input4, input5], outputs = x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
